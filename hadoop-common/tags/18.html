<h3><span class=" glyphicon glyphicon-tag"/>&nbspLogger</h3><kbd>Invokes logging operations</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.crypto.key.kms.server.TestKMS </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testDelegationTokenAccess() throws Exception {
  Configuration conf=new Configuration();
  conf.set("hadoop.security.authentication","kerberos");
  UserGroupInformation.setConfiguration(conf);
  final File testDir=getTestDir();
  conf=createBaseKMSConf(testDir);
  conf.set("hadoop.kms.authentication.type","kerberos");
  conf.set("hadoop.kms.authentication.kerberos.keytab",keytab.getAbsolutePath());
  conf.set("hadoop.kms.authentication.kerberos.principal","HTTP/localhost");
  conf.set("hadoop.kms.authentication.kerberos.name.rules","DEFAULT");
  writeConf(testDir,conf);
  runServer(null,null,testDir,new KMSCallable(){
    @Override public Void call() throws Exception {
      final Configuration conf=new Configuration();
      conf.setInt(KeyProvider.DEFAULT_BITLENGTH_NAME,64);
      final URI uri=createKMSUri(getKMSUrl());
      final Credentials credentials=new Credentials();
      final UserGroupInformation nonKerberosUgi=UserGroupInformation.getCurrentUser();
      try {
        KeyProvider kp=new KMSClientProvider(uri,conf);
        kp.createKey("kA",new KeyProvider.Options(conf));
      }
 catch (      IOException ex) {
        System.out.println(ex.getMessage());
      }
      doAs("client",new PrivilegedExceptionAction<Void>(){
        @Override public Void run() throws Exception {
          KeyProvider kp=new KMSClientProvider(uri,conf);
          KeyProviderDelegationTokenExtension kpdte=KeyProviderDelegationTokenExtension.createKeyProviderDelegationTokenExtension(kp);
          kpdte.addDelegationTokens("foo",credentials);
          return null;
        }
      }
);
      nonKerberosUgi.addCredentials(credentials);
      try {
        KeyProvider kp=new KMSClientProvider(uri,conf);
        kp.createKey("kA",new KeyProvider.Options(conf));
      }
 catch (      IOException ex) {
        System.out.println(ex.getMessage());
      }
      nonKerberosUgi.doAs(new PrivilegedExceptionAction<Void>(){
        @Override public Void run() throws Exception {
          KeyProvider kp=new KMSClientProvider(uri,conf);
          kp.createKey("kD",new KeyProvider.Options(conf));
          return null;
        }
      }
);
      return null;
    }
  }
);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.FileContextPermissionBase </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testCreatePermission() throws IOException {
  if (Path.WINDOWS) {
    System.out.println("Cannot run test for Windows");
    return;
  }
  String filename="foo";
  Path f=fileContextTestHelper.getTestRootPath(fc,filename);
  fileContextTestHelper.createFile(fc,filename);
  doFilePermissionCheck(FileContext.FILE_DEFAULT_PERM.applyUMask(fc.getUMask()),fc.getFileStatus(f).getPermission());
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testSetPermission() throws IOException {
  if (Path.WINDOWS) {
    System.out.println("Cannot run test for Windows");
    return;
  }
  String filename="foo";
  Path f=fileContextTestHelper.getTestRootPath(fc,filename);
  createFile(fc,f);
  try {
    FsPermission all=new FsPermission((short)0777);
    FsPermission none=new FsPermission((short)0);
    fc.setPermission(f,none);
    doFilePermissionCheck(none,fc.getFileStatus(f).getPermission());
    fc.setPermission(f,all);
    doFilePermissionCheck(all,fc.getFileStatus(f).getPermission());
  }
  finally {
    cleanupFile(fc,f);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestLocalFileSystem </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Regression test for HADOOP-9307: BufferedFSInputStream returning
 * wrong results after certain sequences of seeks and reads.
 */
@Test public void testBufferedFSInputStream() throws IOException {
  Configuration conf=new Configuration();
  conf.setClass("fs.file.impl",RawLocalFileSystem.class,FileSystem.class);
  conf.setInt(CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,4096);
  FileSystem fs=FileSystem.newInstance(conf);
  byte[] buf=new byte[10 * 1024];
  new Random().nextBytes(buf);
  FSDataOutputStream stream=fs.create(TEST_PATH);
  try {
    stream.write(buf);
  }
  finally {
    stream.close();
  }
  Random r=new Random();
  FSDataInputStream stm=fs.open(TEST_PATH);
  int seeks[]=new int[10];
  int reads[]=new int[10];
  try {
    for (int i=0; i < 1000; i++) {
      int seekOff=r.nextInt(buf.length);
      int toRead=r.nextInt(Math.min(buf.length - seekOff,32000));
      seeks[i % seeks.length]=seekOff;
      reads[i % reads.length]=toRead;
      verifyRead(stm,buf,seekOff,toRead);
    }
  }
 catch (  AssertionError afe) {
    StringBuilder sb=new StringBuilder();
    sb.append("Sequence of actions:\n");
    for (int j=0; j < seeks.length; j++) {
      sb.append("seek @ ").append(seeks[j]).append("  ").append("read ").append(reads[j]).append("\n");
    }
    System.err.println(sb.toString());
    throw afe;
  }
 finally {
    stm.close();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestAppendDifferentChecksum </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test which randomly alternates between appending with
 * CRC32 and with CRC32C, crossing several block boundaries.
 * Then, checks that all of the data can be read back correct.
 */
@Test(timeout=RANDOM_TEST_RUNTIME * 2) public void testAlgoSwitchRandomized() throws IOException {
  FileSystem fsWithCrc32=createFsWithChecksum("CRC32",512);
  FileSystem fsWithCrc32C=createFsWithChecksum("CRC32C",512);
  Path p=new Path("/testAlgoSwitchRandomized");
  long seed=Time.now();
  System.out.println("seed: " + seed);
  Random r=new Random(seed);
  IOUtils.closeStream(fsWithCrc32.create(p));
  long st=Time.now();
  int len=0;
  while (Time.now() - st < RANDOM_TEST_RUNTIME) {
    int thisLen=r.nextInt(500);
    FileSystem fs=(r.nextBoolean() ? fsWithCrc32 : fsWithCrc32C);
    FSDataOutputStream stm=fs.append(p);
    try {
      AppendTestUtil.write(stm,len,thisLen);
    }
  finally {
      stm.close();
    }
    len+=thisLen;
  }
  AppendTestUtil.check(fsWithCrc32,p,len);
  AppendTestUtil.check(fsWithCrc32C,p,len);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestCrcCorruption </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testCrcCorruption() throws Exception {
  System.out.println("TestCrcCorruption with default parameters");
  Configuration conf1=new HdfsConfiguration();
  conf1.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
  DFSTestUtil util1=new DFSTestUtil.Builder().setName("TestCrcCorruption").setNumFiles(40).build();
  thistest(conf1,util1);
  System.out.println("TestCrcCorruption with specific parameters");
  Configuration conf2=new HdfsConfiguration();
  conf2.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,17);
  conf2.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,34);
  DFSTestUtil util2=new DFSTestUtil.Builder().setName("TestCrcCorruption").setNumFiles(40).setMaxSize(400).build();
  thistest(conf2,util2);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDistributedFileSystem </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test(timeout=60000) public void testListFiles() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  try {
    DistributedFileSystem fs=cluster.getFileSystem();
    final Path relative=new Path("relative");
    fs.create(new Path(relative,"foo")).close();
    final List<LocatedFileStatus> retVal=new ArrayList<LocatedFileStatus>();
    final RemoteIterator<LocatedFileStatus> iter=fs.listFiles(relative,true);
    while (iter.hasNext()) {
      retVal.add(iter.next());
    }
    System.out.println("retVal = " + retVal);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test a simple flush on a simple HDFS file.
 * @throws IOException an exception might be thrown
 */
@Test public void testSimpleFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/simpleFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file simpleFlush.dat");
    int mid=AppendTestUtil.FILE_SIZE / 2;
    stm.write(fileContents,0,mid);
    stm.hflush();
    System.out.println("Wrote and Flushed first part of file.");
    stm.write(fileContents,mid,AppendTestUtil.FILE_SIZE - mid);
    System.out.println("Written second part of file");
    stm.hflush();
    stm.hflush();
    System.out.println("Wrote and Flushed second part of file.");
    checkFile(fs,file1,1);
    stm.close();
    System.out.println("Closed file.");
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test that file data can be flushed.
 * @throws IOException an exception might be thrown
 */
@Test public void testComplexFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/complexFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file complexFlush.dat");
    int start=0;
    for (start=0; (start + 29) < AppendTestUtil.FILE_SIZE; ) {
      stm.write(fileContents,start,29);
      stm.hflush();
      start+=29;
    }
    stm.write(fileContents,start,AppendTestUtil.FILE_SIZE - start);
    checkFile(fs,file1,1);
    stm.close();
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend3 </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * TC12: Append to partial CRC chunk
 * @throws IOException an exception might be thrown
 */
@Test public void testTC12() throws Exception {
  final Path p=new Path("/TC12/foo");
  System.out.println("p=" + p);
  final int len1=25687;
{
    FSDataOutputStream out=fs.create(p,false,buffersize,REPLICATION,BLOCK_SIZE);
    AppendTestUtil.write(out,0,len1);
    out.close();
  }
  final int len2=5877;
{
    FSDataOutputStream out=fs.append(p);
    AppendTestUtil.write(out,len1,len2);
    out.close();
  }
  AppendTestUtil.check(fs,p,len1 + len2);
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * TC1: Append on block boundary.
 * @throws IOException an exception might be thrown
 */
@Test public void testTC1() throws Exception {
  final Path p=new Path("/TC1/foo");
  System.out.println("p=" + p);
  final int len1=(int)BLOCK_SIZE;
{
    FSDataOutputStream out=fs.create(p,false,buffersize,REPLICATION,BLOCK_SIZE);
    AppendTestUtil.write(out,0,len1);
    out.close();
  }
  final int len2=(int)BLOCK_SIZE / 2;
{
    FSDataOutputStream out=fs.append(p);
    AppendTestUtil.write(out,len1,len2);
    out.close();
  }
  AppendTestUtil.check(fs,p,len1 + len2);
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * TC2: Append on non-block boundary.
 * @throws IOException an exception might be thrown
 */
@Test public void testTC2() throws Exception {
  final Path p=new Path("/TC2/foo");
  System.out.println("p=" + p);
  final int len1=(int)(BLOCK_SIZE + BLOCK_SIZE / 2);
{
    FSDataOutputStream out=fs.create(p,false,buffersize,REPLICATION,BLOCK_SIZE);
    AppendTestUtil.write(out,0,len1);
    out.close();
  }
  AppendTestUtil.check(fs,p,len1);
  final int len2=(int)BLOCK_SIZE / 4;
{
    FSDataOutputStream out=fs.append(p);
    AppendTestUtil.write(out,len1,len2);
    out.close();
  }
  AppendTestUtil.check(fs,p,len1 + len2);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileConcurrentReader </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * test case: if the BlockSender decides there is only one packet to send,
 * the previous computation of the pktSize based on transferToAllowed
 * would result in too small a buffer to do the buffer-copy needed
 * for partial chunks.
 */
@Test(timeout=30000) public void testUnfinishedBlockPacketBufferOverrun() throws IOException {
  Path path=new Path("/");
  System.out.println("Path : \"" + path.toString() + "\"");
  Path file1=new Path("/unfinished-block");
  final FSDataOutputStream stm=TestFileCreation.createFile(fileSystem,file1,1);
  final int bytesPerChecksum=conf.getInt("io.bytes.per.checksum",512);
  final int partialBlockSize=bytesPerChecksum - 1;
  writeFileAndSync(stm,partialBlockSize);
  checkCanRead(fileSystem,file1,partialBlockSize);
  stm.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileCorruption </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * check if local FS can handle corrupted blocks properly 
 */
@Test public void testLocalFileCorruption() throws Exception {
  Configuration conf=new HdfsConfiguration();
  Path file=new Path(PathUtils.getTestDirName(getClass()),"corruptFile");
  FileSystem fs=FileSystem.getLocal(conf);
  DataOutputStream dos=fs.create(file);
  dos.writeBytes("original bytes");
  dos.close();
  dos=new DataOutputStream(new FileOutputStream(file.toString()));
  dos.writeBytes("corruption");
  dos.close();
  DataInputStream dis=fs.open(file,512);
  try {
    System.out.println("A ChecksumException is expected to be logged.");
    dis.readByte();
  }
 catch (  ChecksumException ignore) {
  }
  fs.delete(file,true);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileCreation </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testFsClose() throws Exception {
  System.out.println("test file system close start");
  final int DATANODE_NUM=3;
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
  DistributedFileSystem dfs=null;
  try {
    cluster.waitActive();
    dfs=cluster.getFileSystem();
    final String f=DIR + "foofs";
    final Path fpath=new Path(f);
    FSDataOutputStream out=TestFileCreation.createFile(dfs,fpath,DATANODE_NUM);
    out.write("something".getBytes());
    dfs.close();
  }
  finally {
    System.out.println("testFsClose successful");
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestHFlush </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * This creates a slow writer and check to see 
 * if pipeline heartbeats work fine
 */
@Test public void testPipelineHeartbeat() throws Exception {
  final int DATANODE_NUM=2;
  final int fileLen=6;
  Configuration conf=new HdfsConfiguration();
  final int timeout=2000;
  conf.setInt(DFSConfigKeys.DFS_CLIENT_SOCKET_TIMEOUT_KEY,timeout);
  final Path p=new Path("/pipelineHeartbeat/foo");
  System.out.println("p=" + p);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
  try {
    DistributedFileSystem fs=cluster.getFileSystem();
    byte[] fileContents=AppendTestUtil.initBuffer(fileLen);
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,p,DATANODE_NUM);
    stm.write(fileContents,0,1);
    Thread.sleep(timeout);
    stm.hflush();
    System.out.println("Wrote 1 byte and hflush " + p);
    Thread.sleep(timeout);
    stm.write(fileContents,1,1);
    stm.hflush();
    stm.write(fileContents,2,1);
    Thread.sleep(timeout);
    stm.hflush();
    stm.write(fileContents,3,1);
    Thread.sleep(timeout);
    stm.write(fileContents,4,1);
    stm.hflush();
    stm.write(fileContents,5,1);
    Thread.sleep(timeout);
    stm.close();
    AppendTestUtil.checkFullFile(fs,p,fileLen,fileContents,"Failed to slowly write to a file");
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestWriteConfigurationToDFS </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test(timeout=60000) public void testWriteConf() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,4096);
  System.out.println("Setting conf in: " + System.identityHashCode(conf));
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  FileSystem fs=null;
  OutputStream os=null;
  try {
    fs=cluster.getFileSystem();
    Path filePath=new Path("/testWriteConf.xml");
    os=fs.create(filePath);
    StringBuilder longString=new StringBuilder();
    for (int i=0; i < 100000; i++) {
      longString.append("hello");
    }
    conf.set("foobar",longString.toString());
    conf.writeXml(os);
    os.close();
    os=null;
    fs.close();
    fs=null;
  }
  finally {
    IOUtils.cleanup(null,os,fs);
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testVolumeFailure() throws Exception {
  FileSystem fs=cluster.getFileSystem();
  dataDir=new File(cluster.getDataDirectory());
  System.out.println("Data dir: is " + dataDir.getPath());
  String filename="/test.txt";
  Path filePath=new Path(filename);
  int filesize=block_size * blocks_num;
  DFSTestUtil.createFile(fs,filePath,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,filePath,repl);
  System.out.println("file " + filename + "(size "+ filesize+ ") is created and replicated");
  data_fail=new File(dataDir,"data3");
  failedDir=MiniDFSCluster.getFinalizedDir(dataDir,cluster.getNamesystem().getBlockPoolId());
  if (failedDir.exists() && !deteteBlocks(failedDir)) {
    throw new IOException("Could not delete hdfs directory '" + failedDir + "'");
  }
  data_fail.setReadOnly();
  failedDir.setReadOnly();
  System.out.println("Deleteing " + failedDir.getPath() + "; exist="+ failedDir.exists());
  triggerFailure(filename,filesize);
  DataNode dn=cluster.getDataNodes().get(1);
  String bpid=cluster.getNamesystem().getBlockPoolId();
  DatanodeRegistration dnR=dn.getDNRegistrationForBP(bpid);
  Map<DatanodeStorage,BlockListAsLongs> perVolumeBlockLists=dn.getFSDataset().getBlockReports(bpid);
  StorageBlockReport[] reports=new StorageBlockReport[perVolumeBlockLists.size()];
  int reportIndex=0;
  for (  Map.Entry<DatanodeStorage,BlockListAsLongs> kvPair : perVolumeBlockLists.entrySet()) {
    DatanodeStorage dnStorage=kvPair.getKey();
    BlockListAsLongs blockList=kvPair.getValue();
    reports[reportIndex++]=new StorageBlockReport(dnStorage,blockList.getBlockListAsLongs());
  }
  cluster.getNameNodeRpc().blockReport(dnR,bpid,reports);
  verify(filename,filesize);
  System.out.println("creating file test1.txt");
  Path fileName1=new Path("/test1.txt");
  DFSTestUtil.createFile(fs,fileName1,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,fileName1,repl);
  System.out.println("file " + fileName1.getName() + " is created and replicated");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testFencingStress() throws Exception {
  HAStressTestHarness harness=new HAStressTestHarness();
  harness.conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,1000);
  final MiniDFSCluster cluster=harness.startCluster();
  try {
    cluster.waitActive();
    cluster.transitionToActive(0);
    FileSystem fs=harness.getFailoverFs();
    TestContext togglers=new TestContext();
    for (int i=0; i < NUM_THREADS; i++) {
      Path p=new Path("/test-" + i);
      DFSTestUtil.createFile(fs,p,BLOCK_SIZE * 10,(short)3,(long)i);
      togglers.addThread(new ReplicationToggler(togglers,fs,p));
    }
    harness.addReplicationTriggerThread(500);
    harness.addFailoverThread(5000);
    harness.startThreads();
    togglers.startThreads();
    togglers.waitFor(RUNTIME);
    togglers.stop();
    harness.stopThreads();
    for (int i=0; i < NUM_THREADS; i++) {
      Path p=new Path("/test-" + i);
      DFSTestUtil.readFile(fs,p);
    }
  }
  finally {
    System.err.println("===========================\n\n\n\n");
    harness.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Stress test for pipeline/lease recovery. Starts a number of
 * threads, each of which creates a file and has another client
 * break the lease. While these threads run, failover proceeds
 * back and forth between two namenodes.
 */
@Test(timeout=STRESS_RUNTIME * 3) public void testPipelineRecoveryStress() throws Exception {
  HAStressTestHarness harness=new HAStressTestHarness();
  harness.conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY,false);
  harness.conf.setInt(DFSConfigKeys.DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,1000);
  final MiniDFSCluster cluster=harness.startCluster();
  try {
    cluster.waitActive();
    cluster.transitionToActive(0);
    FileSystem fs=harness.getFailoverFs();
    DistributedFileSystem fsAsOtherUser=createFsAsOtherUser(cluster,harness.conf);
    TestContext testers=new TestContext();
    for (int i=0; i < STRESS_NUM_THREADS; i++) {
      Path p=new Path("/test-" + i);
      testers.addThread(new PipelineTestThread(testers,fs,fsAsOtherUser,p));
    }
    harness.addReplicationTriggerThread(500);
    harness.addFailoverThread(5000);
    harness.startThreads();
    testers.startThreads();
    testers.waitFor(STRESS_RUNTIME);
    testers.stop();
    harness.stopThreads();
  }
  finally {
    System.err.println("===========================\n\n\n\n");
    harness.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test(timeout=60000) public void testStandbyIsHot() throws Exception {
  Configuration conf=new Configuration();
  HAUtil.setAllowStandbyReads(conf,true);
  conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(3).build();
  try {
    cluster.waitActive();
    cluster.transitionToActive(0);
    NameNode nn1=cluster.getNameNode(0);
    NameNode nn2=cluster.getNameNode(1);
    FileSystem fs=HATestUtil.configureFailoverFs(cluster,conf);
    Thread.sleep(1000);
    System.err.println("==================================");
    DFSTestUtil.writeFile(fs,TEST_FILE_PATH,TEST_FILE_DATA);
    nn1.getRpcServer().rollEditLog();
    System.err.println("==================================");
    LOG.info("Waiting for block locations to appear on standby node");
    waitForBlockLocations(cluster,nn2,TEST_FILE,3);
    cluster.triggerHeartbeats();
    cluster.triggerBlockReports();
    LOG.info("Changing replication to 1");
    fs.setReplication(TEST_FILE_PATH,(short)1);
    BlockManagerTestUtil.computeAllPendingWork(nn1.getNamesystem().getBlockManager());
    waitForBlockLocations(cluster,nn1,TEST_FILE,1);
    nn1.getRpcServer().rollEditLog();
    LOG.info("Waiting for lowered replication to show up on standby");
    waitForBlockLocations(cluster,nn2,TEST_FILE,1);
    LOG.info("Changing replication to 3");
    fs.setReplication(TEST_FILE_PATH,(short)3);
    BlockManagerTestUtil.computeAllPendingWork(nn1.getNamesystem().getBlockManager());
    nn1.getRpcServer().rollEditLog();
    LOG.info("Waiting for higher replication to show up on standby");
    waitForBlockLocations(cluster,nn2,TEST_FILE,3);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.util.TestChunkedArrayList </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testPerformance(){
  String obj="hello world";
  final int numElems=1000000;
  final int numTrials=5;
  for (int trial=0; trial < numTrials; trial++) {
    System.gc();
{
      ArrayList<String> arrayList=new ArrayList<String>();
      Stopwatch sw=new Stopwatch();
      sw.start();
      for (int i=0; i < numElems; i++) {
        arrayList.add(obj);
      }
      System.out.println("       ArrayList " + sw.elapsedMillis());
    }
    System.gc();
{
      ChunkedArrayList<String> chunkedList=new ChunkedArrayList<String>();
      Stopwatch sw=new Stopwatch();
      sw.start();
      for (int i=0; i < numElems; i++) {
        chunkedList.add(obj);
      }
      System.out.println("ChunkedArrayList " + sw.elapsedMillis());
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.io.TestDataByteBuffers </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testBaseBuffers() throws IOException {
  DataOutputBuffer dob=new DataOutputBuffer();
  Random r=new Random();
  long seed=r.nextLong();
  r.setSeed(seed);
  System.out.println("SEED: " + seed);
  writeJunk(dob,r,seed,1000);
  DataInputBuffer dib=new DataInputBuffer();
  dib.reset(dob.getData(),0,dob.getLength());
  readJunk(dib,r,seed,1000);
  dob.reset();
  writeJunk(dob,r,seed,1000);
  dib.reset(dob.getData(),0,dob.getLength());
  readJunk(dib,r,seed,1000);
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void TestDataOutputByteBufferCompatibility() throws IOException {
  DataOutputByteBuffer dob=new DataOutputByteBuffer();
  Random r=new Random();
  long seed=r.nextLong();
  r.setSeed(seed);
  System.out.println("SEED: " + seed);
  writeJunk(dob,r,seed,1000);
  ByteBuffer buf=ByteBuffer.allocate(dob.getLength());
  for (  ByteBuffer b : dob.getData()) {
    buf.put(b);
  }
  buf.flip();
  DataInputBuffer dib=new DataInputBuffer();
  dib.reset(buf.array(),0,buf.remaining());
  readJunk(dib,r,seed,1000);
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void TestDataInputByteBufferCompatibility() throws IOException {
  DataOutputBuffer dob=new DataOutputBuffer();
  Random r=new Random();
  long seed=r.nextLong();
  r.setSeed(seed);
  System.out.println("SEED: " + seed);
  writeJunk(dob,r,seed,1000);
  ByteBuffer buf=ByteBuffer.wrap(dob.getData(),0,dob.getLength());
  DataInputByteBuffer dib=new DataInputByteBuffer();
  dib.reset(buf);
  readJunk(dib,r,seed,1000);
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testByteBuffers() throws IOException {
  DataOutputByteBuffer dob=new DataOutputByteBuffer();
  Random r=new Random();
  long seed=r.nextLong();
  r.setSeed(seed);
  System.out.println("SEED: " + seed);
  writeJunk(dob,r,seed,1000);
  DataInputByteBuffer dib=new DataInputByteBuffer();
  dib.reset(dob.getData());
  readJunk(dib,r,seed,1000);
  dob.reset();
  writeJunk(dob,r,seed,1000);
  dib.reset(dob.getData());
  readJunk(dib,r,seed,1000);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void benchmark2() throws Exception {
  int maps=100;
  int reduces=50;
  int maxConcurrentRunningTasks=500;
  System.out.println("Running benchmark with throttled running tasks with " + "maxConcurrentRunningTasks:" + maxConcurrentRunningTasks + " maps:"+ maps+ " reduces:"+ reduces);
  run(new ThrottledMRApp(maps,reduces,maxConcurrentRunningTasks));
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void benchmark1() throws Exception {
  int maps=100;
  int reduces=0;
  System.out.println("Running benchmark with maps:" + maps + " reduces:"+ reduces);
  run(new MRApp(maps,reduces,true,this.getClass().getName(),true){
    @Override protected ContainerAllocator createContainerAllocator(    ClientService clientService,    AppContext context){
      AMPreemptionPolicy policy=new NoopAMPreemptionPolicy();
      return new RMContainerAllocator(clientService,context,policy){
        @Override protected ApplicationMasterProtocol createSchedulerProxy(){
          return new ApplicationMasterProtocol(){
            @Override public RegisterApplicationMasterResponse registerApplicationMaster(            RegisterApplicationMasterRequest request) throws IOException {
              RegisterApplicationMasterResponse response=Records.newRecord(RegisterApplicationMasterResponse.class);
              response.setMaximumResourceCapability(Resource.newInstance(10240,1));
              return response;
            }
            @Override public FinishApplicationMasterResponse finishApplicationMaster(            FinishApplicationMasterRequest request) throws IOException {
              FinishApplicationMasterResponse response=Records.newRecord(FinishApplicationMasterResponse.class);
              return response;
            }
            @Override public AllocateResponse allocate(            AllocateRequest request) throws IOException {
              AllocateResponse response=Records.newRecord(AllocateResponse.class);
              List<ResourceRequest> askList=request.getAskList();
              List<Container> containers=new ArrayList<Container>();
              for (              ResourceRequest req : askList) {
                if (!ResourceRequest.isAnyLocation(req.getResourceName())) {
                  continue;
                }
                int numContainers=req.getNumContainers();
                for (int i=0; i < numContainers; i++) {
                  ContainerId containerId=ContainerId.newInstance(getContext().getApplicationAttemptId(),request.getResponseId() + i);
                  containers.add(Container.newInstance(containerId,NodeId.newInstance("host" + containerId.getId(),2345),"host" + containerId.getId() + ":5678",req.getCapability(),req.getPriority(),null));
                }
              }
              response.setAllocatedContainers(containers);
              response.setResponseId(request.getResponseId() + 1);
              response.setNumClusterNodes(350);
              return response;
            }
          }
;
        }
      }
;
    }
  }
);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.v2.app.TestMRApp </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testCountersOnJobFinish() throws Exception {
  MRAppWithSpiedJob app=new MRAppWithSpiedJob(1,1,true,this.getClass().getName(),true);
  JobImpl job=(JobImpl)app.submit(new Configuration());
  app.waitForState(job,JobState.SUCCEEDED);
  app.verifyCompleted();
  System.out.println(job.getAllCounters());
  job.getAllCounters();
  job.getAllCounters();
  verify(job,times(1)).constructFinalFullcounters();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.metrics2.lib.TestMutableMetrics </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Ensure that quantile estimates from {@link MutableQuantiles} are within
 * specified error bounds.
 */
@Test(timeout=30000) public void testMutableQuantilesError() throws Exception {
  MetricsRecordBuilder mb=mockMetricsRecordBuilder();
  MetricsRegistry registry=new MetricsRegistry("test");
  MutableQuantiles quantiles=registry.newQuantiles("foo","stat","Ops","Latency",5);
  long start=System.nanoTime() / 1000000;
  for (long i=1; i <= 1000; i++) {
    quantiles.add(i);
    quantiles.add(1001 - i);
  }
  long end=System.nanoTime() / 1000000;
  Thread.sleep(6000 - (end - start));
  registry.snapshot(mb,false);
  Map<Quantile,Long> previousSnapshot=quantiles.previousSnapshot;
  for (  Entry<Quantile,Long> item : previousSnapshot.entrySet()) {
    System.out.println(String.format("Quantile %.2f has value %d",item.getKey().quantile,item.getValue()));
  }
  verify(mb).addGauge(info("FooNumOps","Number of ops for stat with 5s interval"),(long)2000);
  Quantile[] quants=MutableQuantiles.quantiles;
  String name="Foo%dthPercentileLatency";
  String desc="%d percentile latency with 5 second interval for stat";
  for (  Quantile q : quants) {
    int percentile=(int)(100 * q.quantile);
    int error=(int)(1000 * q.error);
    String n=String.format(name,percentile);
    String d=String.format(desc,percentile);
    long expected=(long)(q.quantile * 1000);
    verify(mb).addGauge(eq(info(n,d)),leq(expected + error));
    verify(mb).addGauge(eq(info(n,d)),geq(expected - error));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.util.TestDataChecksum </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testBulkOps() throws Exception {
  for (  DataChecksum.Type type : CHECKSUM_TYPES) {
    System.err.println("---- beginning tests with checksum type " + type + "----");
    DataChecksum checksum=DataChecksum.newDataChecksum(type,BYTES_PER_CHUNK);
    for (    boolean useDirect : new boolean[]{false,true}) {
      doBulkTest(checksum,1023,useDirect);
      doBulkTest(checksum,1024,useDirect);
      doBulkTest(checksum,1025,useDirect);
    }
  }
}

</code></pre>

<br>
<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Simple performance test for the "common case" checksum usage in HDFS:
 * computing and verifying CRC32C with 512 byte chunking on native
 * buffers.
 */
@Test public void commonUsagePerfTest() throws Exception {
  final int NUM_RUNS=5;
  final DataChecksum checksum=DataChecksum.newDataChecksum(DataChecksum.Type.CRC32C,512);
  final int dataLength=512 * 1024 * 1024;
  Harness h=new Harness(checksum,dataLength,true);
  for (int i=0; i < NUM_RUNS; i++) {
    Stopwatch s=new Stopwatch().start();
    checksum.calculateChunkedSums(h.dataBuf,h.checksumBuf);
    s.stop();
    System.err.println("Calculate run #" + i + ": "+ s.elapsedTime(TimeUnit.MICROSECONDS)+ "us");
    s=new Stopwatch().start();
    checksum.verifyChunkedSums(h.dataBuf,h.checksumBuf,"fake file",0);
    s.stop();
    System.err.println("Verify run #" + i + ": "+ s.elapsedTime(TimeUnit.MICROSECONDS)+ "us");
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test {@link NMAuditLogger} without IP set.
 */
@Test public void testNMAuditLoggerWithoutIP() throws Exception {
  testSuccessLogFormat(false);
  testFailureLogFormat(false);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResource </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testResourceEquality() throws URISyntaxException {
  Random r=new Random();
  long seed=r.nextLong();
  r.setSeed(seed);
  System.out.println("SEED: " + seed);
  long basetime=r.nextLong() >>> 2;
  org.apache.hadoop.yarn.api.records.LocalResource yA=getYarnResource(new Path("http://yak.org:80/foobar"),-1,basetime,FILE,PUBLIC,null);
  org.apache.hadoop.yarn.api.records.LocalResource yB=getYarnResource(new Path("http://yak.org:80/foobar"),-1,basetime,FILE,PUBLIC,null);
  final LocalResourceRequest a=new LocalResourceRequest(yA);
  LocalResourceRequest b=new LocalResourceRequest(yA);
  checkEqual(a,b);
  b=new LocalResourceRequest(yB);
  checkEqual(a,b);
  yB=getYarnResource(new Path("http://yak.org:80/foobar"),-1,basetime,FILE,PRIVATE,null);
  b=new LocalResourceRequest(yB);
  checkEqual(a,b);
  yB=getYarnResource(new Path("http://yak.org:80/foobar"),0,basetime,FILE,PRIVATE,null);
  b=new LocalResourceRequest(yB);
  checkEqual(a,b);
  yB=getYarnResource(new Path("hdfs://dingo.org:80/foobar"),0,basetime,ARCHIVE,PUBLIC,null);
  b=new LocalResourceRequest(yB);
  checkNotEqual(a,b);
  yB=getYarnResource(new Path("http://yak.org:80/foobar"),0,basetime,ARCHIVE,PUBLIC,null);
  b=new LocalResourceRequest(yB);
  checkNotEqual(a,b);
  yB=getYarnResource(new Path("http://yak.org:80/foobar"),0,basetime + 1,FILE,PUBLIC,null);
  b=new LocalResourceRequest(yB);
  checkNotEqual(a,b);
  yB=getYarnResource(new Path("http://yak.org:80/foobar"),0,basetime + 1,FILE,PUBLIC,"^/foo/.*");
  b=new LocalResourceRequest(yB);
  checkNotEqual(a,b);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test(timeout=20000) @SuppressWarnings("unchecked") public void testFailedPublicResource() throws Exception {
  List<Path> localDirs=new ArrayList<Path>();
  String[] sDirs=new String[4];
  for (int i=0; i < 4; ++i) {
    localDirs.add(lfs.makeQualified(new Path(basedir,i + "")));
    sDirs[i]=localDirs.get(i).toString();
  }
  conf.setStrings(YarnConfiguration.NM_LOCAL_DIRS,sDirs);
  DrainDispatcher dispatcher=new DrainDispatcher();
  EventHandler<ApplicationEvent> applicationBus=mock(EventHandler.class);
  dispatcher.register(ApplicationEventType.class,applicationBus);
  EventHandler<ContainerEvent> containerBus=mock(EventHandler.class);
  dispatcher.register(ContainerEventType.class,containerBus);
  ContainerExecutor exec=mock(ContainerExecutor.class);
  DeletionService delService=mock(DeletionService.class);
  LocalDirsHandlerService dirsHandler=new LocalDirsHandlerService();
  dirsHandler.init(conf);
  dispatcher.init(conf);
  dispatcher.start();
  try {
    ResourceLocalizationService rawService=new ResourceLocalizationService(dispatcher,exec,delService,dirsHandler,new NMNullStateStoreService());
    ResourceLocalizationService spyService=spy(rawService);
    doReturn(mockServer).when(spyService).createServer();
    doReturn(lfs).when(spyService).getLocalFileContext(isA(Configuration.class));
    spyService.init(conf);
    spyService.start();
    final String user="user0";
    final Application app=mock(Application.class);
    final ApplicationId appId=BuilderUtils.newApplicationId(314159265358979L,3);
    when(app.getUser()).thenReturn(user);
    when(app.getAppId()).thenReturn(appId);
    spyService.handle(new ApplicationLocalizationEvent(LocalizationEventType.INIT_APPLICATION_RESOURCES,app));
    dispatcher.await();
    final Container c=getMockContainer(appId,42,user);
    Random r=new Random();
    long seed=r.nextLong();
    System.out.println("SEED: " + seed);
    r.setSeed(seed);
    final CyclicBarrier barrier=new CyclicBarrier(2);
    doAnswer(new Answer<Void>(){
      public Void answer(      InvocationOnMock invocation) throws IOException {
        try {
          barrier.await();
        }
 catch (        InterruptedException e) {
        }
catch (        BrokenBarrierException e) {
        }
        throw new IOException("forced failure");
      }
    }
).when(spylfs).setPermission(isA(Path.class),isA(FsPermission.class));
    final LocalResource pubResource=getPublicMockedResource(r);
    final LocalResourceRequest pubReq=new LocalResourceRequest(pubResource);
    Map<LocalResourceVisibility,Collection<LocalResourceRequest>> req=new HashMap<LocalResourceVisibility,Collection<LocalResourceRequest>>();
    req.put(LocalResourceVisibility.PUBLIC,Collections.singletonList(pubReq));
    Set<LocalResourceRequest> pubRsrcs=new HashSet<LocalResourceRequest>();
    pubRsrcs.add(pubReq);
    spyService.handle(new ContainerLocalizationRequestEvent(c,req));
    spyService.handle(new ContainerLocalizationRequestEvent(c,req));
    dispatcher.await();
    barrier.await();
    verify(containerBus,timeout(5000).times(2)).handle(isA(ContainerResourceFailedEvent.class));
  }
  finally {
    dispatcher.stop();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.yarn.server.resourcemanager.TestRMAuditLogger </h4><pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test {@link RMAuditLogger} without IP set.
 */
@Test public void testRMAuditLoggerWithoutIP() throws Exception {
  testSuccessLogFormat(false);
  testFailureLogFormat(false);
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppendRestart (3 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="6"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('6')" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value "><kbd id="tag-6"class="label-info"style="display: inline-block;font-size:7pt" >EqualityVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="7"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('7')" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls"><kbd id="tag-7"class="label-info"style="display: inline-block;font-size:7pt" >InternalCallVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(1)</kbd></button>&nbsp;<button id="9"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('9')" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) "><kbd id="tag-9"class="label-info"style="display: inline-block;font-size:7pt" >APIUtilityVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-9 type-7 type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Regression test for HDFS-2991. Creates and appends to files
 * where blocks start/end on block boundaries.
 */
@Test public void testAppendRestart() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,0);
  MiniDFSCluster cluster=null;
  FSDataOutputStream stream=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    FileSystem fs=cluster.getFileSystem();
    File editLog=new File(FSImageTestUtil.getNameNodeCurrentDirs(cluster,0).get(0),NNStorage.getInProgressEditsFileName(1));
    EnumMap<FSEditLogOpCodes,Holder<Integer>> counts;
    Path p1=new Path("/block-boundaries");
    writeAndAppend(fs,p1,BLOCK_SIZE,BLOCK_SIZE);
    counts=FSImageTestUtil.countEditLogOpTypes(editLog);
    assertEquals(2,(int)counts.get(FSEditLogOpCodes.OP_ADD).held);
    assertEquals(2,(int)counts.get(FSEditLogOpCodes.OP_ADD_BLOCK).held);
    assertEquals(2,(int)counts.get(FSEditLogOpCodes.OP_CLOSE).held);
    Path p2=new Path("/not-block-boundaries");
    writeAndAppend(fs,p2,BLOCK_SIZE / 2,BLOCK_SIZE);
    counts=FSImageTestUtil.countEditLogOpTypes(editLog);
    assertEquals(2 + 2,(int)counts.get(FSEditLogOpCodes.OP_ADD).held);
    assertEquals(1,(int)counts.get(FSEditLogOpCodes.OP_UPDATE_BLOCKS).held);
    assertEquals(2 + 2,(int)counts.get(FSEditLogOpCodes.OP_ADD_BLOCK).held);
    assertEquals(2 + 2,(int)counts.get(FSEditLogOpCodes.OP_CLOSE).held);
    cluster.restartNameNode();
    AppendTestUtil.check(fs,p1,2 * BLOCK_SIZE);
    AppendTestUtil.check(fs,p2,3 * BLOCK_SIZE / 2);
  }
  finally {
    IOUtils.closeStream(stream);
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<pre class="type-7 type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Earlier versions of HDFS had a bug (HDFS-2991) which caused
 * append(), when called exactly at a block boundary,
 * to not log an OP_ADD. This ensures that we can read from
 * such buggy versions correctly, by loading an image created
 * using a namesystem image created with 0.23.1-rc2 exhibiting
 * the issue.
 */
@Test public void testLoadLogsFromBuggyEarlierVersions() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  String tarFile=System.getProperty("test.cache.data","build/test/cache") + "/" + HADOOP_23_BROKEN_APPEND_TGZ;
  String testDir=PathUtils.getTestDirName(getClass());
  File dfsDir=new File(testDir,"image-with-buggy-append");
  if (dfsDir.exists() && !FileUtil.fullyDelete(dfsDir)) {
    throw new IOException("Could not delete dfs directory '" + dfsDir + "'");
  }
  FileUtil.unTar(new File(tarFile),new File(testDir));
  File nameDir=new File(dfsDir,"name");
  GenericTestUtils.assertExists(nameDir);
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameDir.getAbsolutePath());
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).numDataNodes(0).waitSafeMode(false).startupOption(StartupOption.UPGRADE).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    Path testPath=new Path("/tmp/io_data/test_io_0");
    assertEquals(2 * 1024 * 1024,fs.getFileStatus(testPath).getLen());
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test to append to the file, when one of datanode in the existing pipeline
 * is down.
 */
@Test public void testAppendWithPipelineRecovery() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  FSDataOutputStream out=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).manageDataDfsDirs(true).manageNameDfsDirs(true).numDataNodes(4).racks(new String[]{"/rack1","/rack1","/rack1","/rack2"}).build();
    cluster.waitActive();
    DistributedFileSystem fs=cluster.getFileSystem();
    Path path=new Path("/test1");
    out=fs.create(path,true,BLOCK_SIZE,(short)3,BLOCK_SIZE);
    AppendTestUtil.write(out,0,1024);
    out.close();
    cluster.stopDataNode(3);
    out=fs.append(path);
    AppendTestUtil.write(out,1024,1024);
    out.close();
    cluster.restartNameNode(true);
    AppendTestUtil.check(fs,path,2048);
  }
  finally {
    IOUtils.closeStream(out);
    if (null != cluster) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

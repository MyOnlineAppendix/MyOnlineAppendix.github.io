<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSRollback (2 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="13"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('13')" data-toggle="tooltip" title="Verifies assertions in iterations"><kbd id="tag-13"class="label-info"style="display: inline-block;font-size:7pt" >IterativeVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="9"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('9')" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) "><kbd id="tag-9"class="label-info"style="display: inline-block;font-size:7pt" >APIUtilityVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="7"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('7')" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls"><kbd id="tag-7"class="label-info"style="display: inline-block;font-size:7pt" >InternalCallVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="4"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('4')" data-toggle="tooltip" title="Releases resources used by the test cases"><kbd id="tag-4"class="label-info"style="display: inline-block;font-size:7pt" >TestCleaner&nbsp;(1)</kbd></button>&nbsp;<button id="10"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('10')" data-toggle="tooltip" title="Verifies boolean conditions"><kbd id="tag-10"class="label-info"style="display: inline-block;font-size:7pt" >BooleanVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-4 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
"></span><br>
@After public void tearDown() throws Exception {
  LOG.info("Shutting down MiniDFSCluster");
  if (cluster != null)   cluster.shutdown();
}

</code></pre>

<pre class="type-9 type-13 type-7 type-10 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * This test attempts to rollback the NameNode and DataNode under
 * a number of valid and invalid conditions.
 */
@Test public void testRollback() throws Exception {
  File[] baseDirs;
  UpgradeUtilities.initialize();
  StorageInfo storageInfo=null;
  for (int numDirs=1; numDirs <= 2; numDirs++) {
    conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    String[] nameNodeDirs=conf.getStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY);
    String[] dataNodeDirs=conf.getStrings(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY);
    log("Normal NameNode rollback",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    NameNode.doRollback(conf,false);
    checkResult(NAME_NODE,nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("Normal DataNode rollback",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    NameNode.doRollback(conf,false);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).dnStartupOption(StartupOption.ROLLBACK).build();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"previous");
    cluster.startDataNodes(conf,1,false,StartupOption.ROLLBACK,null);
    checkResult(DATA_NODE,dataNodeDirs);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("Normal BlockPool rollback",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    NameNode.doRollback(conf,false);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).dnStartupOption(StartupOption.ROLLBACK).build();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    UpgradeUtilities.createBlockPoolStorageDirs(dataNodeDirs,"current",UpgradeUtilities.getCurrentBlockPoolID(cluster));
    UpgradeUtilities.createBlockPoolStorageDirs(dataNodeDirs,"previous",UpgradeUtilities.getCurrentBlockPoolID(cluster));
    storageInfo=new StorageInfo(HdfsConstants.DATANODE_LAYOUT_VERSION - 1,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),UpgradeUtilities.getCurrentFsscTime(cluster),NodeType.DATA_NODE);
    File[] dataCurrentDirs=new File[dataNodeDirs.length];
    for (int i=0; i < dataNodeDirs.length; i++) {
      dataCurrentDirs[i]=new File((new Path(dataNodeDirs[i] + "/current")).toString());
    }
    UpgradeUtilities.createDataNodeVersionFile(dataCurrentDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    cluster.startDataNodes(conf,1,false,StartupOption.ROLLBACK,null);
    assertTrue(cluster.isDataNodeUp());
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode rollback without existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    startNameNodeShouldFail("None of the storage directories contain previous fs state");
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("DataNode rollback without existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).startupOption(StartupOption.UPGRADE).build();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    cluster.startDataNodes(conf,1,false,StartupOption.ROLLBACK,null);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode rollback with future stored layout version in previous",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    NameNode.doRollback(conf,false);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).dnStartupOption(StartupOption.ROLLBACK).build();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"previous");
    storageInfo=new StorageInfo(Integer.MIN_VALUE,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),UpgradeUtilities.getCurrentFsscTime(cluster),NodeType.DATA_NODE);
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.ROLLBACK,cluster.getNamesystem().getBlockPoolId());
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode rollback with newer fsscTime in previous",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    NameNode.doRollback(conf,false);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).dnStartupOption(StartupOption.ROLLBACK).build();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"previous");
    storageInfo=new StorageInfo(HdfsConstants.DATANODE_LAYOUT_VERSION,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),Long.MAX_VALUE,NodeType.DATA_NODE);
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.ROLLBACK,cluster.getNamesystem().getBlockPoolId());
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode rollback with no edits file",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    deleteMatchingFiles(baseDirs,"edits.*");
    startNameNodeShouldFail("Gap in transactions");
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode rollback with no image file",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    deleteMatchingFiles(baseDirs,"fsimage_.*");
    startNameNodeShouldFail("No valid image files found");
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode rollback with corrupt version file",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    for (    File f : baseDirs) {
      UpgradeUtilities.corruptFile(new File(f,"VERSION"),"layoutVersion".getBytes(Charsets.UTF_8),"xxxxxxxxxxxxx".getBytes(Charsets.UTF_8));
    }
    startNameNodeShouldFail("file VERSION has layoutVersion missing");
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode rollback with old layout version in previous",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    storageInfo=new StorageInfo(1,UpgradeUtilities.getCurrentNamespaceID(null),UpgradeUtilities.getCurrentClusterID(null),UpgradeUtilities.getCurrentFsscTime(null),NodeType.NAME_NODE);
    UpgradeUtilities.createNameNodeVersionFile(conf,baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startNameNodeShouldFail("Cannot rollback to storage version 1 using this version");
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

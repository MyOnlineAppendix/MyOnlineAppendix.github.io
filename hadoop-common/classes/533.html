<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport (2 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="7"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('7')" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls"><kbd id="tag-7"class="label-info"style="display: inline-block;font-size:7pt" >InternalCallVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="13"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('13')" data-toggle="tooltip" title="Verifies assertions in iterations"><kbd id="tag-13"class="label-info"style="display: inline-block;font-size:7pt" >IterativeVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="6"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('6')" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value "><kbd id="tag-6"class="label-info"style="display: inline-block;font-size:7pt" >EqualityVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="9"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('9')" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) "><kbd id="tag-9"class="label-info"style="display: inline-block;font-size:7pt" >APIUtilityVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="10"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('10')" data-toggle="tooltip" title="Verifies boolean conditions"><kbd id="tag-10"class="label-info"style="display: inline-block;font-size:7pt" >BooleanVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-7 type-10 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * The following test first creates a file.
 * It verifies the block information from a datanode.
 * Then, it updates the block with new information and verifies again. 
 */
@Test public void testVolumeSize() throws Exception {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  long reserved=10000;
  conf.setLong(DFSConfigKeys.DFS_DATANODE_DU_RESERVED_KEY,reserved);
  try {
    cluster=new MiniDFSCluster.Builder(conf).build();
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final DatanodeManager dm=cluster.getNamesystem().getBlockManager().getDatanodeManager();
    final List<DatanodeDescriptor> live=new ArrayList<DatanodeDescriptor>();
    final List<DatanodeDescriptor> dead=new ArrayList<DatanodeDescriptor>();
    dm.fetchDatanodes(live,dead,false);
    assertTrue(live.size() == 1);
    long used, remaining, configCapacity, nonDFSUsed, bpUsed;
    float percentUsed, percentRemaining, percentBpUsed;
    for (    final DatanodeDescriptor datanode : live) {
      used=datanode.getDfsUsed();
      remaining=datanode.getRemaining();
      nonDFSUsed=datanode.getNonDfsUsed();
      configCapacity=datanode.getCapacity();
      percentUsed=datanode.getDfsUsedPercent();
      percentRemaining=datanode.getRemainingPercent();
      bpUsed=datanode.getBlockPoolUsed();
      percentBpUsed=datanode.getBlockPoolUsedPercent();
      LOG.info("Datanode configCapacity " + configCapacity + " used "+ used+ " non DFS used "+ nonDFSUsed+ " remaining "+ remaining+ " perentUsed "+ percentUsed+ " percentRemaining "+ percentRemaining);
      assertTrue(configCapacity == (used + remaining + nonDFSUsed));
      assertTrue(percentUsed == DFSUtil.getPercentUsed(used,configCapacity));
      assertTrue(percentRemaining == DFSUtil.getPercentRemaining(remaining,configCapacity));
      assertTrue(percentBpUsed == DFSUtil.getPercentUsed(bpUsed,configCapacity));
    }
    DF df=new DF(new File(cluster.getDataDirectory()),conf);
    int numOfDataDirs=2;
    long diskCapacity=numOfDataDirs * df.getCapacity();
    reserved*=numOfDataDirs;
    configCapacity=namesystem.getCapacityTotal();
    used=namesystem.getCapacityUsed();
    nonDFSUsed=namesystem.getNonDfsUsedSpace();
    remaining=namesystem.getCapacityRemaining();
    percentUsed=namesystem.getPercentUsed();
    percentRemaining=namesystem.getPercentRemaining();
    bpUsed=namesystem.getBlockPoolUsedSpace();
    percentBpUsed=namesystem.getPercentBlockPoolUsed();
    LOG.info("Data node directory " + cluster.getDataDirectory());
    LOG.info("Name node diskCapacity " + diskCapacity + " configCapacity "+ configCapacity+ " reserved "+ reserved+ " used "+ used+ " remaining "+ remaining+ " nonDFSUsed "+ nonDFSUsed+ " remaining "+ remaining+ " percentUsed "+ percentUsed+ " percentRemaining "+ percentRemaining+ " bpUsed "+ bpUsed+ " percentBpUsed "+ percentBpUsed);
    assertTrue(configCapacity == diskCapacity - reserved);
    assertTrue(configCapacity == (used + remaining + nonDFSUsed));
    assertTrue(percentUsed == DFSUtil.getPercentUsed(used,configCapacity));
    assertTrue(percentBpUsed == DFSUtil.getPercentUsed(bpUsed,configCapacity));
    assertTrue(percentRemaining == ((float)remaining * 100.0f) / (float)configCapacity);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<pre class="type-9 type-13 type-7 type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
@Test public void testXceiverCount() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_KEY,0);
  MiniDFSCluster cluster=null;
  final int nodes=8;
  final int fileCount=5;
  final short fileRepl=3;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(nodes).build();
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final DatanodeManager dnm=namesystem.getBlockManager().getDatanodeManager();
    List<DataNode> datanodes=cluster.getDataNodes();
    final DistributedFileSystem fs=cluster.getFileSystem();
    triggerHeartbeats(datanodes);
    int expectedTotalLoad=nodes;
    int expectedInServiceNodes=nodes;
    int expectedInServiceLoad=nodes;
    assertEquals(nodes,namesystem.getNumLiveDataNodes());
    assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
    assertEquals(expectedTotalLoad,namesystem.getTotalLoad());
    assertEquals((double)expectedInServiceLoad / expectedInServiceLoad,namesystem.getInServiceXceiverAverage(),EPSILON);
    for (int i=0; i < nodes / 2; i++) {
      DataNode dn=datanodes.get(i);
      DatanodeDescriptor dnd=dnm.getDatanode(dn.getDatanodeId());
      dn.shutdown();
      dnd.setLastUpdate(0L);
      BlockManagerTestUtil.checkHeartbeat(namesystem.getBlockManager());
      expectedInServiceNodes--;
      assertEquals(expectedInServiceNodes,namesystem.getNumLiveDataNodes());
      assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
    }
    cluster.restartDataNodes();
    cluster.waitActive();
    datanodes=cluster.getDataNodes();
    expectedInServiceNodes=nodes;
    assertEquals(nodes,datanodes.size());
    assertEquals(nodes,namesystem.getNumLiveDataNodes());
    assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
    assertEquals(expectedTotalLoad,namesystem.getTotalLoad());
    assertEquals((double)expectedInServiceLoad / expectedInServiceLoad,namesystem.getInServiceXceiverAverage(),EPSILON);
    DFSOutputStream[] streams=new DFSOutputStream[fileCount];
    for (int i=0; i < fileCount; i++) {
      streams[i]=(DFSOutputStream)fs.create(new Path("/f" + i),fileRepl).getWrappedStream();
      streams[i].write("1".getBytes());
      streams[i].hsync();
      expectedTotalLoad+=2 * fileRepl;
      expectedInServiceLoad+=2 * fileRepl;
    }
    triggerHeartbeats(datanodes);
    assertEquals(nodes,namesystem.getNumLiveDataNodes());
    assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
    assertEquals(expectedTotalLoad,namesystem.getTotalLoad());
    assertEquals((double)expectedInServiceLoad / expectedInServiceNodes,namesystem.getInServiceXceiverAverage(),EPSILON);
    for (int i=0; i < fileRepl; i++) {
      expectedInServiceNodes--;
      DatanodeDescriptor dnd=dnm.getDatanode(datanodes.get(i).getDatanodeId());
      expectedInServiceLoad-=dnd.getXceiverCount();
      dnm.startDecommission(dnd);
      DataNodeTestUtils.triggerHeartbeat(datanodes.get(i));
      Thread.sleep(100);
      assertEquals(nodes,namesystem.getNumLiveDataNodes());
      assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
      assertEquals(expectedTotalLoad,namesystem.getTotalLoad());
      assertEquals((double)expectedInServiceLoad / expectedInServiceNodes,namesystem.getInServiceXceiverAverage(),EPSILON);
    }
    for (int i=0; i < fileCount; i++) {
      int decomm=0;
      for (      DatanodeInfo dni : streams[i].getPipeline()) {
        DatanodeDescriptor dnd=dnm.getDatanode(dni);
        expectedTotalLoad-=2;
        if (dnd.isDecommissionInProgress() || dnd.isDecommissioned()) {
          decomm++;
        }
 else {
          expectedInServiceLoad-=2;
        }
      }
      try {
        streams[i].close();
      }
 catch (      IOException ioe) {
        if (decomm < fileRepl) {
          throw ioe;
        }
      }
      triggerHeartbeats(datanodes);
      assertEquals(nodes,namesystem.getNumLiveDataNodes());
      assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
      assertEquals(expectedTotalLoad,namesystem.getTotalLoad());
      assertEquals((double)expectedInServiceLoad / expectedInServiceNodes,namesystem.getInServiceXceiverAverage(),EPSILON);
    }
    for (int i=0; i < nodes; i++) {
      DataNode dn=datanodes.get(i);
      dn.shutdown();
      DatanodeDescriptor dnDesc=dnm.getDatanode(dn.getDatanodeId());
      dnDesc.setLastUpdate(0L);
      BlockManagerTestUtil.checkHeartbeat(namesystem.getBlockManager());
      assertEquals(nodes - 1 - i,namesystem.getNumLiveDataNodes());
      if (i >= fileRepl) {
        expectedInServiceNodes--;
      }
      assertEquals(expectedInServiceNodes,namesystem.getNumDatanodesInService());
      double expectedXceiverAvg=(i == nodes - 1) ? 0.0 : 1.0;
      assertEquals((double)expectedXceiverAvg,namesystem.getInServiceXceiverAverage(),EPSILON);
    }
    assertEquals(0,namesystem.getNumLiveDataNodes());
    assertEquals(0,namesystem.getNumDatanodesInService());
    assertEquals(0.0,namesystem.getTotalLoad(),EPSILON);
    assertEquals(0.0,namesystem.getInServiceXceiverAverage(),EPSILON);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

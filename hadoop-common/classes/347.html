<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestWriteBlockGetsBlockLengthHint (1 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void blockLengthHintIsPropagated() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  final Path path=new Path("/" + METHOD_NAME + ".dat");
  Configuration conf=new HdfsConfiguration();
  FsDatasetChecker.setFactory(conf);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DEFAULT_BLOCK_LENGTH);
  conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  try {
    cluster.waitActive();
    DFSTestUtil.createFile(cluster.getFileSystem(),path,4096,EXPECTED_BLOCK_LENGTH,EXPECTED_BLOCK_LENGTH,(short)1,0x1BAD5EED);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

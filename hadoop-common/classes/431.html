<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure (3 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(1)</kbd></button>&nbsp;<button id="18"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('18')" data-toggle="tooltip" title="Invokes logging operations"><kbd id="tag-18"class="label-info"style="display: inline-block;font-size:7pt" >Logger&nbsp;(1)</kbd></button>&nbsp;<button id="4"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('4')" data-toggle="tooltip" title="Releases resources used by the test cases"><kbd id="tag-4"class="label-info"style="display: inline-block;font-size:7pt" >TestCleaner&nbsp;(1)</kbd></button>&nbsp;<button id="8"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('8')" data-toggle="tooltip" title="Allocates resources before the execution of the test cases"><kbd id="tag-8"class="label-info"style="display: inline-block;font-size:7pt" >TestInitializer&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
"></span><br>
@Before public void setUp() throws Exception {
  conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,block_size);
  conf.setInt(DFSConfigKeys.DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY,1);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(dn_num).build();
  cluster.waitActive();
}

</code></pre>

<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testVolumeFailure() throws Exception {
  FileSystem fs=cluster.getFileSystem();
  dataDir=new File(cluster.getDataDirectory());
  System.out.println("Data dir: is " + dataDir.getPath());
  String filename="/test.txt";
  Path filePath=new Path(filename);
  int filesize=block_size * blocks_num;
  DFSTestUtil.createFile(fs,filePath,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,filePath,repl);
  System.out.println("file " + filename + "(size "+ filesize+ ") is created and replicated");
  data_fail=new File(dataDir,"data3");
  failedDir=MiniDFSCluster.getFinalizedDir(dataDir,cluster.getNamesystem().getBlockPoolId());
  if (failedDir.exists() && !deteteBlocks(failedDir)) {
    throw new IOException("Could not delete hdfs directory '" + failedDir + "'");
  }
  data_fail.setReadOnly();
  failedDir.setReadOnly();
  System.out.println("Deleteing " + failedDir.getPath() + "; exist="+ failedDir.exists());
  triggerFailure(filename,filesize);
  DataNode dn=cluster.getDataNodes().get(1);
  String bpid=cluster.getNamesystem().getBlockPoolId();
  DatanodeRegistration dnR=dn.getDNRegistrationForBP(bpid);
  Map<DatanodeStorage,BlockListAsLongs> perVolumeBlockLists=dn.getFSDataset().getBlockReports(bpid);
  StorageBlockReport[] reports=new StorageBlockReport[perVolumeBlockLists.size()];
  int reportIndex=0;
  for (  Map.Entry<DatanodeStorage,BlockListAsLongs> kvPair : perVolumeBlockLists.entrySet()) {
    DatanodeStorage dnStorage=kvPair.getKey();
    BlockListAsLongs blockList=kvPair.getValue();
    reports[reportIndex++]=new StorageBlockReport(dnStorage,blockList.getBlockListAsLongs());
  }
  cluster.getNameNodeRpc().blockReport(dnR,bpid,reports);
  verify(filename,filesize);
  System.out.println("creating file test1.txt");
  Path fileName1=new Path("/test1.txt");
  DFSTestUtil.createFile(fs,fileName1,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,fileName1,repl);
  System.out.println("file " + fileName1.getName() + " is created and replicated");
}

</code></pre>

<pre class="type-4 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
"></span><br>
@After public void tearDown() throws Exception {
  if (data_fail != null) {
    FileUtil.setWritable(data_fail,true);
  }
  if (failedDir != null) {
    FileUtil.setWritable(failedDir,true);
  }
  if (cluster != null) {
    cluster.shutdown();
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend (7 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(3)</kbd></button>&nbsp;<button id="7"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('7')" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls"><kbd id="tag-7"class="label-info"style="display: inline-block;font-size:7pt" >InternalCallVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="18"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('18')" data-toggle="tooltip" title="Invokes logging operations"><kbd id="tag-18"class="label-info"style="display: inline-block;font-size:7pt" >Logger&nbsp;(2)</kbd></button>&nbsp;<button id="6"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('6')" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value "><kbd id="tag-6"class="label-info"style="display: inline-block;font-size:7pt" >EqualityVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="2"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('2')" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure"><kbd id="tag-2"class="label-info"style="display: inline-block;font-size:7pt" >UtilityVerifier&nbsp;(2)</kbd></button>&nbsp;<button id="3"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('3')" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes"><kbd id="tag-3"class="label-info"style="display: inline-block;font-size:7pt" >HybridVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="11"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('11')" data-toggle="tooltip" title="Verifies assertions inside branch conditions"><kbd id="tag-11"class="label-info"style="display: inline-block;font-size:7pt" >BranchVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="9"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('9')" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) "><kbd id="tag-9"class="label-info"style="display: inline-block;font-size:7pt" >APIUtilityVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="10"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('10')" data-toggle="tooltip" title="Verifies boolean conditions"><kbd id="tag-10"class="label-info"style="display: inline-block;font-size:7pt" >BooleanVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="13"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('13')" data-toggle="tooltip" title="Verifies assertions in iterations"><kbd id="tag-13"class="label-info"style="display: inline-block;font-size:7pt" >IterativeVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="14"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('14')" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution"><kbd id="tag-14"class="label-info"style="display: inline-block;font-size:7pt" >ExceptionVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-14 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies that exceptions are thrown during the test case execution
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * FileNotFoundException is expected for appending to a non-exisiting file
 * @throws FileNotFoundException as the result
 */
@Test(expected=FileNotFoundException.class) public void testFileNotFound() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/nonexistingfile.dat");
    fs.append(file1);
  }
  finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-7 type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Tests appending after soft-limit expires. 
 */
@Test public void testAppendAfterSoftLimit() throws IOException, InterruptedException {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_REPLICATION_KEY,1);
  final long softLimit=1L;
  final long hardLimit=9999999L;
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  cluster.setLeasePeriod(softLimit,hardLimit);
  cluster.waitActive();
  FileSystem fs=cluster.getFileSystem();
  FileSystem fs2=new DistributedFileSystem();
  fs2.initialize(fs.getUri(),conf);
  final Path testPath=new Path("/testAppendAfterSoftLimit");
  final byte[] fileContents=AppendTestUtil.initBuffer(32);
  FSDataOutputStream out=fs.create(testPath);
  out.write(fileContents);
  Thread.sleep(250);
  try {
    FSDataOutputStream appendStream2=fs2.append(testPath);
    appendStream2.write(fileContents);
    appendStream2.close();
    assertEquals(fileContents.length,fs.getFileStatus(testPath).getLen());
  }
  finally {
    fs.close();
    fs2.close();
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-11 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * Old replica of the block should not be accepted as valid for append/read
 */
@Test public void testFailedAppendBlockRejection() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.set("dfs.client.block.write.replace-datanode-on-failure.enable","false");
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  DistributedFileSystem fs=null;
  try {
    fs=cluster.getFileSystem();
    Path path=new Path("/test");
    FSDataOutputStream out=fs.create(path);
    out.writeBytes("hello\n");
    out.close();
    DataNodeProperties dnProp=cluster.stopDataNode(0);
    String dnAddress=dnProp.datanode.getXferAddress().toString();
    if (dnAddress.startsWith("/")) {
      dnAddress=dnAddress.substring(1);
    }
    for (int i=0; i < 2; i++) {
      out=fs.append(path);
      out.writeBytes("helloagain\n");
      out.close();
    }
    out=fs.append(path);
    cluster.restartDataNode(dnProp,true);
    Thread.sleep(2000);
    BlockLocation[] locations=fs.getFileBlockLocations(path,0,Long.MAX_VALUE);
    String[] names=locations[0].getNames();
    for (    String node : names) {
      if (node.equals(dnAddress)) {
        fail("Failed append should not be present in latest block locations.");
      }
    }
    out.close();
  }
  finally {
    IOUtils.closeStream(fs);
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-2 type-6 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test two consecutive appends on a file with a full block. 
 */
@Test public void testAppendTwice() throws Exception {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  final FileSystem fs1=cluster.getFileSystem();
  final FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(conf);
  try {
    final Path p=new Path("/testAppendTwice/foo");
    final int len=1 << 16;
    final byte[] fileContents=AppendTestUtil.initBuffer(len);
{
      FSDataOutputStream out=fs2.create(p,true,4096,(short)1,len);
      out.write(fileContents,0,len);
      out.close();
    }
    fs2.append(p);
    fs1.append(p);
    Assert.fail();
  }
 catch (  RemoteException re) {
    AppendTestUtil.LOG.info("Got an exception:",re);
    Assert.assertEquals(AlreadyBeingCreatedException.class.getName(),re.getClassName());
  }
 finally {
    fs2.close();
    fs1.close();
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test a simple flush on a simple HDFS file.
 * @throws IOException an exception might be thrown
 */
@Test public void testSimpleFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/simpleFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file simpleFlush.dat");
    int mid=AppendTestUtil.FILE_SIZE / 2;
    stm.write(fileContents,0,mid);
    stm.hflush();
    System.out.println("Wrote and Flushed first part of file.");
    stm.write(fileContents,mid,AppendTestUtil.FILE_SIZE - mid);
    System.out.println("Written second part of file");
    stm.hflush();
    stm.hflush();
    System.out.println("Wrote and Flushed second part of file.");
    checkFile(fs,file1,1);
    stm.close();
    System.out.println("Closed file.");
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-18 type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test that file data can be flushed.
 * @throws IOException an exception might be thrown
 */
@Test public void testComplexFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/complexFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file complexFlush.dat");
    int start=0;
    for (start=0; (start + 29) < AppendTestUtil.FILE_SIZE; ) {
      stm.write(fileContents,start,29);
      stm.hflush();
      start+=29;
    }
    stm.write(fileContents,start,AppendTestUtil.FILE_SIZE - start);
    checkFile(fs,file1,1);
    stm.close();
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-9 type-13 type-7 type-10 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test that copy on write for blocks works correctly
 * @throws IOException an exception might be thrown
 */
@Test public void testCopyOnWrite() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
  DFSClient client=new DFSClient(addr,conf);
  try {
    Path file1=new Path("/filestatus.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    writeFile(stm);
    stm.close();
    DataNode[] dn=cluster.listDataNodes();
    assertTrue("There should be only one datanode but found " + dn.length,dn.length == 1);
    LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
    List<LocatedBlock> blocks=locations.getLocatedBlocks();
    for (int i=0; i < blocks.size(); i=i + 2) {
      ExtendedBlock b=blocks.get(i).getBlock();
      final File f=DataNodeTestUtils.getFile(dn[0],b.getBlockPoolId(),b.getLocalBlock().getBlockId());
      File link=new File(f.toString() + ".link");
      System.out.println("Creating hardlink for File " + f + " to "+ link);
      HardLink.createHardLink(f,link);
    }
    for (int i=0; i < blocks.size(); i++) {
      ExtendedBlock b=blocks.get(i).getBlock();
      System.out.println("testCopyOnWrite detaching block " + b);
      assertTrue("Detaching block " + b + " should have returned true",DataNodeTestUtils.unlinkBlock(dn[0],b,1));
    }
    for (int i=0; i < blocks.size(); i++) {
      ExtendedBlock b=blocks.get(i).getBlock();
      System.out.println("testCopyOnWrite detaching block " + b);
      assertTrue("Detaching block " + b + " should have returned false",!DataNodeTestUtils.unlinkBlock(dn[0],b,1));
    }
  }
  finally {
    client.close();
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

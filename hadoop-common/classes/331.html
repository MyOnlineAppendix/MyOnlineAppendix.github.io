<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestReadWhileWriting (1 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test reading while writing. 
 */
@Test public void pipeline_02_03() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
  try {
    cluster.setLeasePeriod(SOFT_LEASE_LIMIT,HARD_LEASE_LIMIT);
    cluster.waitActive();
    final FileSystem fs=cluster.getFileSystem();
    final Path p=new Path(DIR,"file1");
    final int half=BLOCK_SIZE / 2;
{
      final FSDataOutputStream out=fs.create(p,true,fs.getConf().getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096),(short)3,BLOCK_SIZE);
      write(out,0,half);
      ((DFSOutputStream)out.getWrappedStream()).hflush();
    }
    checkFile(p,half,conf);
    AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
    ((DistributedFileSystem)fs).dfs.getLeaseRenewer().interruptAndJoin();
{
      Thread.sleep(2 * SOFT_LEASE_LIMIT);
      final UserGroupInformation current=UserGroupInformation.getCurrentUser();
      final UserGroupInformation ugi=UserGroupInformation.createUserForTesting(current.getShortUserName() + "x",new String[]{"supergroup"});
      final DistributedFileSystem dfs=ugi.doAs(new PrivilegedExceptionAction<DistributedFileSystem>(){
        @Override public DistributedFileSystem run() throws Exception {
          return (DistributedFileSystem)FileSystem.newInstance(conf);
        }
      }
);
      final FSDataOutputStream out=append(dfs,p);
      write(out,0,half);
      out.close();
    }
    checkFile(p,2 * half,conf);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

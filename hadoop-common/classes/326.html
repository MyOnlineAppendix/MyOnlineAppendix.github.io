<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestPersistBlocks (5 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="6"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('6')" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value "><kbd id="tag-6"class="label-info"style="display: inline-block;font-size:7pt" >EqualityVerifier&nbsp;(3)</kbd></button>&nbsp;<button id="20"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('20')" data-toggle="tooltip" title="Verifies values related to public fields."><kbd id="tag-20"class="label-info"style="display: inline-block;font-size:7pt" >PublicFieldVerifier&nbsp;(3)</kbd></button>&nbsp;<button id="7"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('7')" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls"><kbd id="tag-7"class="label-info"style="display: inline-block;font-size:7pt" >InternalCallVerifier&nbsp;(3)</kbd></button>&nbsp;<button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(2)</kbd></button>&nbsp;<button id="3"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('3')" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes"><kbd id="tag-3"class="label-info"style="display: inline-block;font-size:7pt" >HybridVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="9"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('9')" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) "><kbd id="tag-9"class="label-info"style="display: inline-block;font-size:7pt" >APIUtilityVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="10"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('10')" data-toggle="tooltip" title="Verifies boolean conditions"><kbd id="tag-10"class="label-info"style="display: inline-block;font-size:7pt" >BooleanVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-9 type-7 type-10 type-6 type-20 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRestartDfsWithAbandonedBlock() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,0);
  MiniDFSCluster cluster=null;
  long len=0;
  FSDataOutputStream stream;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    FileSystem fs=cluster.getFileSystem();
    stream=fs.create(FILE_PATH,true,BLOCK_SIZE,(short)1,BLOCK_SIZE);
    stream.write(DATA_BEFORE_RESTART);
    stream.hflush();
    while (len < BLOCK_SIZE * (NUM_BLOCKS - 1)) {
      FileStatus status=fs.getFileStatus(FILE_PATH);
      len=status.getLen();
      Thread.sleep(100);
    }
    DFSClient dfsclient=DFSClientAdapter.getDFSClient((DistributedFileSystem)fs);
    HdfsFileStatus fileStatus=dfsclient.getNamenode().getFileInfo(FILE_NAME);
    LocatedBlocks blocks=dfsclient.getNamenode().getBlockLocations(FILE_NAME,0,BLOCK_SIZE * NUM_BLOCKS);
    assertEquals(NUM_BLOCKS,blocks.getLocatedBlocks().size());
    LocatedBlock b=blocks.getLastLocatedBlock();
    dfsclient.getNamenode().abandonBlock(b.getBlock(),fileStatus.getFileId(),FILE_NAME,dfsclient.clientName);
    cluster.restartNameNode();
    FileStatus status=fs.getFileStatus(FILE_PATH);
    assertTrue("Length incorrect: " + status.getLen(),status.getLen() == len - BLOCK_SIZE);
    FSDataInputStream readStream=fs.open(FILE_PATH);
    try {
      byte[] verifyBuf=new byte[DATA_BEFORE_RESTART.length - BLOCK_SIZE];
      IOUtils.readFully(readStream,verifyBuf,0,verifyBuf.length);
      byte[] expectedBuf=new byte[DATA_BEFORE_RESTART.length - BLOCK_SIZE];
      System.arraycopy(DATA_BEFORE_RESTART,0,expectedBuf,0,expectedBuf.length);
      assertArrayEquals(expectedBuf,verifyBuf);
    }
  finally {
      IOUtils.closeStream(readStream);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * check if DFS remains in proper condition after a restart 
 */
@Test public void TestRestartDfsWithFlush() throws Exception {
  testRestartDfs(true);
}

</code></pre>

<pre class="type-7 type-6 type-20 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
"></span><br>
@Test public void testRestartWithPartialBlockHflushed() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,0);
  MiniDFSCluster cluster=null;
  FSDataOutputStream stream;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    FileSystem fs=cluster.getFileSystem();
    NameNode.getAddress(conf).getPort();
    stream=fs.create(FILE_PATH,true,BLOCK_SIZE,(short)1,BLOCK_SIZE);
    stream.write(DATA_BEFORE_RESTART);
    stream.write((byte)1);
    stream.hflush();
    cluster.restartNameNode();
    stream.write((byte)2);
    stream.hflush();
    stream.close();
    assertEquals(DATA_BEFORE_RESTART.length + 2,fs.getFileStatus(FILE_PATH).getLen());
    FSDataInputStream readStream=fs.open(FILE_PATH);
    try {
      byte[] verifyBuf=new byte[DATA_BEFORE_RESTART.length + 2];
      IOUtils.readFully(readStream,verifyBuf,0,verifyBuf.length);
      byte[] expectedBuf=new byte[DATA_BEFORE_RESTART.length + 2];
      System.arraycopy(DATA_BEFORE_RESTART,0,expectedBuf,0,DATA_BEFORE_RESTART.length);
      System.arraycopy(new byte[]{1,2},0,expectedBuf,DATA_BEFORE_RESTART.length,2);
      assertArrayEquals(expectedBuf,verifyBuf);
    }
  finally {
      IOUtils.closeStream(readStream);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Earlier versions of HDFS didn't persist block allocation to the edit log.
 * This makes sure that we can still load an edit log when the OP_CLOSE
 * is the opcode which adds all of the blocks. This is a regression
 * test for HDFS-2773.
 * This test uses a tarred pseudo-distributed cluster from Hadoop 1.0
 * which has a multi-block file. This is similar to the tests in{@link TestDFSUpgradeFromImage} but none of those images include
 * a multi-block file.
 */
@Test public void testEarlierVersionEditLog() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  String tarFile=System.getProperty("test.cache.data","build/test/cache") + "/" + HADOOP_1_0_MULTIBLOCK_TGZ;
  String testDir=PathUtils.getTestDirName(getClass());
  File dfsDir=new File(testDir,"image-1.0");
  if (dfsDir.exists() && !FileUtil.fullyDelete(dfsDir)) {
    throw new IOException("Could not delete dfs directory '" + dfsDir + "'");
  }
  FileUtil.unTar(new File(tarFile),new File(testDir));
  File nameDir=new File(dfsDir,"name");
  GenericTestUtils.assertExists(nameDir);
  File dataDir=new File(dfsDir,"data");
  GenericTestUtils.assertExists(dataDir);
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameDir.getAbsolutePath());
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dataDir.getAbsolutePath());
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).numDataNodes(1).startupOption(StartupOption.UPGRADE).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    Path testPath=new Path("/user/todd/4blocks");
    DFSTestUtil.readFile(fs,testPath);
    FSDataOutputStream stm=fs.append(testPath);
    try {
      stm.write(1);
    }
  finally {
      IOUtils.closeStream(stm);
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-7 type-6 type-20 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
"></span><br>
@Test public void testRestartWithAppend() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,0);
  MiniDFSCluster cluster=null;
  FSDataOutputStream stream;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    FileSystem fs=cluster.getFileSystem();
    NameNode.getAddress(conf).getPort();
    stream=fs.create(FILE_PATH,true,BLOCK_SIZE,(short)1,BLOCK_SIZE);
    stream.write(DATA_BEFORE_RESTART,0,DATA_BEFORE_RESTART.length / 2);
    stream.close();
    stream=fs.append(FILE_PATH,BLOCK_SIZE);
    stream.write(DATA_BEFORE_RESTART,DATA_BEFORE_RESTART.length / 2,DATA_BEFORE_RESTART.length / 2);
    stream.close();
    assertEquals(DATA_BEFORE_RESTART.length,fs.getFileStatus(FILE_PATH).getLen());
    cluster.restartNameNode();
    assertEquals(DATA_BEFORE_RESTART.length,fs.getFileStatus(FILE_PATH).getLen());
    FSDataInputStream readStream=fs.open(FILE_PATH);
    try {
      byte[] verifyBuf=new byte[DATA_BEFORE_RESTART.length];
      IOUtils.readFully(readStream,verifyBuf,0,verifyBuf.length);
      assertArrayEquals(DATA_BEFORE_RESTART,verifyBuf);
    }
  finally {
      IOUtils.closeStream(readStream);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

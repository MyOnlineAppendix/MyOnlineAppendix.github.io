<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFiHFlush (9 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="5"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('5')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-5"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(9)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_b()} but for a pipeline's 2nd datanode
 */
@Test public void hFlushFi03_b() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=512;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,2),2,true);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_c()} but for a pipeline's 2nd datanode
 */
@Test public void hFlushFi03_c() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=400;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,2),2,true);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_a()} but for a pipeline's 2nd datanode
 */
@Test public void hFlushFi03_a() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  runDiskErrorTest(new HdfsConfiguration(),methodName,AppendTestUtil.BLOCK_SIZE,new DerrAction(methodName,2),2,false);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_b()} but writing happens
 * across block and checksum's boundaries
 */
@Test public void hFlushFi01_c() throws Exception {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=400;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,0),0,true);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * The tests calls {@link #runDiskErrorTest(Configuration,String,int,DerrAction,int,boolean)}to make a number of writes across a block boundaries.
 * hflush() is called after each write() during a pipeline life time.
 * Thus, injected fault ought to be triggered for 0th datanode
 */
@Test public void hFlushFi01_b() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=512;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,0),0,true);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * The tests calls {@link #runDiskErrorTest(Configuration,String,int,DerrAction,int,boolean)}to make a number of writes within a block boundaries.
 * Although hflush() is called the test shouldn't expect an IOException
 * in this case because the invocation is happening after write() call 
 * is complete when pipeline doesn't exist anymore.
 * Thus, injected fault won't be triggered for 0th datanode
 */
@Test public void hFlushFi01_a() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  runDiskErrorTest(new HdfsConfiguration(),methodName,AppendTestUtil.BLOCK_SIZE,new DerrAction(methodName,0),0,false);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_a()} but for a pipeline's 1st datanode
 */
@Test public void hFlushFi02_a() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  runDiskErrorTest(new HdfsConfiguration(),methodName,AppendTestUtil.BLOCK_SIZE,new DerrAction(methodName,1),1,false);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_c()} but for a pipeline's 1st datanode
 */
@Test public void hFlushFi02_c() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=400;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,1),1,true);
}

</code></pre>

<pre class="type-5 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Similar to {@link #hFlushFi01_b()} but for a pipeline's 1st datanode
 */
@Test public void hFlushFi02_b() throws IOException {
  final String methodName=FiTestUtil.getMethodName();
  Configuration conf=new HdfsConfiguration();
  int customPerChecksumSize=512;
  int customBlockSize=customPerChecksumSize * 3;
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,customPerChecksumSize);
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,customBlockSize);
  runDiskErrorTest(conf,methodName,customBlockSize,new DerrAction(methodName,1),1,true);
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

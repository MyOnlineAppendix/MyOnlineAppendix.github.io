<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling (2 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="6"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('6')" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value "><kbd id="tag-6"class="label-info"style="display: inline-block;font-size:7pt" >EqualityVerifier&nbsp;(2)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Test if{@link FSNamesystem#handleHeartbeat}can pick up replication and/or invalidate requests and observes the max
 * limit
 */
@Test public void testHeartbeat() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  try {
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final HeartbeatManager hm=namesystem.getBlockManager().getDatanodeManager().getHeartbeatManager();
    final String poolId=namesystem.getBlockPoolId();
    final DatanodeRegistration nodeReg=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(0),poolId);
    final DatanodeDescriptor dd=NameNodeAdapter.getDatanode(namesystem,nodeReg);
    final String storageID=DatanodeStorage.generateUuid();
    dd.updateStorage(new DatanodeStorage(storageID));
    final int REMAINING_BLOCKS=1;
    final int MAX_REPLICATE_LIMIT=conf.getInt(DFSConfigKeys.DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY,2);
    final int MAX_INVALIDATE_LIMIT=DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT;
    final int MAX_INVALIDATE_BLOCKS=2 * MAX_INVALIDATE_LIMIT + REMAINING_BLOCKS;
    final int MAX_REPLICATE_BLOCKS=2 * MAX_REPLICATE_LIMIT + REMAINING_BLOCKS;
    final DatanodeStorageInfo[] ONE_TARGET={dd.getStorageInfo(storageID)};
    try {
      namesystem.writeLock();
synchronized (hm) {
        for (int i=0; i < MAX_REPLICATE_BLOCKS; i++) {
          dd.addBlockToBeReplicated(new Block(i,0,GenerationStamp.LAST_RESERVED_STAMP),ONE_TARGET);
        }
        DatanodeCommand[] cmds=NameNodeAdapter.sendHeartBeat(nodeReg,dd,namesystem).getCommands();
        assertEquals(1,cmds.length);
        assertEquals(DatanodeProtocol.DNA_TRANSFER,cmds[0].getAction());
        assertEquals(MAX_REPLICATE_LIMIT,((BlockCommand)cmds[0]).getBlocks().length);
        ArrayList<Block> blockList=new ArrayList<Block>(MAX_INVALIDATE_BLOCKS);
        for (int i=0; i < MAX_INVALIDATE_BLOCKS; i++) {
          blockList.add(new Block(i,0,GenerationStamp.LAST_RESERVED_STAMP));
        }
        dd.addBlocksToBeInvalidated(blockList);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg,dd,namesystem).getCommands();
        assertEquals(2,cmds.length);
        assertEquals(DatanodeProtocol.DNA_TRANSFER,cmds[0].getAction());
        assertEquals(MAX_REPLICATE_LIMIT,((BlockCommand)cmds[0]).getBlocks().length);
        assertEquals(DatanodeProtocol.DNA_INVALIDATE,cmds[1].getAction());
        assertEquals(MAX_INVALIDATE_LIMIT,((BlockCommand)cmds[1]).getBlocks().length);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg,dd,namesystem).getCommands();
        assertEquals(2,cmds.length);
        assertEquals(DatanodeProtocol.DNA_TRANSFER,cmds[0].getAction());
        assertEquals(REMAINING_BLOCKS,((BlockCommand)cmds[0]).getBlocks().length);
        assertEquals(DatanodeProtocol.DNA_INVALIDATE,cmds[1].getAction());
        assertEquals(MAX_INVALIDATE_LIMIT,((BlockCommand)cmds[1]).getBlocks().length);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg,dd,namesystem).getCommands();
        assertEquals(1,cmds.length);
        assertEquals(DatanodeProtocol.DNA_INVALIDATE,cmds[0].getAction());
        assertEquals(REMAINING_BLOCKS,((BlockCommand)cmds[0]).getBlocks().length);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg,dd,namesystem).getCommands();
        assertEquals(0,cmds.length);
      }
    }
  finally {
      namesystem.writeUnlock();
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<pre class="type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Test if{@link FSNamesystem#handleHeartbeat}correctly selects data node targets for block recovery.
 */
@Test public void testHeartbeatBlockRecovery() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  try {
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final HeartbeatManager hm=namesystem.getBlockManager().getDatanodeManager().getHeartbeatManager();
    final String poolId=namesystem.getBlockPoolId();
    final DatanodeRegistration nodeReg1=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(0),poolId);
    final DatanodeDescriptor dd1=NameNodeAdapter.getDatanode(namesystem,nodeReg1);
    dd1.updateStorage(new DatanodeStorage(DatanodeStorage.generateUuid()));
    final DatanodeRegistration nodeReg2=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(1),poolId);
    final DatanodeDescriptor dd2=NameNodeAdapter.getDatanode(namesystem,nodeReg2);
    dd2.updateStorage(new DatanodeStorage(DatanodeStorage.generateUuid()));
    final DatanodeRegistration nodeReg3=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(2),poolId);
    final DatanodeDescriptor dd3=NameNodeAdapter.getDatanode(namesystem,nodeReg3);
    dd3.updateStorage(new DatanodeStorage(DatanodeStorage.generateUuid()));
    try {
      namesystem.writeLock();
synchronized (hm) {
        NameNodeAdapter.sendHeartBeat(nodeReg1,dd1,namesystem);
        NameNodeAdapter.sendHeartBeat(nodeReg2,dd2,namesystem);
        NameNodeAdapter.sendHeartBeat(nodeReg3,dd3,namesystem);
        dd1.setLastUpdate(System.currentTimeMillis());
        dd2.setLastUpdate(System.currentTimeMillis());
        dd3.setLastUpdate(System.currentTimeMillis());
        final DatanodeStorageInfo[] storages={dd1.getStorageInfos()[0],dd2.getStorageInfos()[0],dd3.getStorageInfos()[0]};
        BlockInfoUnderConstruction blockInfo=new BlockInfoUnderConstruction(new Block(0,0,GenerationStamp.LAST_RESERVED_STAMP),3,BlockUCState.UNDER_RECOVERY,storages);
        dd1.addBlockToBeRecovered(blockInfo);
        DatanodeCommand[] cmds=NameNodeAdapter.sendHeartBeat(nodeReg1,dd1,namesystem).getCommands();
        assertEquals(1,cmds.length);
        assertEquals(DatanodeProtocol.DNA_RECOVERBLOCK,cmds[0].getAction());
        BlockRecoveryCommand recoveryCommand=(BlockRecoveryCommand)cmds[0];
        assertEquals(1,recoveryCommand.getRecoveringBlocks().size());
        DatanodeInfo[] recoveringNodes=recoveryCommand.getRecoveringBlocks().toArray(new BlockRecoveryCommand.RecoveringBlock[0])[0].getLocations();
        assertEquals(3,recoveringNodes.length);
        assertEquals(recoveringNodes[0],dd1);
        assertEquals(recoveringNodes[1],dd2);
        assertEquals(recoveringNodes[2],dd3);
        dd1.setLastUpdate(System.currentTimeMillis());
        dd2.setLastUpdate(System.currentTimeMillis() - 40 * 1000);
        dd3.setLastUpdate(System.currentTimeMillis());
        blockInfo=new BlockInfoUnderConstruction(new Block(0,0,GenerationStamp.LAST_RESERVED_STAMP),3,BlockUCState.UNDER_RECOVERY,storages);
        dd1.addBlockToBeRecovered(blockInfo);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg1,dd1,namesystem).getCommands();
        assertEquals(1,cmds.length);
        assertEquals(DatanodeProtocol.DNA_RECOVERBLOCK,cmds[0].getAction());
        recoveryCommand=(BlockRecoveryCommand)cmds[0];
        assertEquals(1,recoveryCommand.getRecoveringBlocks().size());
        recoveringNodes=recoveryCommand.getRecoveringBlocks().toArray(new BlockRecoveryCommand.RecoveringBlock[0])[0].getLocations();
        assertEquals(2,recoveringNodes.length);
        assertEquals(recoveringNodes[0],dd1);
        assertEquals(recoveringNodes[1],dd3);
        dd1.setLastUpdate(System.currentTimeMillis() - 60 * 1000);
        dd2.setLastUpdate(System.currentTimeMillis() - 40 * 1000);
        dd3.setLastUpdate(System.currentTimeMillis() - 80 * 1000);
        blockInfo=new BlockInfoUnderConstruction(new Block(0,0,GenerationStamp.LAST_RESERVED_STAMP),3,BlockUCState.UNDER_RECOVERY,storages);
        dd1.addBlockToBeRecovered(blockInfo);
        cmds=NameNodeAdapter.sendHeartBeat(nodeReg1,dd1,namesystem).getCommands();
        assertEquals(1,cmds.length);
        assertEquals(DatanodeProtocol.DNA_RECOVERBLOCK,cmds[0].getAction());
        recoveryCommand=(BlockRecoveryCommand)cmds[0];
        assertEquals(1,recoveryCommand.getRecoveringBlocks().size());
        recoveringNodes=recoveryCommand.getRecoveringBlocks().toArray(new BlockRecoveryCommand.RecoveringBlock[0])[0].getLocations();
        assertEquals(3,recoveringNodes.length);
        assertEquals(recoveringNodes[0],dd1);
        assertEquals(recoveringNodes[1],dd2);
        assertEquals(recoveringNodes[2],dd3);
      }
    }
  finally {
      namesystem.writeUnlock();
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

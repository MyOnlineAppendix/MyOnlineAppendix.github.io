<h3><span class=" glyphicon glyphicon-tag"/>&nbspBooleanVerifier</h3><kbd>Verifies boolean conditions</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.conf.TestJobConf </h4><pre class="type-4 type-7 type-6 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testProfileParamsDefaults(){
  JobConf configuration=new JobConf();
  Assert.assertNull(configuration.get(MRJobConfig.TASK_PROFILE_PARAMS));
  String result=configuration.getProfileParams();
  Assert.assertNotNull(result);
  Assert.assertTrue(result.contains("file=%s"));
  Assert.assertTrue(result.startsWith("-agentlib:hprof"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.slive.TestSlive </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testMRFlow() throws Exception {
  ConfigExtractor extractor=getTestConfig(false);
  SliveTest s=new SliveTest(getBaseConfig());
  int ec=ToolRunner.run(s,getTestArgs(false));
  assertTrue(ec == 0);
  String resFile=extractor.getResultFile();
  File fn=new File(resFile);
  assertTrue(fn.exists());
}

</code></pre>

<br>
<pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDataWriting() throws Exception {
  long byteAm=100;
  File fn=getTestFile();
  DataWriter writer=new DataWriter(rnd);
  FileOutputStream fs=new FileOutputStream(fn);
  GenerateOutput ostat=writer.writeSegment(byteAm,fs);
  LOG.info(ostat);
  fs.close();
  assertTrue(ostat.getBytesWritten() == byteAm);
  DataVerifier vf=new DataVerifier();
  FileInputStream fin=new FileInputStream(fn);
  VerifyOutput vfout=vf.verifyFile(byteAm,new DataInputStream(fin));
  LOG.info(vfout);
  fin.close();
  assertEquals(vfout.getBytesRead(),byteAm);
  assertTrue(vfout.getChunksDifferent() == 0);
}

</code></pre>

<br>
<pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testFinder() throws Exception {
  ConfigExtractor extractor=getTestConfig(false);
  PathFinder fr=new PathFinder(extractor,rnd);
  int maxIterations=10000;
  Set<Path> files=new HashSet<Path>();
  for (int i=0; i < maxIterations; i++) {
    files.add(fr.getFile());
  }
  assertTrue(files.size() == 10);
  Set<Path> dirs=new HashSet<Path>();
  for (int i=0; i < maxIterations; i++) {
    dirs.add(fr.getDirectory());
  }
  assertTrue(dirs.size() == 10);
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testBadChunks() throws Exception {
  File fn=getTestFile();
  int byteAm=10000;
  FileOutputStream fout=new FileOutputStream(fn);
  byte[] bytes=new byte[byteAm];
  rnd.nextBytes(bytes);
  fout.write(bytes);
  fout.close();
  DataVerifier vf=new DataVerifier();
  VerifyOutput vout=new VerifyOutput(0,0,0,0);
  DataInputStream in=null;
  try {
    in=new DataInputStream(new FileInputStream(fn));
    vout=vf.verifyFile(byteAm,in);
  }
 catch (  Exception e) {
  }
 finally {
    if (in != null)     in.close();
  }
  assertTrue(vout.getChunksSame() == 0);
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testSelector() throws Exception {
  ConfigExtractor extractor=getTestConfig(false);
  RouletteSelector selector=new RouletteSelector(rnd);
  List<OperationWeight> sList=new LinkedList<OperationWeight>();
  Operation op=selector.select(sList);
  assertTrue(op == null);
  CreateOp cop=new CreateOp(extractor,rnd);
  sList.add(new OperationWeight(cop,1.0d));
  AppendOp aop=new AppendOp(extractor,rnd);
  sList.add(new OperationWeight(aop,0.01d));
  op=selector.select(sList);
  assertTrue(op == cop);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlockPlacementPolicyRaid </h4><pre class="type-11 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test that the har parity files will be placed at the good locations when we
 * create them.
 */
@Test public void testChooseTargetForHarRaidFile() throws IOException {
  setupCluster();
  try {
    String[] racks={"/rack2","/rack2","/rack2","/rack2","/rack2","/rack2"};
    String[] hosts={"host2.rack2.com","host3.rack2.com","host4.rack2.com","host5.rack2.com","host6.rack2.com","host7.rack2.com"};
    cluster.startDataNodes(conf,6,true,null,racks,hosts,null);
    String harParity=raidrsHarTempPrefix + "/dir/file";
    int numBlocks=11;
    DFSTestUtil.createFile(fs,new Path(harParity),numBlocks,(short)1,0L);
    DFSTestUtil.waitReplication(fs,new Path(harParity),(short)1);
    FileStatus stat=fs.getFileStatus(new Path(harParity));
    BlockLocation[] loc=fs.getFileBlockLocations(stat,0,stat.getLen());
    int rsParityLength=RaidNode.rsParityLength(conf);
    for (int i=0; i < numBlocks - rsParityLength; i++) {
      Set<String> locations=new HashSet<String>();
      for (int j=0; j < rsParityLength; j++) {
        for (int k=0; k < loc[i + j].getNames().length; k++) {
          String name=loc[i + j].getNames()[k];
          LOG.info("Har Raid block location: " + name);
          Assert.assertTrue(locations.add(name));
        }
      }
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-11 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test that the parity files will be placed at the good locations when we
 * create them.
 */
@Test public void testChooseTargetForRaidFile() throws IOException {
  setupCluster();
  try {
    String src="/dir/file";
    String parity=raidrsTempPrefix + src;
    DFSTestUtil.createFile(fs,new Path(src),4,(short)1,0L);
    DFSTestUtil.waitReplication(fs,new Path(src),(short)1);
    refreshPolicy();
    setBlockPlacementPolicy(namesystem,policy);
    String[] racks={"/rack2","/rack2","/rack2","/rack2","/rack2","/rack2"};
    String[] hosts={"host2.rack2.com","host3.rack2.com","host4.rack2.com","host5.rack2.com","host6.rack2.com","host7.rack2.com"};
    cluster.startDataNodes(conf,6,true,null,racks,hosts,null);
    int numBlocks=6;
    DFSTestUtil.createFile(fs,new Path(parity),numBlocks,(short)2,0L);
    DFSTestUtil.waitReplication(fs,new Path(parity),(short)2);
    FileStatus srcStat=fs.getFileStatus(new Path(src));
    BlockLocation[] srcLoc=fs.getFileBlockLocations(srcStat,0,srcStat.getLen());
    FileStatus parityStat=fs.getFileStatus(new Path(parity));
    BlockLocation[] parityLoc=fs.getFileBlockLocations(parityStat,0,parityStat.getLen());
    int parityLen=RaidNode.rsParityLength(conf);
    for (int i=0; i < numBlocks / parityLen; i++) {
      Set<String> locations=new HashSet<String>();
      for (int j=0; j < srcLoc.length; j++) {
        String[] names=srcLoc[j].getNames();
        for (int k=0; k < names.length; k++) {
          LOG.info("Source block location: " + names[k]);
          locations.add(names[k]);
        }
      }
      for (int j=0; j < parityLen; j++) {
        String[] names=parityLoc[j + i * parityLen].getNames();
        for (int k=0; k < names.length; k++) {
          LOG.info("Parity block location: " + names[k]);
          Assert.assertTrue(locations.add(names[k]));
        }
      }
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-11 type-4 type-7 type-5 type-12 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test BlockPlacementPolicyRaid actually deletes the correct replica.
 * Start 2 datanodes and create 1 source file and its parity file.
 * 1) Start host1, create the parity file with replication 1
 * 2) Start host2, create the source file with replication 2
 * 3) Set repliation of source file to 1
 * Verify that the policy should delete the block with more companion blocks.
 */
@Test public void testDeleteReplica() throws IOException {
  setupCluster();
  try {
    setBlockPlacementPolicy(namesystem,new BlockPlacementPolicyDefault(conf,namesystem,namesystem.clusterMap));
    DatanodeDescriptor datanode1=namesystem.datanodeMap.values().iterator().next();
    String source="/dir/file";
    String parity=xorPrefix + source;
    final Path parityPath=new Path(parity);
    DFSTestUtil.createFile(fs,parityPath,3,(short)1,0L);
    DFSTestUtil.waitReplication(fs,parityPath,(short)1);
    cluster.startDataNodes(conf,1,true,null,rack2,host2,null);
    DatanodeDescriptor datanode2=null;
    for (    DatanodeDescriptor d : namesystem.datanodeMap.values()) {
      if (!d.getName().equals(datanode1.getName())) {
        datanode2=d;
      }
    }
    Assert.assertTrue(datanode2 != null);
    cluster.waitActive();
    final Path sourcePath=new Path(source);
    DFSTestUtil.createFile(fs,sourcePath,5,(short)2,0L);
    DFSTestUtil.waitReplication(fs,sourcePath,(short)2);
    refreshPolicy();
    Assert.assertEquals(parity,policy.getParityFile(source));
    Assert.assertEquals(source,policy.getSourceFile(parity,xorPrefix));
    List<LocatedBlock> sourceBlocks=getBlocks(namesystem,source);
    List<LocatedBlock> parityBlocks=getBlocks(namesystem,parity);
    Assert.assertEquals(5,sourceBlocks.size());
    Assert.assertEquals(3,parityBlocks.size());
    Collection<LocatedBlock> companionBlocks;
    companionBlocks=getCompanionBlocks(namesystem,policy,sourceBlocks.get(0).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{0,1},new int[]{0});
    companionBlocks=getCompanionBlocks(namesystem,policy,sourceBlocks.get(1).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{0,1},new int[]{0});
    companionBlocks=getCompanionBlocks(namesystem,policy,sourceBlocks.get(2).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{2,3},new int[]{1});
    companionBlocks=getCompanionBlocks(namesystem,policy,sourceBlocks.get(3).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{2,3},new int[]{1});
    companionBlocks=getCompanionBlocks(namesystem,policy,sourceBlocks.get(4).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{4},new int[]{2});
    companionBlocks=getCompanionBlocks(namesystem,policy,parityBlocks.get(0).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{0,1},new int[]{0});
    companionBlocks=getCompanionBlocks(namesystem,policy,parityBlocks.get(1).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{2,3},new int[]{1});
    companionBlocks=getCompanionBlocks(namesystem,policy,parityBlocks.get(2).getBlock());
    verifyCompanionBlocks(companionBlocks,sourceBlocks,parityBlocks,new int[]{4},new int[]{2});
    refreshPolicy();
    setBlockPlacementPolicy(namesystem,policy);
    fs.setReplication(sourcePath,(short)1);
    DFSTestUtil.waitReplication(fs,sourcePath,(short)1);
    Map<String,Integer> counters=new HashMap<String,Integer>();
    refreshPolicy();
    for (int i=0; i < parityBlocks.size(); i++) {
      companionBlocks=getCompanionBlocks(namesystem,policy,parityBlocks.get(i).getBlock());
      counters=BlockPlacementPolicyRaid.countCompanionBlocks(companionBlocks,false);
      Assert.assertTrue(counters.get(datanode1.getName()) >= 1 && counters.get(datanode1.getName()) <= 2);
      Assert.assertTrue(counters.get(datanode1.getName()) + counters.get(datanode2.getName()) == companionBlocks.size());
      counters=BlockPlacementPolicyRaid.countCompanionBlocks(companionBlocks,true);
      Assert.assertTrue(counters.get(datanode1.getParent().getName()) >= 1 && counters.get(datanode1.getParent().getName()) <= 2);
      Assert.assertTrue(counters.get(datanode1.getParent().getName()) + counters.get(datanode2.getParent().getName()) == companionBlocks.size());
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the result of getCompanionBlocks() on the unraided files
 */
@Test public void testGetCompanionBLocks() throws IOException {
  setupCluster();
  try {
    String file1="/dir/file1";
    String file2="/raid/dir/file2";
    String file3="/raidrs/dir/file3";
    setBlockPlacementPolicy(namesystem,new BlockPlacementPolicyDefault(conf,namesystem,namesystem.clusterMap));
    DFSTestUtil.createFile(fs,new Path(file1),3,(short)1,0L);
    DFSTestUtil.createFile(fs,new Path(file2),4,(short)1,0L);
    DFSTestUtil.createFile(fs,new Path(file3),8,(short)1,0L);
    Collection<LocatedBlock> companionBlocks;
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file1).get(0).getBlock());
    Assert.assertTrue(companionBlocks == null || companionBlocks.size() == 0);
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file1).get(2).getBlock());
    Assert.assertTrue(companionBlocks == null || companionBlocks.size() == 0);
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file2).get(0).getBlock());
    Assert.assertEquals(1,companionBlocks.size());
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file2).get(3).getBlock());
    Assert.assertEquals(1,companionBlocks.size());
    int rsParityLength=RaidNode.rsParityLength(conf);
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file3).get(0).getBlock());
    Assert.assertEquals(rsParityLength,companionBlocks.size());
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file3).get(4).getBlock());
    Assert.assertEquals(rsParityLength,companionBlocks.size());
    companionBlocks=getCompanionBlocks(namesystem,policy,getBlocks(namesystem,file3).get(6).getBlock());
    Assert.assertEquals(2,companionBlocks.size());
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestCluster </h4><pre class="type-10 type-11 type-13 type-14 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test to verify the common properties of tasks.
 * @throws Exception
 */
@Test public void testTaskDetails() throws Exception {
  Configuration conf=new Configuration(cluster.getConf());
  JTProtocol wovenClient=cluster.getJTClient().getProxy();
  FinishTaskControlAction.configureControlActionForJob(conf);
  SleepJob job=new SleepJob();
  job.setConf(conf);
  Job rJob=job.createJob(1,1,100,100,100,100);
  JobClient client=cluster.getJTClient().getClient();
  rJob.submit();
  RunningJob rJob1=client.getJob(org.apache.hadoop.mapred.JobID.downgrade(rJob.getJobID()));
  JobID id=rJob.getJobID();
  JobInfo jInfo=wovenClient.getJobInfo(id);
  while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
    Thread.sleep(1000);
    jInfo=wovenClient.getJobInfo(id);
  }
  LOG.info("Waiting till job starts running one map");
  TaskInfo[] myTaskInfos=wovenClient.getTaskInfo(id);
  boolean isOneTaskStored=false;
  String sometaskpid=null;
  org.apache.hadoop.mapreduce.TaskAttemptID sometaskId=null;
  TTClient myCli=null;
  for (  TaskInfo info : myTaskInfos) {
    if (!info.isSetupOrCleanup()) {
      String[] taskTrackers=info.getTaskTrackers();
      for (      String taskTracker : taskTrackers) {
        TTInfo ttInfo=wovenClient.getTTInfo(taskTracker);
        TTClient ttCli=cluster.getTTClient(ttInfo.getStatus().getHost());
        TaskID taskId=info.getTaskID();
        TTTaskInfo ttTaskInfo=ttCli.getProxy().getTask(taskId);
        Assert.assertNotNull(ttTaskInfo);
        Assert.assertNotNull(ttTaskInfo.getConf());
        Assert.assertNotNull(ttTaskInfo.getUser());
        Assert.assertTrue(ttTaskInfo.getTaskStatus().getProgress() >= 0.0);
        Assert.assertTrue(ttTaskInfo.getTaskStatus().getProgress() <= 1.0);
        String pid=ttTaskInfo.getPid();
        int i=1;
        while (pid.isEmpty()) {
          Thread.sleep(1000);
          LOG.info("Waiting for task to report its pid back");
          ttTaskInfo=ttCli.getProxy().getTask(taskId);
          pid=ttTaskInfo.getPid();
          if (i == 40) {
            Assert.fail("The task pid not reported for 40 seconds.");
          }
          i++;
        }
        if (!isOneTaskStored) {
          sometaskpid=pid;
          sometaskId=ttTaskInfo.getTaskStatus().getTaskID();
          myCli=ttCli;
          isOneTaskStored=true;
        }
        LOG.info("verified task progress to be between 0 and 1");
        State state=ttTaskInfo.getTaskStatus().getRunState();
        if (ttTaskInfo.getTaskStatus().getProgress() < 1.0 && ttTaskInfo.getTaskStatus().getProgress() > 0.0) {
          Assert.assertEquals(TaskStatus.State.RUNNING,state);
          LOG.info("verified run state as " + state);
        }
        FinishTaskControlAction action=new FinishTaskControlAction(org.apache.hadoop.mapred.TaskID.downgrade(info.getTaskID()));
        ttCli.getProxy().sendAction(action);
      }
    }
  }
  rJob.killJob();
  int i=1;
  while (!rJob.isComplete()) {
    Thread.sleep(1000);
    if (i == 40) {
      Assert.fail("The job not completed within 40 seconds after killing it.");
    }
    i++;
  }
  TTTaskInfo myTaskInfo=myCli.getProxy().getTask(sometaskId.getTaskID());
  i=0;
  while (myTaskInfo != null && !myTaskInfo.getPid().isEmpty()) {
    LOG.info("sleeping till task is retired from TT memory");
    Thread.sleep(1000);
    myTaskInfo=myCli.getProxy().getTask(sometaskId.getTaskID());
    if (i == 40) {
      Assert.fail("Task not retired from TT memory within 40 seconds of job completeing");
    }
    i++;
  }
  Assert.assertFalse(myCli.getProxy().isProcessTreeAlive(sometaskpid));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestCompositeTaskTrackerInstrumentation </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCompositeInstrumentation() throws IOException {
  TaskTracker tt=new TaskTracker();
  DummyTaskTrackerInstrumentation inst1=new DummyTaskTrackerInstrumentation(tt);
  DummyTaskTrackerInstrumentation inst2=new DummyTaskTrackerInstrumentation(tt);
  ArrayList<TaskTrackerInstrumentation> insts=new ArrayList<TaskTrackerInstrumentation>();
  insts.add(inst1);
  insts.add(inst2);
  CompositeTaskTrackerInstrumentation comp=new CompositeTaskTrackerInstrumentation(tt,insts);
  TaskAttemptID tid=new TaskAttemptID();
  File file=new File("file");
  Task task=new MapTask();
  TaskStatus status=new MapTaskStatus();
  assertFalse(inst1.completeTaskCalled);
  assertFalse(inst2.completeTaskCalled);
  comp.completeTask(tid);
  assertTrue(inst1.completeTaskCalled);
  assertTrue(inst2.completeTaskCalled);
  assertFalse(inst1.timedoutTaskCalled);
  assertFalse(inst2.timedoutTaskCalled);
  comp.timedoutTask(tid);
  assertTrue(inst1.timedoutTaskCalled);
  assertTrue(inst2.timedoutTaskCalled);
  assertFalse(inst1.taskFailedPingCalled);
  assertFalse(inst2.taskFailedPingCalled);
  comp.taskFailedPing(tid);
  assertTrue(inst1.taskFailedPingCalled);
  assertTrue(inst2.taskFailedPingCalled);
  assertFalse(inst1.reportTaskLaunchCalled);
  assertFalse(inst2.reportTaskLaunchCalled);
  comp.reportTaskLaunch(tid,file,file);
  assertTrue(inst1.reportTaskLaunchCalled);
  assertTrue(inst2.reportTaskLaunchCalled);
  assertFalse(inst1.reportTaskEndCalled);
  assertFalse(inst2.reportTaskEndCalled);
  comp.reportTaskEnd(tid);
  assertTrue(inst1.reportTaskEndCalled);
  assertTrue(inst2.reportTaskEndCalled);
  assertFalse(inst1.statusUpdateCalled);
  assertFalse(inst2.statusUpdateCalled);
  comp.statusUpdate(task,status);
  assertTrue(inst1.statusUpdateCalled);
  assertTrue(inst2.statusUpdateCalled);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestConcatenatedCompressedInput </h4><pre class="type-10 type-11 type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test using the raw Inflater codec for reading gzip files.
 */
@Test public void testPrototypeInflaterGzip() throws IOException {
  CompressionCodec gzip=new GzipCodec();
  localFs.delete(workDir,true);
  System.out.println(COLOR_BR_BLUE + "testPrototypeInflaterGzip() using " + "non-native/Java Inflater and manual gzip header/trailer parsing"+ COLOR_NORMAL);
  final String fn="concat" + gzip.getDefaultExtension();
  Path fnLocal=new Path(System.getProperty("test.concat.data","/tmp"),fn);
  Path fnHDFS=new Path(workDir,fn);
  localFs.copyFromLocalFile(fnLocal,fnHDFS);
  final FileInputStream in=new FileInputStream(fnLocal.toString());
  assertEquals("concat bytes available",148,in.available());
  byte[] compressedBuf=new byte[256];
  int numBytesRead=in.read(compressedBuf,0,10);
  assertEquals("header bytes read",10,numBytesRead);
  assertEquals("1st byte",0x1f,compressedBuf[0] & 0xff);
  assertEquals("2nd byte",0x8b,compressedBuf[1] & 0xff);
  assertEquals("3rd byte (compression method)",8,compressedBuf[2] & 0xff);
  byte flags=(byte)(compressedBuf[3] & 0xff);
  if ((flags & 0x04) != 0) {
    numBytesRead=in.read(compressedBuf,0,2);
    assertEquals("XLEN bytes read",2,numBytesRead);
    int xlen=((compressedBuf[1] << 8) | compressedBuf[0]) & 0xffff;
    in.skip(xlen);
  }
  if ((flags & 0x08) != 0) {
    while ((numBytesRead=in.read()) != 0) {
      assertFalse("unexpected end-of-file while reading filename",numBytesRead == -1);
    }
  }
  if ((flags & 0x10) != 0) {
    while ((numBytesRead=in.read()) != 0) {
      assertFalse("unexpected end-of-file while reading comment",numBytesRead == -1);
    }
  }
  if ((flags & 0xe0) != 0) {
    assertTrue("reserved bits are set??",(flags & 0xe0) == 0);
  }
  if ((flags & 0x02) != 0) {
    numBytesRead=in.read(compressedBuf,0,2);
    assertEquals("CRC16 bytes read",2,numBytesRead);
    int crc16=((compressedBuf[1] << 8) | compressedBuf[0]) & 0xffff;
  }
  numBytesRead=in.read(compressedBuf);
  byte[] uncompressedBuf=new byte[256];
  Inflater inflater=new Inflater(true);
  inflater.setInput(compressedBuf,0,numBytesRead);
  try {
    int numBytesUncompressed=inflater.inflate(uncompressedBuf);
    String outString=new String(uncompressedBuf,0,numBytesUncompressed,"UTF-8");
    System.out.println("uncompressed data of first gzip member = [" + outString + "]");
  }
 catch (  java.util.zip.DataFormatException ex) {
    throw new IOException(ex.getMessage());
  }
  in.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestDistributedCacheModifiedFile </h4><pre class="type-10 type-11 type-13 type-14 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDistributedCache() throws Exception {
  Configuration conf=new Configuration(cluster.getConf());
  JTProtocol wovenClient=cluster.getJTClient().getProxy();
  int count=0;
  boolean continueLoop=true;
  int countLoop=0;
  int taskTrackerCounter=0;
  ArrayList<String> taskTrackerCollection=new ArrayList<String>();
  boolean taskTrackerFound=false;
  do {
    SleepJob job=new SleepJob();
    job.setConf(conf);
    Job slpJob=job.createJob(5,1,1000,1000,100,100);
    String input="This will be the content of\n" + "distributed cache\n";
    DataOutputStream file=UtilsForTests.createTmpFileDFS(dfs,URIPATH,permission,input);
    DistributedCache.createSymlink(conf);
    URI uri=URI.create(uriPath);
    DistributedCache.addCacheFile(uri,conf);
    JobConf jconf=new JobConf(conf);
    FinishTaskControlAction.configureControlActionForJob(conf);
    slpJob.submit();
    RunningJob rJob=cluster.getJTClient().getClient().getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
    countLoop++;
    TTClient tClient=null;
    JobInfo jInfo=wovenClient.getJobInfo(rJob.getID());
    LOG.info("jInfo is :" + jInfo);
    Assert.assertNotNull("jobInfo is null",jInfo);
    count=0;
    while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
      UtilsForTests.waitFor(10000);
      count++;
      jInfo=wovenClient.getJobInfo(rJob.getID());
      if (count > 10) {
        Assert.fail("job has not reached running state for more than" + "100 seconds. Failing at this point");
      }
    }
    LOG.info("job id is :" + rJob.getID().toString());
    TaskInfo[] taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    boolean distCacheFileIsFound;
    for (    TaskInfo taskInfo : taskInfos) {
      distCacheFileIsFound=false;
      String[] taskTrackers=taskInfo.getTaskTrackers();
      for (      String taskTracker : taskTrackers) {
        taskTracker=UtilsForTests.getFQDNofTT(taskTracker);
        LOG.info("taskTracker is :" + taskTracker);
        taskTrackerFound=false;
        if (countLoop > 1) {
          if (taskTracker != null) {
            continueLoop=taskTrackerCollection.contains(taskTracker);
          }
          if (continueLoop) {
            taskTrackerFound=true;
          }
        }
        if (taskTracker != null)         taskTrackerCollection.add(taskTracker);
        if (countLoop > 1) {
          continueLoop=false;
        }
        tClient=cluster.getTTClient(taskTracker);
        if (tClient == null) {
          continue;
        }
        String[] localDirs=tClient.getMapredLocalDirs();
        int distributedFileCount=0;
        for (        String localDir : localDirs) {
          localDir=localDir + Path.SEPARATOR + TaskTracker.getPublicDistributedCacheDir();
          LOG.info("localDir is : " + localDir);
          FileStatus[] fileStatuses=tClient.listStatus(localDir,true,true);
          for (          FileStatus fileStatus : fileStatuses) {
            Path path=fileStatus.getPath();
            LOG.info("path is :" + path.toString());
            distCacheFileIsFound=(path.toString()).endsWith(distributedFileName);
            if (distCacheFileIsFound) {
              LOG.info("PATH found is :" + path.toString());
              distributedFileCount++;
              String filename=path.getName();
              FsPermission fsPerm=fileStatus.getPermission();
              Assert.assertTrue("File Permission is not 777",fsPerm.equals(new FsPermission("777")));
            }
          }
        }
        LOG.debug("The distributed FileCount is :" + distributedFileCount);
        LOG.debug("The taskTrackerFound is :" + taskTrackerFound);
        if (distributedFileCount != 2 && taskTrackerFound) {
          Assert.fail("The distributed cache file has to be two. " + "But found was " + distributedFileCount);
        }
 else         if (distributedFileCount > 1 && !taskTrackerFound) {
          Assert.fail("The distributed cache file cannot more than one." + " But found was " + distributedFileCount);
        }
 else         if (distributedFileCount < 1)         Assert.fail("The distributed cache file is less than one. " + "But found was " + distributedFileCount);
        if (!distCacheFileIsFound) {
          Assert.assertEquals("The distributed cache file does not exist",distCacheFileIsFound,false);
        }
      }
    }
    for (    TaskInfo taskInfoRemaining : taskInfos) {
      FinishTaskControlAction action=new FinishTaskControlAction(TaskID.downgrade(taskInfoRemaining.getTaskID()));
      Collection<TTClient> tts=cluster.getTTClients();
      for (      TTClient cli : tts) {
        cli.getProxy().sendAction(action);
      }
    }
    rJob.killJob();
    Thread.sleep(3000);
    TaskInfo[] myTaskInfos=wovenClient.getTaskInfo(rJob.getID());
    if (myTaskInfos != null) {
      for (      TaskInfo info : myTaskInfos) {
        if (info.isSetupOrCleanup()) {
          String[] taskTrackers=info.getTaskTrackers();
          for (          String taskTracker : taskTrackers) {
            taskTracker=UtilsForTests.getFQDNofTT(taskTracker);
            LOG.info("taskTracker is :" + taskTracker);
            if (taskTracker != null)             taskTrackerCollection.add(taskTracker);
          }
        }
      }
    }
    while (jInfo != null && !jInfo.getStatus().isJobComplete()) {
      Thread.sleep(10000);
      jInfo=wovenClient.getJobInfo(rJob.getID());
    }
  }
 while (continueLoop);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestDistributedCachePrivateFile </h4><pre class="type-10 type-11 type-13 type-14 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDistributedCache() throws Exception {
  Configuration conf=new Configuration(cluster.getConf());
  JTProtocol wovenClient=cluster.getJTClient().getProxy();
  int count=0;
  SleepJob job=new SleepJob();
  job.setConf(conf);
  Job slpJob=job.createJob(5,1,1000,1000,100,100);
  DistributedCache.createSymlink(conf);
  URI uri=URI.create(uriPath);
  DistributedCache.addCacheFile(uri,conf);
  JobConf jconf=new JobConf(conf);
  FinishTaskControlAction.configureControlActionForJob(conf);
  slpJob.submit();
  RunningJob rJob=cluster.getJTClient().getClient().getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
  JobStatus[] jobStatus=client.getAllJobs();
  String userName=jobStatus[0].getUsername();
  TTClient tClient=null;
  JobInfo jInfo=wovenClient.getJobInfo(rJob.getID());
  LOG.info("jInfo is :" + jInfo);
  Assert.assertNotNull("jobInfo is null",jInfo);
  count=0;
  while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
    UtilsForTests.waitFor(10000);
    count++;
    jInfo=wovenClient.getJobInfo(rJob.getID());
    if (count > 10) {
      Assert.fail("job has not reached running state for more than" + "100 seconds. Failing at this point");
    }
  }
  LOG.info("job id is :" + rJob.getID().toString());
  TaskInfo[] taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
  boolean distCacheFileIsFound;
  for (  TaskInfo taskInfo : taskInfos) {
    distCacheFileIsFound=false;
    String[] taskTrackers=taskInfo.getTaskTrackers();
    for (    String taskTracker : taskTrackers) {
      taskTracker=UtilsForTests.getFQDNofTT(taskTracker);
      tClient=cluster.getTTClient(taskTracker);
      String[] localDirs=tClient.getMapredLocalDirs();
      int distributedFileCount=0;
      String localDirOnly=null;
      boolean FileNotPresentForThisDirectoryPath=false;
      for (      String localDir : localDirs) {
        FileNotPresentForThisDirectoryPath=false;
        localDirOnly=localDir;
        localDirOnly=localDir + Path.SEPARATOR + TaskTracker.SUBDIR+ Path.SEPARATOR+ userName;
        localDir=localDir + Path.SEPARATOR + TaskTracker.getPrivateDistributedCacheDir(userName);
        FileStatus fileStatusMapredLocalDirUserName=null;
        try {
          fileStatusMapredLocalDirUserName=tClient.getFileStatus(localDirOnly,true);
        }
 catch (        Exception e) {
          LOG.info("LocalDirOnly :" + localDirOnly + " not found");
          FileNotPresentForThisDirectoryPath=true;
        }
        if (FileNotPresentForThisDirectoryPath)         continue;
        Path pathMapredLocalDirUserName=fileStatusMapredLocalDirUserName.getPath();
        FsPermission fsPermMapredLocalDirUserName=fileStatusMapredLocalDirUserName.getPermission();
        Assert.assertTrue("Directory Permission is not 700",fsPermMapredLocalDirUserName.equals(new FsPermission("700")));
        FileStatus[] fileStatuses=tClient.listStatus(localDir,true,true);
        for (        FileStatus fileStatus : fileStatuses) {
          Path path=fileStatus.getPath();
          LOG.info("path is :" + path.toString());
          distCacheFileIsFound=(path.toString()).endsWith(distributedFileName);
          if (distCacheFileIsFound) {
            LOG.info("PATH found is :" + path.toString());
            distributedFileCount++;
            String filename=path.getName();
            FsPermission fsPerm=fileStatus.getPermission();
            Assert.assertTrue("File Permission is not 777",fsPerm.equals(new FsPermission("777")));
          }
        }
      }
      LOG.info("Distributed File count is :" + distributedFileCount);
      if (distributedFileCount > 1) {
        Assert.fail("The distributed cache file is more than one");
      }
 else       if (distributedFileCount < 1)       Assert.fail("The distributed cache file is less than one");
      if (!distCacheFileIsFound) {
        Assert.assertEquals("The distributed cache file does not exist",distCacheFileIsFound,false);
      }
    }
    for (    TaskInfo taskInfoRemaining : taskInfos) {
      FinishTaskControlAction action=new FinishTaskControlAction(TaskID.downgrade(taskInfoRemaining.getTaskID()));
      Collection<TTClient> tts=cluster.getTTClients();
      for (      TTClient cli : tts) {
        cli.getProxy().sendAction(action);
      }
    }
    rJob.killJob();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestDistributedCacheUnModifiedFile </h4><pre class="type-10 type-11 type-13 type-14 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDistributedCache() throws Exception {
  Configuration conf=new Configuration(cluster.getConf());
  JTProtocol wovenClient=cluster.getJTClient().getProxy();
  int count=0;
  boolean continueLoop=true;
  int countLoop=0;
  int taskTrackerCounter=0;
  ArrayList<String> taskTrackerCollection=new ArrayList<String>();
  do {
    SleepJob job=new SleepJob();
    job.setConf(conf);
    Job slpJob=job.createJob(5,1,1000,1000,100,100);
    DistributedCache.createSymlink(conf);
    URI uri=URI.create(uriPath);
    DistributedCache.addCacheFile(uri,conf);
    JobConf jconf=new JobConf(conf);
    FinishTaskControlAction.configureControlActionForJob(conf);
    slpJob.submit();
    RunningJob rJob=cluster.getJTClient().getClient().getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
    countLoop++;
    TTClient tClient=null;
    JobInfo jInfo=wovenClient.getJobInfo(rJob.getID());
    LOG.info("jInfo is :" + jInfo);
    Assert.assertNotNull("jobInfo is null",jInfo);
    count=0;
    while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
      UtilsForTests.waitFor(10000);
      count++;
      jInfo=wovenClient.getJobInfo(rJob.getID());
      if (count > 10) {
        Assert.fail("job has not reached running state for more than" + "100 seconds. Failing at this point");
      }
    }
    LOG.info("job id is :" + rJob.getID().toString());
    TaskInfo[] taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    boolean distCacheFileIsFound;
    for (    TaskInfo taskInfo : taskInfos) {
      distCacheFileIsFound=false;
      String[] taskTrackers=taskInfo.getTaskTrackers();
      for (      String taskTracker : taskTrackers) {
        taskTracker=UtilsForTests.getFQDNofTT(taskTracker);
        LOG.info("taskTracker is :" + taskTracker);
        if (countLoop > 1) {
          if (taskTracker != null) {
            continueLoop=taskTrackerCollection.contains(taskTracker);
          }
          if (!continueLoop) {
            break;
          }
        }
        if (taskTracker != null)         taskTrackerCollection.add(taskTracker);
        if (countLoop > 2) {
          continueLoop=false;
        }
        tClient=cluster.getTTClient(taskTracker);
        if (tClient == null) {
          continue;
        }
        String[] localDirs=tClient.getMapredLocalDirs();
        int distributedFileCount=0;
        for (        String localDir : localDirs) {
          localDir=localDir + Path.SEPARATOR + TaskTracker.getPublicDistributedCacheDir();
          LOG.info("localDir is : " + localDir);
          FileStatus[] fileStatuses=tClient.listStatus(localDir,true,true);
          for (          FileStatus fileStatus : fileStatuses) {
            Path path=fileStatus.getPath();
            LOG.info("path is :" + path.toString());
            distCacheFileIsFound=(path.toString()).endsWith(distributedFileName);
            if (distCacheFileIsFound) {
              LOG.info("PATH found is :" + path.toString());
              distributedFileCount++;
              String filename=path.getName();
              FsPermission fsPerm=fileStatus.getPermission();
              Assert.assertTrue("File Permission is not 777",fsPerm.equals(new FsPermission("777")));
            }
          }
        }
        if (distributedFileCount > 1) {
          Assert.fail("The distributed cache file is more than one");
        }
 else         if (distributedFileCount < 1)         Assert.fail("The distributed cache file is less than one");
        if (!distCacheFileIsFound) {
          Assert.assertEquals("The distributed cache file does not exist",distCacheFileIsFound,false);
        }
      }
    }
    for (    TaskInfo taskInfoRemaining : taskInfos) {
      FinishTaskControlAction action=new FinishTaskControlAction(TaskID.downgrade(taskInfoRemaining.getTaskID()));
      Collection<TTClient> tts=cluster.getTTClients();
      for (      TTClient cli : tts) {
        cli.getProxy().sendAction(action);
      }
    }
    rJob.killJob();
  }
 while (continueLoop);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestJobCounters </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Tests {@link TaskCounter}'s {@link TaskCounter.COMMITTED_HEAP_BYTES}. 
 * The test consists of running a low-memory job which consumes less heap 
 * memory and then running a high-memory job which consumes more heap memory, 
 * and then ensuring that COMMITTED_HEAP_BYTES of low-memory job is smaller 
 * than that of the high-memory job.
 * @throws IOException
 */
@Test @SuppressWarnings("deprecation") public void testHeapUsageCounter() throws Exception {
  JobConf conf=new JobConf();
  FileSystem fileSystem=FileSystem.getLocal(conf);
  Path rootDir=new Path(System.getProperty("test.build.data","/tmp"));
  Path testRootDir=new Path(rootDir,"testHeapUsageCounter");
  fileSystem.delete(testRootDir,true);
  fileSystem.setWorkingDirectory(testRootDir);
  fileSystem.deleteOnExit(testRootDir);
  MiniMRCluster mrCluster=new MiniMRCluster(1,fileSystem.getUri().toString(),1);
  try {
    conf=mrCluster.createJobConf();
    JobClient jobClient=new JobClient(conf);
    Path inDir=new Path(testRootDir,"in");
    createWordsFile(inDir,conf);
    RunningJob lowMemJob=runHeapUsageTestJob(conf,testRootDir,"-Xms32m -Xmx1G",0,0,fileSystem,jobClient,inDir);
    JobID lowMemJobID=lowMemJob.getID();
    long lowMemJobMapHeapUsage=getTaskCounterUsage(jobClient,lowMemJobID,1,0,TaskType.MAP);
    System.out.println("Job1 (low memory job) map task heap usage: " + lowMemJobMapHeapUsage);
    long lowMemJobReduceHeapUsage=getTaskCounterUsage(jobClient,lowMemJobID,1,0,TaskType.REDUCE);
    System.out.println("Job1 (low memory job) reduce task heap usage: " + lowMemJobReduceHeapUsage);
    RunningJob highMemJob=runHeapUsageTestJob(conf,testRootDir,"-Xms32m -Xmx1G",lowMemJobMapHeapUsage + 256 * 1024 * 1024,lowMemJobReduceHeapUsage + 256 * 1024 * 1024,fileSystem,jobClient,inDir);
    JobID highMemJobID=highMemJob.getID();
    long highMemJobMapHeapUsage=getTaskCounterUsage(jobClient,highMemJobID,1,0,TaskType.MAP);
    System.out.println("Job2 (high memory job) map task heap usage: " + highMemJobMapHeapUsage);
    long highMemJobReduceHeapUsage=getTaskCounterUsage(jobClient,highMemJobID,1,0,TaskType.REDUCE);
    System.out.println("Job2 (high memory job) reduce task heap usage: " + highMemJobReduceHeapUsage);
    assertTrue("Incorrect map heap usage reported by the map task",lowMemJobMapHeapUsage < highMemJobMapHeapUsage);
    assertTrue("Incorrect reduce heap usage reported by the reduce task",lowMemJobReduceHeapUsage < highMemJobReduceHeapUsage);
  }
  finally {
    mrCluster.shutdown();
    try {
      fileSystem.delete(testRootDir,true);
    }
 catch (    IOException ioe) {
    }
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testNewCounterA() throws Exception {
  final Job job=createJob();
  final Configuration conf=job.getConfiguration();
  conf.setInt(JobContext.IO_SORT_FACTOR,2);
  removeWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);
  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);
  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);
  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN0"));
  assertTrue(job.waitForCompletion(true));
  final Counters c1=Counters.downgrade(job.getCounters());
  validateCounters(c1,90112,15360,61440);
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testNewCounterC() throws Exception {
  final Job job=createJob();
  final Configuration conf=job.getConfiguration();
  conf.setInt(JobContext.IO_SORT_FACTOR,3);
  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);
  createWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);
  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);
  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN2"));
  assertTrue(job.waitForCompletion(true));
  final Counters c1=Counters.downgrade(job.getCounters());
  validateCounters(c1,147456,25600,102400);
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testNewCounterB() throws Exception {
  final Job job=createJob();
  final Configuration conf=job.getConfiguration();
  conf.setInt(JobContext.IO_SORT_FACTOR,2);
  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);
  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);
  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);
  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN1"));
  assertTrue(job.waitForCompletion(true));
  final Counters c1=Counters.downgrade(job.getCounters());
  validateCounters(c1,131072,20480,81920);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestJobTrackerPlugins </h4><pre class="type-10 type-4 type-7 type-16 type-6 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether two objects/variables are the same">IdentityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether two objects/variables are the same
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void test() throws Exception {
  JobConf conf=new JobConf();
  conf.set(JTConfig.JT_IPC_ADDRESS,"localhost:0");
  conf.set(JTConfig.JT_HTTP_ADDRESS,"0.0.0.0:0");
  conf.setClass(JTConfig.JT_PLUGINS,FakeServicePlugin.class,ServicePlugin.class);
  assertNull("Plugin not created",FakeServicePlugin.getInstance());
  JobTracker jobTracker=JobTracker.startTracker(conf);
  assertNotNull("Plugin created",FakeServicePlugin.getInstance());
  assertSame("Service is jobTracker",FakeServicePlugin.getInstance().getService(),jobTracker);
  assertFalse("Plugin not stopped",FakeServicePlugin.getInstance().isStopped());
  jobTracker.close();
  assertTrue("Plugin stopped",FakeServicePlugin.getInstance().isStopped());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestJvmManager </h4><pre class="type-10 type-4 type-7 type-12 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies values related to public fields.
"></span><br>
/** 
 * Tests the jvm kill from JvmRunner and JvmManager simultaneously.
 * Starts a process, which sleeps for 60 seconds, in a thread.
 * Calls JvmRunner.kill() in a thread.
 * Also calls JvmManager.taskKilled().
 * Makes sure that the jvm is killed and JvmManager could launch another task
 * properly.
 * @throws Exception
 */
@Test public void testJvmKill() throws Exception {
  JvmManagerForType mapJvmManager=jvmManager.getJvmManagerForType(TaskType.MAP);
  JobConf taskConf=new JobConf(ttConf);
  TaskAttemptID attemptID=new TaskAttemptID("test",0,TaskType.MAP,0,0);
  Task task=new MapTask(null,attemptID,0,null,1);
  task.setConf(taskConf);
  TaskInProgress tip=tt.new TaskInProgress(task,taskConf);
  File pidFile=new File(TEST_DIR,"pid");
  final TaskRunner taskRunner=task.createRunner(tt,tip);
  final Vector<String> vargs=new Vector<String>(2);
  vargs.add(writeScript("SLEEP","sleep 60\n",pidFile).getAbsolutePath());
  final File workDir=new File(TEST_DIR,"work");
  workDir.mkdir();
  final File stdout=new File(TEST_DIR,"stdout");
  final File stderr=new File(TEST_DIR,"stderr");
  Thread launcher=new Thread(){
    public void run(){
      try {
        taskRunner.launchJvmAndWait(null,vargs,stdout,stderr,100,workDir,null);
      }
 catch (      InterruptedException e) {
        e.printStackTrace();
        return;
      }
    }
  }
;
  launcher.start();
  for (int i=0; i < 10; i++) {
    if (pidFile.exists()) {
      break;
    }
    UtilsForTests.waitFor(100);
  }
  assertTrue("pidFile is not present",pidFile.exists());
  BufferedReader in=new BufferedReader(new FileReader(pidFile));
  String pid=in.readLine();
  in.close();
  JVMId jvmid=mapJvmManager.runningTaskToJvm.get(taskRunner);
  jvmManager.setPidToJvm(jvmid,pid);
  final JvmRunner jvmRunner=mapJvmManager.jvmIdToRunner.get(jvmid);
  Thread killer=new Thread(){
    public void run(){
      jvmRunner.kill();
    }
  }
;
  killer.start();
  Thread.sleep(100);
  taskRunner.kill();
  assertTrue(jvmRunner.killed);
  attemptID=new TaskAttemptID("test",0,TaskType.MAP,0,1);
  task=new MapTask(null,attemptID,0,null,1);
  task.setConf(taskConf);
  tip=tt.new TaskInProgress(task,taskConf);
  TaskRunner taskRunner2=task.createRunner(tt,tip);
  Vector<String> vargs2=new Vector<String>(1);
  vargs2.add(writeScript("LS","ls",pidFile).getAbsolutePath());
  File workDir2=new File(TEST_DIR,"work2");
  workDir.mkdir();
  File stdout2=new File(TEST_DIR,"stdout2");
  File stderr2=new File(TEST_DIR,"stderr2");
  taskRunner2.launchJvmAndWait(null,vargs2,stdout2,stderr2,100,workDir2,null);
  killer.join();
  jvmRunner.join();
  launcher.join();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestMapRed </h4><pre class="type-11 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testNullKeys() throws Exception {
  JobConf conf=new JobConf(TestMapRed.class);
  FileSystem fs=FileSystem.getLocal(conf);
  HashSet<String> values=new HashSet<String>();
  String m="AAAAAAAAAAAAAA";
  for (int i=1; i < 11; ++i) {
    values.add(m);
    m=m.replace((char)('A' + i - 1),(char)('A' + i));
  }
  Path testdir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(fs);
  fs.delete(testdir,true);
  Path inFile=new Path(testdir,"nullin/blah");
  SequenceFile.Writer w=SequenceFile.createWriter(fs,conf,inFile,NullWritable.class,Text.class,SequenceFile.CompressionType.NONE);
  Text t=new Text();
  for (  String s : values) {
    t.set(s);
    w.append(NullWritable.get(),t);
  }
  w.close();
  FileInputFormat.setInputPaths(conf,inFile);
  FileOutputFormat.setOutputPath(conf,new Path(testdir,"nullout"));
  conf.setMapperClass(NullMapper.class);
  conf.setReducerClass(IdentityReducer.class);
  conf.setOutputKeyClass(NullWritable.class);
  conf.setOutputValueClass(Text.class);
  conf.setInputFormat(SequenceFileInputFormat.class);
  conf.setOutputFormat(SequenceFileOutputFormat.class);
  conf.setNumReduceTasks(1);
  JobClient.runJob(conf);
  SequenceFile.Reader r=new SequenceFile.Reader(fs,new Path(testdir,"nullout/part-00000"),conf);
  m="AAAAAAAAAAAAAA";
  for (int i=1; r.next(NullWritable.get(),t); ++i) {
    assertTrue("Unexpected value: " + t,values.remove(t.toString()));
    m=m.replace((char)('A' + i - 1),(char)('A' + i));
  }
  assertTrue("Missing values: " + values.toString(),values.isEmpty());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestPushConfig </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * This test about testing the pushConfig feature. The pushConfig functionality
 * available as part of the cluster process manager. The functionality takes
 * in local input directory and pushes all the files from the local to the 
 * remote conf directory. This functionality is required is change the config
 * on the fly and restart the cluster which will be used by other test cases
 * @throws Exception is thrown if pushConfig fails. 
 */
@Test public void testPushConfig() throws Exception {
  final String DUMMY_CONFIG_STRING="mapreduce.newdummy.conf";
  final String DUMMY_CONFIG_STRING_VALUE="HerriotTestRules";
  Configuration origconf=new Configuration(cluster.getConf());
  origconf.set(DUMMY_CONFIG_STRING,DUMMY_CONFIG_STRING_VALUE);
  String localDir=HadoopDaemonRemoteCluster.getDeployedHadoopConfDir() + File.separator + localConfDir;
  File lFile=new File(localDir);
  if (!lFile.exists()) {
    lFile.mkdir();
  }
  String mapredConf=localDir + File.separator + "mapred-site.xml";
  File file=new File(mapredConf);
  origconf.writeXml(new FileOutputStream(file));
  Configuration daemonConf=cluster.getJTClient().getProxy().getDaemonConf();
  Assert.assertTrue("Dummy varialble is expected to be null before restart.",daemonConf.get(DUMMY_CONFIG_STRING) == null);
  String newDir=cluster.getClusterManager().pushConfig(localDir);
  cluster.stop();
  AbstractDaemonClient cli=cluster.getJTClient();
  waitForClusterStop(cli);
  cluster.getClusterManager().start(newDir);
  cli=cluster.getJTClient();
  waitForClusterStart(cli);
  Configuration newconf=cluster.getJTClient().getProxy().getDaemonConf();
  Assert.assertTrue("Extra varialble is expected to be set",newconf.get(DUMMY_CONFIG_STRING).equals(DUMMY_CONFIG_STRING_VALUE));
  cluster.getClusterManager().stop(newDir);
  cli=cluster.getJTClient();
  waitForClusterStop(cli);
  cluster.getClusterManager().start();
  cli=cluster.getJTClient();
  waitForClusterStart(cli);
  daemonConf=cluster.getJTClient().getProxy().getDaemonConf();
  Assert.assertTrue("Dummy variable is expected to be null after restart.",daemonConf.get(DUMMY_CONFIG_STRING) == null);
  lFile.delete();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestQueueManager </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testhasAccess() throws Exception {
  deleteQueuesConfigFile();
  Document doc=createDocument();
  createSimpleDocumentWithAcls(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueManager qm=new QueueManager(QUEUES_CONFIG_FILE_PATH,true);
  UserGroupInformation ugi;
  ugi=createUGI("u1");
  assertTrue(qm.hasAccess("p1" + NAME_SEPARATOR + "p12",QueueACL.SUBMIT_JOB,ugi));
  ugi=createUGI("u2");
  assertTrue(qm.hasAccess("p1" + NAME_SEPARATOR + "p12",QueueACL.ADMINISTER_JOBS,ugi));
  ugi=createUGI("u1");
  assertTrue(qm.hasAccess("p1" + NAME_SEPARATOR + "p11",QueueACL.SUBMIT_JOB,ugi));
  ugi=createUGI("u2");
  assertTrue(qm.hasAccess("p1" + NAME_SEPARATOR + "p11",QueueACL.ADMINISTER_JOBS,ugi));
  ugi=createUGI("u1");
  assertFalse(qm.hasAccess("p1" + NAME_SEPARATOR + "p13",QueueACL.SUBMIT_JOB,ugi));
  ugi=createUGI("u2");
  assertFalse(qm.hasAccess("p1" + NAME_SEPARATOR + "p13",QueueACL.ADMINISTER_JOBS,ugi));
  assertTrue(qm.isRunning("p1" + NAME_SEPARATOR + "p13"));
}

</code></pre>

<br>
<pre class="type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the refresh of queues.
 * @throws Exception
 */
@Test public void testRefresh() throws Exception {
  deleteQueuesConfigFile();
  Document doc=createDocument();
  createSimpleDocument(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueManager qm=new QueueManager(QUEUES_CONFIG_FILE_PATH,true);
  Queue beforeRefreshRoot=qm.getRoot();
  Set<Queue> rootQueues=beforeRefreshRoot.getChildren();
  for (  Queue qs : rootQueues) {
    if (qs.getName().equals("q1")) {
      assertEquals(qs.getProperties().getProperty("capacity"),"10");
      assertEquals(qs.getProperties().getProperty("maxCapacity"),"35");
    }
 else     if (qs.getName().equals("p1")) {
      Set<Queue> children=qs.getChildren();
      for (      Queue child : children) {
        if (child.getName().equals("p1" + NAME_SEPARATOR + "p12")) {
          assertTrue(child.getAcls().get(toFullPropertyName(child.getName(),ACL_SUBMIT_JOB_TAG)).isUserAllowed(createUGI("u1")));
          assertTrue(child.getAcls().get(toFullPropertyName(child.getName(),ACL_ADMINISTER_JOB_TAG)).isUserAllowed(createUGI("u2")));
          assertTrue(child.getState().equals(QueueState.STOPPED));
        }
 else {
          assertTrue(child.getState().equals(QueueState.RUNNING));
        }
      }
    }
  }
  deleteQueuesConfigFile();
  doc=createDocument();
  refreshSimpleDocument(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueConfigurationParser cp=new QueueConfigurationParser(QUEUES_CONFIG_FILE_PATH,true);
  qm.getRoot().isHierarchySameAs(cp.getRoot());
  qm.setQueues(cp.getRoot().getChildren().toArray(new Queue[cp.getRoot().getChildren().size()]));
  Queue afterRefreshRoot=qm.getRoot();
  rootQueues=afterRefreshRoot.getChildren();
  for (  Queue qs : rootQueues) {
    if (qs.getName().equals("q1")) {
      assertEquals(qs.getProperties().getProperty("capacity"),"70");
      assertEquals(qs.getProperties().getProperty("maxCapacity"),"35");
    }
 else     if (qs.getName().equals("p1")) {
      Set<Queue> children=qs.getChildren();
      for (      Queue child : children) {
        if (child.getName().equals("p1" + NAME_SEPARATOR + "p12")) {
          assertTrue(child.getAcls().get(toFullPropertyName(child.getName(),ACL_SUBMIT_JOB_TAG)).isUserAllowed(createUGI("u3")));
          assertTrue(child.getAcls().get(toFullPropertyName(child.getName(),ACL_ADMINISTER_JOB_TAG)).isUserAllowed(createUGI("u4")));
          assertTrue(child.getState().equals(QueueState.RUNNING));
        }
 else {
          assertTrue(child.getState().equals(QueueState.STOPPED));
        }
      }
    }
  }
}

</code></pre>

<br>
<pre class="type-13 type-14 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testJobQueueInfoGeneration() throws Exception {
  deleteQueuesConfigFile();
  Document doc=createDocument();
  createSimpleDocument(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueManager qm=new QueueManager(QUEUES_CONFIG_FILE_PATH,true);
  List<JobQueueInfo> rootQueues=qm.getRoot().getJobQueueInfo().getChildren();
  assertEquals(rootQueues.size(),2);
  List<String> names=new ArrayList<String>();
  for (  JobQueueInfo q : rootQueues) {
    names.add(q.getQueueName());
    if (q.getQueueName().equals("q1")) {
      Properties p=q.getProperties();
      assertEquals(p.getProperty("capacity"),"10");
      assertEquals(p.getProperty("maxCapacity"),"35");
      assertTrue(q.getChildren().isEmpty());
    }
 else     if (q.getQueueName().equals("p1")) {
      List<JobQueueInfo> children=q.getChildren();
      assertEquals(children.size(),2);
      for (      JobQueueInfo child : children) {
        if (child.getQueueName().equals("p1" + NAME_SEPARATOR + "p12")) {
          assertEquals(child.getQueueState(),QueueState.STOPPED.getStateName());
        }
 else         if (child.getQueueName().equals("p1" + NAME_SEPARATOR + "p11")) {
          assertEquals(child.getQueueState(),QueueState.RUNNING.getStateName());
        }
 else {
          fail("Only 2 children");
        }
      }
    }
 else {
      fail("Only 2 queues with q1 and p1 ");
    }
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testXMLParsing() throws Exception {
  deleteQueuesConfigFile();
  Document doc=createDocument();
  createSimpleDocument(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueManager qm=new QueueManager(QUEUES_CONFIG_FILE_PATH,true);
  Set<Queue> rootQueues=qm.getRoot().getChildren();
  List<String> names=new ArrayList<String>();
  for (  Queue q : rootQueues) {
    names.add(q.getName());
  }
  assertEquals(rootQueues.size(),2);
  assertTrue(names.contains("q1"));
  assertTrue(names.contains("p1"));
  Set<String> leafNames=qm.getLeafQueueNames();
  Queue p=qm.getQueue("p1");
  Set<Queue> children=p.getChildren();
  assertTrue(children.size() == 2);
  assertTrue(leafNames.contains("p1" + NAME_SEPARATOR + "p11"));
  assertTrue(leafNames.contains("p1" + NAME_SEPARATOR + "p12"));
  Queue q=qm.getQueue("p1" + NAME_SEPARATOR + "p12");
  assertTrue(q.getAcls().get(toFullPropertyName(q.getName(),ACL_SUBMIT_JOB_TAG)).isUserAllowed(createUGI("u1")));
  assertTrue(q.getAcls().get(toFullPropertyName(q.getName(),ACL_ADMINISTER_JOB_TAG)).isUserAllowed(createUGI("u2")));
  assertTrue(q.getState().equals(QueueState.STOPPED));
}

</code></pre>

<br>
<pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testhasAccessForParent() throws Exception {
  deleteQueuesConfigFile();
  Document doc=createDocument();
  createSimpleDocument(doc);
  writeToFile(doc,QUEUES_CONFIG_FILE_PATH);
  QueueManager qm=new QueueManager(QUEUES_CONFIG_FILE_PATH,true);
  UserGroupInformation ugi=createUGI("u1");
  assertFalse(qm.hasAccess("p1",QueueACL.SUBMIT_JOB,ugi));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestQueueManagerWithJobTracker </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests job submission when acls are disabled
 * @throws Exception
 */
@Test public void testAclsDisabled() throws Exception {
  startCluster(false);
  Job job=submitSleepJob(0,0,0,0,true,"u2,g1","p1" + NAME_SEPARATOR + "p11",conf);
  assertTrue("Job submitted for u2 in queue p1:p11 is not successful.",job.isSuccessful());
  job=submitSleepJob(0,0,0,0,true,"u1,g1","p1" + NAME_SEPARATOR + "p11",conf);
  assertTrue("Job submitted for u2 in queue p1:p11 is not successful.",job.isSuccessful());
  job=submitSleepJob(1,1,0,0,false,"u1,g1","p1" + NAME_SEPARATOR + "p11",conf);
  final JobConf jobConf=miniMRCluster.createJobConf();
  UserGroupInformation ugi=UserGroupInformation.createUserForTesting("u3",new String[]{"g3"});
  Cluster cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
    public Cluster run() throws IOException {
      return new Cluster(jobConf);
    }
  }
);
  JobID jobID=job.getStatus().getJobID();
  JobInProgress jip=miniMRCluster.getJobTrackerRunner().getJobTracker().getJob(org.apache.hadoop.mapred.JobID.downgrade(jobID));
  miniMRCluster.getJobTrackerRunner().getJobTracker().initJob(jip);
  cluster.getJob(jobID).killJob();
  assertEquals("job submitted for u1 and queue p1:p11 is not killed.",cluster.getJob(jobID).getStatus().getState(),(State.KILLED));
}

</code></pre>

<br>
<pre class="type-10 type-14 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests the accessibility to kill a job
 * @throws Exception
 */
@Test public void testAccessToKillJob() throws Exception {
  startCluster(true);
  Job job=submitSleepJob(1,1,100,100,false,"u1,g1","p1" + NAME_SEPARATOR + "p11",conf);
  final JobConf jobConf=miniMRCluster.createJobConf();
  Cluster cluster=null;
  JobID jobID=job.getStatus().getJobID();
  JobTracker tracker=miniMRCluster.getJobTrackerRunner().getJobTracker();
  JobInProgress jip=tracker.getJob(org.apache.hadoop.mapred.JobID.downgrade(jobID));
  tracker.initJob(jip);
  try {
    final Configuration userConf=new Configuration(miniMRCluster.createJobConf());
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting("someRandomUser",new String[]{"someRandomGroup"});
    cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
      public Cluster run() throws IOException {
        return new Cluster(userConf);
      }
    }
);
    cluster.getJob(jobID).killJob();
    fail("user 'someRandomeUser' is neither u1 nor in the administer group list");
  }
 catch (  Exception e) {
    final Configuration userConf=new Configuration(miniMRCluster.createJobConf());
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting("u1",new String[]{"g1"});
    cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
      public Cluster run() throws IOException {
        return new Cluster(userConf);
      }
    }
);
    cluster.getJob(jobID).killJob();
    assertEquals("job submitted for u1 and queue p1:p11 is not killed.",cluster.getJob(jobID).getStatus().getState(),(State.KILLED));
  }
  job=submitSleepJob(1,1,100,100,false,"u1,g1","p1" + NAME_SEPARATOR + "p12",conf);
  jobID=job.getStatus().getJobID();
  jip=tracker.getJob(org.apache.hadoop.mapred.JobID.downgrade(jobID));
  tracker.initJob(jip);
  tracker.killJob(job.getJobID());
  assertEquals("job submitted for u1 and queue p1:p11 is not killed.",cluster.getJob(jobID).getStatus().getState(),(State.KILLED));
  final Configuration userConf=new Configuration(miniMRCluster.createJobConf());
  UserGroupInformation ugi=UserGroupInformation.createUserForTesting("u1",new String[]{"g1"});
  cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
    public Cluster run() throws IOException {
      return new Cluster(userConf);
    }
  }
);
  job=submitSleepJob(1,1,10,10,false,"u1,g1","p1" + NAME_SEPARATOR + "p11",conf);
  jobID=job.getStatus().getJobID();
  jip=tracker.getJob(org.apache.hadoop.mapred.JobID.downgrade(jobID));
  tracker.initJob(jip);
  ugi=UserGroupInformation.createUserForTesting("u3",new String[]{"g3"});
  cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
    public Cluster run() throws IOException {
      return new Cluster(jobConf);
    }
  }
);
  try {
    cluster.getJob(jobID).killJob();
    fail("u3 not in administer list");
  }
 catch (  Exception e) {
    ugi=UserGroupInformation.createUserForTesting("u1",new String[]{"g1"});
    cluster=ugi.doAs(new PrivilegedExceptionAction<Cluster>(){
      public Cluster run() throws IOException {
        return new Cluster(jobConf);
      }
    }
);
    assertFalse(cluster.getJob(jobID).isComplete());
    cluster.getJob(jobID).killJob();
    assertEquals("job submitted for u1 and queue p1:p11 is not killed.",cluster.getJob(jobID).getStatus().getState(),(State.KILLED));
  }
  ugi=UserGroupInformation.createUserForTesting("adminUser",new String[]{"g3"});
  checkAccessToKill(tracker,jobConf,ugi);
  ugi=UserGroupInformation.createUserForTesting("u3",new String[]{adminGroup});
  checkAccessToKill(tracker,jobConf,ugi);
  ugi=UserGroupInformation.createUserForTesting("u3",new String[]{deprecatedSuperGroup});
  checkAccessToKill(tracker,jobConf,ugi);
}

</code></pre>

<br>
<pre class="type-10 type-14 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests the submission of job with specified acls
 * @throws Exception
 */
@Test public void testAclsForSubmitJob() throws Exception {
  startCluster(true);
  Job job;
  try {
    job=submitSleepJob(0,0,0,0,true,"u1,g1","p1" + NAME_SEPARATOR + "p13",conf);
    fail("user u1 cannot submit jobs to queue p1:p13");
  }
 catch (  Exception e) {
  }
  job=submitSleepJob(0,0,0,0,true,adminUser + ",g1","p1" + NAME_SEPARATOR + "p13",conf);
  assertTrue("Admin user cannot submit jobs to queue p1:p13",job.isSuccessful());
  job=submitSleepJob(0,0,0,0,true,"u1," + adminGroup,"p1" + NAME_SEPARATOR + "p13",conf);
  assertTrue("Admin group member cannot submit jobs to queue p1:p13",job.isSuccessful());
  job=submitSleepJob(0,0,0,0,true,"u1," + deprecatedSuperGroup,"p1" + NAME_SEPARATOR + "p13",conf);
  assertTrue("Deprecated super group member cannot submit jobs to queue" + " p1:p13",job.isSuccessful());
  try {
    job=submitSleepJob(0,0,0,0,false,"u2,g1","p1" + NAME_SEPARATOR + "p11",conf);
    fail("user u2 cannot submit jobs to queue p1:p11");
  }
 catch (  Exception e) {
  }
  job=submitSleepJob(0,0,0,0,true,"u1,g1","p1" + NAME_SEPARATOR + "p11",conf);
  assertTrue("Job submission for u1 failed in queue : p1:p11.",job.isSuccessful());
  job=submitSleepJob(0,0,0,0,true,"u2,g1","p1" + NAME_SEPARATOR + "p12",conf);
  assertTrue("Job submission for u2 failed in queue : p1:p12.",job.isSuccessful());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestRefreshOfQueues </h4><pre class="type-14 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test to verify that the refresh of the scheduler fails when modified
 * configuration overflows 100%
 * @throws Throwable
 */
@Test public void testFailingCapacityRefresh() throws Throwable {
  JobQueueInfo[] queues=TestQueueManagerRefresh.getSimpleQueueHierarchy();
  queues[0].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(100));
  queues[1].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(70));
  queues[2].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(50));
  QueueManagerTestUtils.writeQueueConfigurationFile(queueConfigFile.getAbsolutePath(),new JobQueueInfo[]{queues[0]});
  try {
    setupAndStartSchedulerFramework(2,2,2);
    fail("Scheduler should have failed to start!");
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().contains(String.format(QueueHierarchyBuilder.TOTAL_CAPACITY_OVERFLOWN_MSG,queues[1].getQueueName() + "," + queues[2].getQueueName(),Float.valueOf(120.0f))));
  }
  queues[1].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(50));
  QueueManagerTestUtils.writeQueueConfigurationFile(queueConfigFile.getAbsolutePath(),new JobQueueInfo[]{queues[0]});
  setupAndStartSchedulerFramework(2,2,2);
  queues[1].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(35));
  queues[2].getProperties().setProperty(CapacitySchedulerConf.CAPACITY_PROPERTY,String.valueOf(95));
  QueueManagerTestUtils.writeQueueConfigurationFile(queueConfigFile.getAbsolutePath(),new JobQueueInfo[]{queues[0]});
  try {
    refreshQueues(taskTrackerManager.getQueueManager(),null,scheduler);
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().contains(String.format(QueueHierarchyBuilder.TOTAL_CAPACITY_OVERFLOWN_MSG,queues[1].getQueueName() + "," + queues[2].getQueueName(),Float.valueOf(130.0f))));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestRemoveIpsFromLoggedNetworkTopology </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testIsIPAddress(){
  final String[] positives={"123.13.42.255","123.01.0.255","000.001.002.020","123\\.13\\.42\\.255","0.0.0.0","255.255.255.255","1080:0:0:0:8:800:200C:417A","1080:01:020:3:8:0800:200C:417A","1080:01:002:0003:080:0800:0200:417A","0:0:0:0:0:0:0:0","ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff"};
  final String[] negatives={"node.megatron.com","13.42.255","123.13.42.255.10","123.256.42.255","123.13.42.255.weird.com","1080:0:0:0:8:200C:417A","1080:0:0:0:1:8:800:200C:417A","1080A:0:0:0:8:800:200C:417A","1080:0:0:0:8:800:200G:417A"};
  for (  String s : positives) {
    Assert.assertTrue(s,SimulatorEngine.isIPAddress(s));
  }
  for (  String s : negatives) {
    Assert.assertFalse(s,SimulatorEngine.isIPAddress(s));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestReporter </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test {@link Reporter}'s progress for a map-only job.
 * This will make sure that only the map phase decides the attempt's progress.
 */
@SuppressWarnings("deprecation") @Test public void testReporterProgressForMapOnlyJob() throws IOException {
  Path test=new Path(testRootTempDir,"testReporterProgressForMapOnlyJob");
  JobConf conf=new JobConf();
  conf.setMapperClass(ProgressTesterMapper.class);
  conf.setMapOutputKeyClass(Text.class);
  conf.setMaxMapAttempts(1);
  conf.setMaxReduceAttempts(0);
  RunningJob job=UtilsForTests.runJob(conf,new Path(test,"in"),new Path(test,"out"),1,0,INPUT);
  job.waitForCompletion();
  assertTrue("Job failed",job.isSuccessful());
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test {@link Reporter}'s progress for map-reduce job.
 */
@SuppressWarnings("deprecation") @Test public void testReporterProgressForMRJob() throws IOException {
  Path test=new Path(testRootTempDir,"testReporterProgressForMRJob");
  JobConf conf=new JobConf();
  conf.setMapperClass(ProgressTesterMapper.class);
  conf.setReducerClass(ProgressTestingReducer.class);
  conf.setMapOutputKeyClass(Text.class);
  conf.setMaxMapAttempts(1);
  conf.setMaxReduceAttempts(1);
  RunningJob job=UtilsForTests.runJob(conf,new Path(test,"in"),new Path(test,"out"),1,1,INPUT);
  job.waitForCompletion();
  assertTrue("Job failed",job.isSuccessful());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestShuffleJobToken </h4><pre class="type-3 type-13 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void setUp() throws Exception {
  dir=new File(System.getProperty("build.webapps","build/webapps") + "/test");
  System.out.println("dir=" + dir.getAbsolutePath());
  if (!dir.exists()) {
    assertTrue(dir.mkdirs());
  }
  server=new HttpServer("test","0.0.0.0",0,true);
  server.addServlet("shuffle","/mapOutput",TaskTracker.MapOutputServlet.class);
  server.start();
  int port=server.getPort();
  baseUrl=new URL("http://localhost:" + port + "/");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestSimulatorEventQueue </h4><pre class="type-11 type-13 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testKeepOrder(){
  SimulatorEventQueue queue=new SimulatorEventQueue();
  SimulatorEventListener listener=new TestListener();
  List<SimulatorEvent> listEvent=new ArrayList<SimulatorEvent>();
  int count=0;
  for (int i=0; i < random.nextInt(100); i++) {
    listEvent.clear();
    for (int j=0; j < random.nextInt(5); j++) {
      listEvent.add(new TestEventWithCount(listener,random.nextInt(10),count++));
    }
    queue.addAll(listEvent);
  }
  TestEventWithCount next;
  TestEventWithCount last=null;
  while ((next=(TestEventWithCount)queue.get()) != null) {
    if (last != null && last.getTimeStamp() == next.getTimeStamp()) {
      Assert.assertTrue(last.getCount() < next.getCount());
    }
    last=next;
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestSimulatorJobTracker </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testTrackerInteraction() throws IOException, InterruptedException {
  LOG.info("Testing Inter Tracker protocols");
  int now=0;
  JobConf jtConf=createJobConf();
  int NoMaps=2;
  int NoReduces=10;
  jtConf.set("fs.default.name","file:///");
  jtConf.set("mapred.jobtracker.taskScheduler",JobQueueTaskScheduler.class.getName());
  SimulatorJobTracker sjobTracker=SimulatorJobTracker.startTracker(jtConf,0);
  System.out.println("Created the SimulatorJobTracker successfully");
  sjobTracker.offerService();
  FakeJobClient jbc=new FakeJobClient(sjobTracker,NoMaps,NoReduces);
  int NoJobs=1;
  for (int i=0; i < NoJobs; i++) {
    jbc.submitNewJob();
  }
  org.apache.hadoop.mapreduce.JobStatus[] allJobs=sjobTracker.getAllJobs();
  Assert.assertTrue("allJobs queue length is " + allJobs.length,allJobs.length >= 1);
  for (  org.apache.hadoop.mapreduce.JobStatus js : allJobs) {
    LOG.info("From JTQueue: job id = " + js.getJobID());
  }
  Configuration ttConf=new Configuration();
  ttConf.set("mumak.tasktracker.tracker.name","tracker_host1.foo.com:localhost/127.0.0.1:9010");
  ttConf.set("mumak.tasktracker.host.name","host1.foo.com");
  ttConf.setInt("mapred.tasktracker.map.tasks.maximum",10);
  ttConf.setInt("mapred.tasktracker.reduce.tasks.maximum",10);
  ttConf.setInt("mumak.tasktracker.heartbeat.fuzz",-1);
  FakeTaskTracker fakeTracker=new FakeTaskTracker(sjobTracker,ttConf);
  int numLaunchTaskActions=0;
  for (int i=0; i < NoMaps * 2; ++i) {
    numLaunchTaskActions+=fakeTracker.sendFakeHeartbeat(now);
    if (numLaunchTaskActions >= NoMaps) {
      break;
    }
    now+=5;
    LOG.debug("Number of MapLaunchTasks=" + numLaunchTaskActions + " now = "+ now);
  }
  Assert.assertTrue("Failed to launch all maps: " + numLaunchTaskActions,numLaunchTaskActions >= NoMaps);
  LOG.info("Sending task completed status");
  numLaunchTaskActions+=fakeTracker.sendFakeHeartbeat(now);
  for (int i=0; i < NoReduces * 2; ++i) {
    if (numLaunchTaskActions >= NoMaps + NoReduces) {
      break;
    }
    numLaunchTaskActions+=fakeTracker.sendFakeHeartbeat(now);
    now+=5;
    LOG.debug("Number of ReduceLaunchTasks=" + numLaunchTaskActions + " now = "+ now);
  }
  Assert.assertTrue("Failed to launch all reduces: " + numLaunchTaskActions,numLaunchTaskActions >= NoMaps + NoReduces);
  numLaunchTaskActions+=fakeTracker.sendFakeHeartbeat(now);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskKilling </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Verifying whether task temporary output directory is cleaned up or not
 * after killing the task.
 */
@Test public void testDirCleanupAfterTaskKilled() throws IOException, InterruptedException {
  TaskInfo taskInfo=null;
  boolean isTempFolderExists=false;
  String localTaskDir=null;
  TTClient ttClient=null;
  TaskID tID=null;
  FileStatus filesStatus[]=null;
  Path inputDir=new Path("input");
  Path outputDir=new Path("output");
  Configuration conf=new Configuration(cluster.getConf());
  JobConf jconf=new JobConf(conf);
  jconf.setJobName("Word Count");
  jconf.setJarByClass(WordCount.class);
  jconf.setMapperClass(WordCount.MapClass.class);
  jconf.setCombinerClass(WordCount.Reduce.class);
  jconf.setReducerClass(WordCount.Reduce.class);
  jconf.setNumMapTasks(1);
  jconf.setNumReduceTasks(1);
  jconf.setMaxMapAttempts(20);
  jconf.setMaxReduceAttempts(20);
  jconf.setOutputKeyClass(Text.class);
  jconf.setOutputValueClass(IntWritable.class);
  cleanup(inputDir,conf);
  cleanup(outputDir,conf);
  createInput(inputDir,conf);
  FileInputFormat.setInputPaths(jconf,inputDir);
  FileOutputFormat.setOutputPath(jconf,outputDir);
  RunningJob runJob=jobClient.submitJob(jconf);
  JobID id=runJob.getID();
  JobInfo jInfo=remoteJTClient.getJobInfo(id);
  int counter=0;
  while (counter < 60) {
    if (jInfo.getStatus().getRunState() == JobStatus.RUNNING) {
      break;
    }
 else {
      UtilsForTests.waitFor(1000);
      jInfo=remoteJTClient.getJobInfo(id);
    }
    counter++;
  }
  Assert.assertTrue("Job has not been started for 1 min.",counter != 60);
  JobStatus[] jobStatus=jobClient.getAllJobs();
  String userName=jobStatus[0].getUsername();
  TaskInfo[] taskInfos=remoteJTClient.getTaskInfo(id);
  for (  TaskInfo taskinfo : taskInfos) {
    if (!taskinfo.isSetupOrCleanup()) {
      taskInfo=taskinfo;
      break;
    }
  }
  counter=0;
  while (counter < 30) {
    if (taskInfo.getTaskStatus().length > 0) {
      if (taskInfo.getTaskStatus()[0].getRunState() == TaskStatus.State.RUNNING) {
        break;
      }
    }
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
    counter++;
  }
  Assert.assertTrue("Task has not been started for 30 sec.",counter != 30);
  tID=TaskID.downgrade(taskInfo.getTaskID());
  FinishTaskControlAction action=new FinishTaskControlAction(tID);
  String[] taskTrackers=taskInfo.getTaskTrackers();
  counter=0;
  while (counter < 30) {
    if (taskTrackers.length != 0) {
      break;
    }
    UtilsForTests.waitFor(100);
    taskTrackers=taskInfo.getTaskTrackers();
    counter++;
  }
  String hostName=taskTrackers[0].split("_")[1];
  hostName=hostName.split(":")[0];
  ttClient=cluster.getTTClient(hostName);
  ttClient.getProxy().sendAction(action);
  String localDirs[]=ttClient.getMapredLocalDirs();
  TaskAttemptID taskAttID=new TaskAttemptID(tID,0);
  for (  String localDir : localDirs) {
    localTaskDir=localDir + "/" + TaskTracker.getLocalTaskDir(userName,id.toString(),taskAttID.toString());
    filesStatus=ttClient.listStatus(localTaskDir,true);
    if (filesStatus.length > 0) {
      isTempFolderExists=true;
      NetworkedJob networkJob=new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster);
      networkJob.killTask(taskAttID,false);
      break;
    }
  }
  Assert.assertTrue("Task Attempt directory " + taskAttID + " has not been found while task was running.",isTempFolderExists);
  taskInfo=remoteJTClient.getTaskInfo(tID);
  counter=0;
  while (counter < 60) {
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(tID);
    filesStatus=ttClient.listStatus(localTaskDir,true);
    if (filesStatus.length == 0) {
      break;
    }
    counter++;
  }
  Assert.assertTrue("Task attempt temporary folder has not been cleaned.",isTempFolderExists && filesStatus.length == 0);
  counter=0;
  while (counter < 30) {
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(tID);
    counter++;
  }
  taskInfo=remoteJTClient.getTaskInfo(tID);
  Assert.assertEquals("Task status has not been changed to KILLED.",TaskStatus.State.KILLED,taskInfo.getTaskStatus()[0].getRunState());
}

</code></pre>

<br>
<pre class="type-11 type-13 type-14 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testAllTaskAttemptKill() throws Exception {
  Configuration conf=new Configuration(cluster.getConf());
  JobStatus[] jobStatus=null;
  SleepJob job=new SleepJob();
  job.setConf(conf);
  Job slpJob=job.createJob(3,1,40000,1000,100,100);
  JobConf jconf=new JobConf(conf);
  slpJob.submit();
  RunningJob rJob=cluster.getJTClient().getClient().getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
  int MAX_MAP_TASK_ATTEMPTS=Integer.parseInt(jconf.get(MRJobConfig.MAP_MAX_ATTEMPTS));
  LOG.info("MAX_MAP_TASK_ATTEMPTS is : " + MAX_MAP_TASK_ATTEMPTS);
  Assert.assertTrue(MAX_MAP_TASK_ATTEMPTS > 0);
  TTClient tClient=null;
  TTClient[] ttClients=null;
  JobInfo jInfo=remoteJTClient.getJobInfo(rJob.getID());
  Assert.assertNotNull(jInfo.getStatus().getRunState());
  while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
    try {
      Thread.sleep(10000);
    }
 catch (    InterruptedException e) {
    }
    ;
    jInfo=remoteJTClient.getJobInfo(rJob.getID());
  }
  JobID jobidStore=rJob.getID();
  jobidStore=JobID.downgrade(jobidStore);
  LOG.info("job id is :" + jobidStore.toString());
  TaskInfo[] taskInfos=null;
  boolean runningCount=false;
  int count=0;
  do {
    taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    runningCount=false;
    for (    TaskInfo taskInfo : taskInfos) {
      TaskStatus[] taskStatuses=taskInfo.getTaskStatus();
      if (taskStatuses.length > 0) {
        LOG.info("taskStatuses[0].getRunState() is :" + taskStatuses[0].getRunState());
        if (taskStatuses[0].getRunState() == TaskStatus.State.RUNNING) {
          runningCount=true;
          break;
        }
 else {
          LOG.info("Sleeping 5 seconds");
          Thread.sleep(5000);
        }
      }
    }
    count++;
    if (count > 10) {
      Assert.fail("Since the sleep count has reached beyond a point" + "failing at this point");
    }
  }
 while (!runningCount);
  String taskIdKilled=null;
  for (int i=0; i < MAX_MAP_TASK_ATTEMPTS; i++) {
    taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    for (    TaskInfo taskInfo : taskInfos) {
      TaskAttemptID taskAttemptID;
      if (!taskInfo.isSetupOrCleanup()) {
        TaskID taskid=TaskID.downgrade(taskInfo.getTaskID());
        LOG.info("taskid is :" + taskid);
        if (i == 0) {
          taskIdKilled=taskid.toString();
          taskAttemptID=new TaskAttemptID(taskid,i);
          LOG.info("taskAttemptid going to be killed is : " + taskAttemptID);
          (new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster)).killTask(taskAttemptID,true);
          checkTaskCompletionEvent(taskAttemptID,jInfo);
          break;
        }
 else {
          if (taskIdKilled.equals(taskid.toString())) {
            taskAttemptID=new TaskAttemptID(taskid,i);
            LOG.info("taskAttemptid going to be killed is : " + taskAttemptID);
            (new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster)).killTask(taskAttemptID,true);
            checkTaskCompletionEvent(taskAttemptID,jInfo);
            break;
          }
        }
      }
    }
  }
  while (jInfo != null && !jInfo.getStatus().isJobComplete()) {
    Thread.sleep(10000);
    jInfo=remoteJTClient.getJobInfo(rJob.getID());
  }
  jobStatus=jobClient.getAllJobs();
  JobStatus jobStatusFound=null;
  for (  JobStatus jobStatusTmp : jobStatus) {
    if (JobID.downgrade(jobStatusTmp.getJobID()).equals(jobidStore)) {
      jobStatusFound=jobStatusTmp;
      LOG.info("jobStatus found is :" + jobStatusFound.getJobId().toString());
    }
  }
  Assert.assertEquals("The job should have failed at this stage",JobStatus.FAILED,jobStatusFound.getRunState());
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Verifying whether task temporary output directory is cleaned up or not
 * after failing the task.
 */
@Test public void testDirCleanupAfterTaskFailed() throws IOException, InterruptedException {
  TTClient ttClient=null;
  FileStatus filesStatus[]=null;
  String localTaskDir=null;
  TaskInfo taskInfo=null;
  TaskID tID=null;
  boolean isTempFolderExists=false;
  Path inputDir=new Path("input");
  Path outputDir=new Path("output");
  Configuration conf=new Configuration(cluster.getConf());
  JobConf jconf=new JobConf(conf);
  jconf.setJobName("Task Failed job");
  jconf.setJarByClass(UtilsForTests.class);
  jconf.setMapperClass(FailedMapperClass.class);
  jconf.setNumMapTasks(1);
  jconf.setNumReduceTasks(0);
  jconf.setMaxMapAttempts(1);
  cleanup(inputDir,conf);
  cleanup(outputDir,conf);
  createInput(inputDir,conf);
  FileInputFormat.setInputPaths(jconf,inputDir);
  FileOutputFormat.setOutputPath(jconf,outputDir);
  RunningJob runJob=jobClient.submitJob(jconf);
  JobID id=runJob.getID();
  JobInfo jInfo=remoteJTClient.getJobInfo(id);
  int counter=0;
  while (counter < 60) {
    if (jInfo.getStatus().getRunState() == JobStatus.RUNNING) {
      break;
    }
 else {
      UtilsForTests.waitFor(1000);
      jInfo=remoteJTClient.getJobInfo(id);
    }
    counter++;
  }
  Assert.assertTrue("Job has not been started for 1 min.",counter != 60);
  JobStatus[] jobStatus=jobClient.getAllJobs();
  String userName=jobStatus[0].getUsername();
  TaskInfo[] taskInfos=remoteJTClient.getTaskInfo(id);
  for (  TaskInfo taskinfo : taskInfos) {
    if (!taskinfo.isSetupOrCleanup()) {
      taskInfo=taskinfo;
      break;
    }
  }
  tID=TaskID.downgrade(taskInfo.getTaskID());
  FinishTaskControlAction action=new FinishTaskControlAction(tID);
  String[] taskTrackers=taskInfo.getTaskTrackers();
  counter=0;
  while (counter < 30) {
    if (taskTrackers.length != 0) {
      break;
    }
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
    taskTrackers=taskInfo.getTaskTrackers();
    counter++;
  }
  Assert.assertTrue("Task tracker not found.",taskTrackers.length != 0);
  String hostName=taskTrackers[0].split("_")[1];
  hostName=hostName.split(":")[0];
  ttClient=cluster.getTTClient(hostName);
  ttClient.getProxy().sendAction(action);
  counter=0;
  while (counter < 60) {
    if (taskInfo.getTaskStatus().length > 0) {
      if (taskInfo.getTaskStatus()[0].getRunState() == TaskStatus.State.RUNNING) {
        break;
      }
    }
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
    counter++;
  }
  Assert.assertTrue("Task has not been started for 1 min.",counter != 60);
  String localDirs[]=ttClient.getMapredLocalDirs();
  TaskAttemptID taskAttID=new TaskAttemptID(tID,0);
  for (  String localDir : localDirs) {
    localTaskDir=localDir + "/" + TaskTracker.getLocalTaskDir(userName,id.toString(),taskAttID.toString());
    filesStatus=ttClient.listStatus(localTaskDir,true);
    if (filesStatus.length > 0) {
      isTempFolderExists=true;
      break;
    }
  }
  taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
  Assert.assertTrue("Task Attempt directory " + taskAttID + " has not been found while task was running.",isTempFolderExists);
  counter=0;
  while (counter < 30) {
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(tID);
    counter++;
  }
  Assert.assertEquals("Task status has not been changed to FAILED.",taskInfo.getTaskStatus()[0].getRunState(),TaskStatus.State.FAILED);
  filesStatus=ttClient.listStatus(localTaskDir,true);
  Assert.assertTrue("Temporary folder has not been cleanup.",filesStatus.length == 0);
}

</code></pre>

<br>
<pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Verifying the running job status whether it succeeds or not after failing
 * some of its tasks.
 * @throws ClassNotFoundException
 */
@Test public void testFailedTaskJobStatus() throws IOException, InterruptedException, ClassNotFoundException {
  Configuration conf=new Configuration(cluster.getConf());
  TaskInfo taskInfo=null;
  SleepJob job=new SleepJob();
  job.setConf(conf);
  Job slpJob=job.createJob(3,1,4000,4000,100,100);
  JobConf jobConf=new JobConf(conf);
  jobConf.setMaxMapAttempts(20);
  jobConf.setMaxReduceAttempts(20);
  slpJob.submit();
  RunningJob runJob=jobClient.getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
  JobID id=runJob.getID();
  JobInfo jInfo=remoteJTClient.getJobInfo(id);
  int counter=0;
  while (counter < 60) {
    if (jInfo.getStatus().getRunState() == JobStatus.RUNNING) {
      break;
    }
 else {
      UtilsForTests.waitFor(1000);
      jInfo=remoteJTClient.getJobInfo(id);
    }
    counter++;
  }
  Assert.assertTrue("Job has not been started for 1 min.",counter != 60);
  TaskInfo[] taskInfos=remoteJTClient.getTaskInfo(id);
  for (  TaskInfo taskinfo : taskInfos) {
    if (!taskinfo.isSetupOrCleanup()) {
      taskInfo=taskinfo;
    }
  }
  counter=0;
  taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
  while (counter < 60) {
    if (taskInfo.getTaskStatus().length > 0) {
      if (taskInfo.getTaskStatus()[0].getRunState() == TaskStatus.State.RUNNING) {
        break;
      }
    }
    UtilsForTests.waitFor(1000);
    taskInfo=remoteJTClient.getTaskInfo(taskInfo.getTaskID());
    counter++;
  }
  Assert.assertTrue("Task has not been started for 1 min.",counter != 60);
  NetworkedJob networkJob=new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster);
  TaskID tID=TaskID.downgrade(taskInfo.getTaskID());
  TaskAttemptID taskAttID=new TaskAttemptID(tID,0);
  networkJob.killTask(taskAttID,false);
  LOG.info("Waiting till the job is completed...");
  while (!jInfo.getStatus().isJobComplete()) {
    UtilsForTests.waitFor(100);
    jInfo=remoteJTClient.getJobInfo(id);
  }
  Assert.assertEquals("JobStatus",jInfo.getStatus().getRunState(),JobStatus.SUCCEEDED);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskLogServlet </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testHtmlLogs() throws Exception {
  String attemptIdStr="attempt_123_0001_m_000001_0";
  setupValidLogs(attemptIdStr);
  HttpTester request=new HttpTester();
  request.setMethod("GET");
  request.setURI("/tasklog?attemptid=" + attemptIdStr);
  request.setVersion("HTTP/1.0");
  HttpTester response=doRequest(request);
  assertEquals(HttpServletResponse.SC_OK,response.getStatus());
  assertEquals("text/html; charset=utf-8",response.getHeader("content-type"));
  assertTrue(response.getContent().contains("&lt;b&gt;this is stderr"));
  assertTrue(response.getContent().contains("&lt;b&gt;this is stdout"));
  assertTrue(response.getContent().contains("&lt;b&gt;this is syslog"));
  request.setURI("/tasklog?attemptid=" + attemptIdStr + "&start=1&end=6");
  response=doRequest(request);
  assertEquals(HttpServletResponse.SC_OK,response.getStatus());
  assertEquals("text/html; charset=utf-8",response.getHeader("content-type"));
  assertFalse(response.getContent().contains("&lt;b"));
  assertFalse(response.getContent().contains("this is"));
  assertTrue(response.getContent().contains("b&gt;thi</pre>"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskOutputSize </h4><pre class="type-10 type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testTaskOutputSize() throws Exception {
  MiniMRCluster mr=new MiniMRCluster(1,"file:///",1);
  Path inDir=new Path(rootDir,"input");
  Path outDir=new Path(rootDir,"output");
  Job job=MapReduceTestUtil.createJob(mr.createJobConf(),inDir,outDir,1,1);
  job.waitForCompletion(true);
  assertTrue("Job failed",job.isSuccessful());
  JobTracker jt=mr.getJobTrackerRunner().getJobTracker();
  for (  TaskCompletionEvent tce : job.getTaskCompletionEvents(0,100)) {
    TaskStatus ts=jt.getTaskStatus(TaskAttemptID.downgrade(tce.getTaskAttemptId()));
    if (tce.isMapTask()) {
      assertTrue("map output size is not found for " + tce.getTaskAttemptId(),ts.getOutputSize() > 0);
    }
 else {
      assertEquals("task output size not expected for " + tce.getTaskAttemptId(),-1,ts.getOutputSize());
    }
  }
  job=MapReduceTestUtil.createJob(mr.createJobConf(),inDir,outDir,1,0);
  job.waitForCompletion(true);
  assertTrue("Job failed",job.isSuccessful());
  for (  TaskCompletionEvent tce : job.getTaskCompletionEvents(0,100)) {
    TaskStatus ts=jt.getTaskStatus(TaskAttemptID.downgrade(tce.getTaskAttemptId()));
    assertEquals("task output size not expected for " + tce.getTaskAttemptId(),-1,ts.getOutputSize());
  }
  job=MapReduceTestUtil.createFailJob(mr.createJobConf(),outDir,inDir);
  job.waitForCompletion(true);
  assertFalse("Job not failed",job.isSuccessful());
  for (  TaskCompletionEvent tce : job.getTaskCompletionEvents(0,100)) {
    TaskStatus ts=jt.getTaskStatus(TaskAttemptID.downgrade(tce.getTaskAttemptId()));
    assertEquals("task output size not expected for " + tce.getTaskAttemptId(),-1,ts.getOutputSize());
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskTrackerDirectories </h4><pre class="type-3 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void deleteTestDir() throws IOException {
  FileUtil.fullyDelete(new File(TEST_DIR));
  assertFalse("Could not delete " + TEST_DIR,new File(TEST_DIR).exists());
}

</code></pre>

<br>
<pre class="type-14 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * If the log dir can't be created, the TT should fail to start since
 * it will be unable to localize or run tasks.
 */
@Test public void testCantCreateLogDir() throws Exception {
  File dir=TaskLog.getUserLogDir();
  FileUtil.fullyDelete(dir);
  assertTrue("Making file in place of log dir",dir.createNewFile());
  try {
    setupTaskController(new Configuration());
    fail("Didn't throw!");
  }
 catch (  IOException ioe) {
    System.err.println("Got expected exception");
    ioe.printStackTrace(System.out);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskTrackerMemoryManager </h4><pre class="type-10 type-11 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies boolean conditions
"></span><br>
/** 
 * Test for verifying that tasks causing cumulative usage to go beyond TT's
 * limit get killed even though they all are under individual limits. Memory
 * management for tasks with disabled task-limits also traverses the same
 * code-path, so we don't need a separate testTaskLimitsDisabled.
 * @throws Exception
 */
@Test public void testTasksCumulativelyExceedingTTLimits() throws Exception {
  if (!isProcfsBasedTreeAvailable()) {
    return;
  }
  long PER_TASK_LIMIT=100 * 1024L;
  JobConf fConf=new JobConf();
  fConf.setLong(MRConfig.MAPMEMORY_MB,1L);
  fConf.setLong(MRConfig.REDUCEMEMORY_MB,1L);
  long TASK_TRACKER_LIMIT=2 * 1024 * 1024L;
  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);
  startCluster(fConf);
  Pattern taskOverLimitPattern=Pattern.compile(String.format(taskOverLimitPatternString,String.valueOf(PER_TASK_LIMIT)));
  Pattern trackerOverLimitPattern=Pattern.compile("Killing one of the least progress tasks - .*, as " + "the cumulative memory usage of all the tasks on the TaskTracker" + " exceeds virtual memory limit " + TASK_TRACKER_LIMIT + ".");
  Matcher mat=null;
  JobConf conf=new JobConf(miniMRCluster.createJobConf());
  conf.setMemoryForMapTask(PER_TASK_LIMIT);
  conf.setMemoryForReduceTask(PER_TASK_LIMIT);
  JobClient jClient=new JobClient(conf);
  SleepJob sleepJob=new SleepJob();
  sleepJob.setConf(conf);
  Job job=sleepJob.createJob(1,1,5000,1,1000,1);
  job.submit();
  boolean TTOverFlowMsgPresent=false;
  while (true) {
    List<TaskReport> allTaskReports=new ArrayList<TaskReport>();
    allTaskReports.addAll(Arrays.asList(jClient.getSetupTaskReports(JobID.downgrade(job.getJobID()))));
    allTaskReports.addAll(Arrays.asList(jClient.getMapTaskReports(JobID.downgrade(job.getJobID()))));
    for (    TaskReport tr : allTaskReports) {
      String[] diag=tr.getDiagnostics();
      for (      String str : diag) {
        mat=taskOverLimitPattern.matcher(str);
        assertFalse(mat.find());
        mat=trackerOverLimitPattern.matcher(str);
        if (mat.find()) {
          TTOverFlowMsgPresent=true;
        }
      }
    }
    if (TTOverFlowMsgPresent) {
      break;
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
    }
  }
  job.killJob();
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test to verify the check for whether a process tree is over limit or not.
 * @throws IOException if there was a problem setting up the
 * fake procfs directories or files.
 */
@Test public void testProcessTreeLimits() throws IOException {
  File procfsRootDir=new File(TEST_ROOT_DIR,"proc");
  String[] pids={"100","200","300","400","500","600","700"};
  try {
    TestProcfsBasedProcessTree.setupProcfsRootDir(procfsRootDir);
    TestProcfsBasedProcessTree.setupPidDirs(procfsRootDir,pids);
    TestProcfsBasedProcessTree.ProcessStatInfo[] procs=new TestProcfsBasedProcessTree.ProcessStatInfo[7];
    procs[0]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"100","proc1","1","100","100","100000"});
    procs[1]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"200","proc2","1","200","200","200000"});
    procs[2]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"300","proc3","200","200","200","300000"});
    procs[3]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"400","proc4","200","200","200","400000"});
    procs[4]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"500","proc5","100","100","100","1500000"});
    procs[5]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"600","proc6","1","600","600","100000"});
    procs[6]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"700","proc7","600","600","600","100000"});
    TestProcfsBasedProcessTree.writeStatFiles(procfsRootDir,pids,procs);
    long limit=700000;
    TaskMemoryManagerThread test=new TaskMemoryManagerThread(1000000L,5000L);
    ProcfsBasedProcessTree pTree=new ProcfsBasedProcessTree("100",true,100L,procfsRootDir.getAbsolutePath());
    pTree.getProcessTree();
    assertTrue("tree rooted at 100 should be over limit " + "after first iteration.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));
    pTree=new ProcfsBasedProcessTree("200",true,100L,procfsRootDir.getAbsolutePath());
    pTree.getProcessTree();
    assertFalse("tree rooted at 200 shouldn't be over limit " + "after one iteration.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));
    pTree.getProcessTree();
    assertTrue("tree rooted at 200 should be over limit after 2 iterations",test.isProcessTreeOverLimit(pTree,"dummyId",limit));
    pTree=new ProcfsBasedProcessTree("600",true,100L,procfsRootDir.getAbsolutePath());
    pTree.getProcessTree();
    assertFalse("tree rooted at 600 should never be over limit.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));
    pTree.getProcessTree();
    assertFalse("tree rooted at 600 should never be over limit.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));
  }
  finally {
    FileUtil.fullyDelete(procfsRootDir);
  }
}

</code></pre>

<br>
<pre class="type-11 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test for verifying that tasks causing cumulative usage of physical memory
 * to go beyond TT's limit get killed.
 * @throws Exception
 */
@Test public void testTasksCumulativelyExceedingTTPhysicalLimits() throws Exception {
  if (!isProcfsBasedTreeAvailable()) {
    return;
  }
  JobConf fConf=new JobConf();
  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);
  LinuxResourceCalculatorPlugin memoryCalculatorPlugin=new LinuxResourceCalculatorPlugin();
  long totalPhysicalMemory=memoryCalculatorPlugin.getPhysicalMemorySize();
  long reservedPhysicalMemory=totalPhysicalMemory / (1024 * 1024) + 1;
  fConf.setLong(TTConfig.TT_RESERVED_PHYSCIALMEMORY_MB,reservedPhysicalMemory);
  long maxRssMemoryAllowedForAllTasks=totalPhysicalMemory - reservedPhysicalMemory * 1024 * 1024L;
  Pattern physicalMemoryOverLimitPattern=Pattern.compile("Killing one of the memory-consuming tasks - .*" + ", as the cumulative RSS memory usage of all the tasks on " + "the TaskTracker exceeds physical memory limit " + maxRssMemoryAllowedForAllTasks + ".");
  startCluster(fConf);
  Matcher mat=null;
  JobConf conf=new JobConf(miniMRCluster.createJobConf());
  conf.setLong(MRJobConfig.MAP_MEMORY_PHYSICAL_MB,2 * 1024L);
  conf.setLong(MRJobConfig.REDUCE_MEMORY_PHYSICAL_MB,2 * 1024L);
  JobClient jClient=new JobClient(conf);
  SleepJob sleepJob=new SleepJob();
  sleepJob.setConf(conf);
  Job job=sleepJob.createJob(1,1,100000,1,100000,1);
  job.submit();
  boolean TTOverFlowMsgPresent=false;
  while (true) {
    List<TaskReport> allTaskReports=new ArrayList<TaskReport>();
    allTaskReports.addAll(Arrays.asList(jClient.getSetupTaskReports(JobID.downgrade(job.getJobID()))));
    allTaskReports.addAll(Arrays.asList(jClient.getMapTaskReports(JobID.downgrade(job.getJobID()))));
    for (    TaskReport tr : allTaskReports) {
      String[] diag=tr.getDiagnostics();
      for (      String str : diag) {
        mat=physicalMemoryOverLimitPattern.matcher(str);
        if (mat.find()) {
          TTOverFlowMsgPresent=true;
        }
      }
    }
    if (TTOverFlowMsgPresent) {
      break;
    }
    assertFalse("Job should not finish successfully",job.isSuccessful());
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
    }
  }
  job.killJob();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTaskTrackerSlotManagement </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case to test addition of free slot when the job fails localization due
 * to cache file being modified after the job has started running.
 * @throws Exception
 */
@Test public void testFreeingOfTaskSlots() throws Exception {
  MiniMRCluster mrCluster=new MiniMRCluster(0,"file:///",1);
  Configuration conf=mrCluster.createJobConf();
  Cluster cluster=new Cluster(conf);
  conf.set(JobContext.MAP_DEBUG_SCRIPT,"/bin/echo");
  conf.set(JobContext.REDUCE_DEBUG_SCRIPT,"/bin/echo");
  Job j=MapReduceTestUtil.createJob(conf,new Path(TEST_DIR,"in"),new Path(TEST_DIR,"out"),0,0);
  j.addCacheFile(new URI(CACHE_FILE_PATH));
  j.setMaxMapAttempts(1);
  j.setMaxReduceAttempts(1);
  j.submit();
  File myFile=new File(CACHE_FILE_PATH);
  myFile.setLastModified(0L);
  mrCluster.startTaskTracker(null,null,0,1);
  j.waitForCompletion(false);
  Assert.assertFalse("Job successfully completed.",j.isSuccessful());
  ClusterMetrics metrics=cluster.getClusterStatus();
  Assert.assertEquals(0,metrics.getOccupiedMapSlots());
  Assert.assertEquals(0,metrics.getOccupiedReduceSlots());
  TaskTracker tt=mrCluster.getTaskTrackerRunner(0).getTaskTracker();
  Assert.assertEquals(metrics.getMapSlotCapacity(),tt.getFreeSlots(true));
  Assert.assertEquals(metrics.getReduceSlotCapacity(),tt.getFreeSlots(false));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestTextInputFormat </h4><pre class="type-10 type-11 type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFormat() throws Exception {
  JobConf job=new JobConf(defaultConf);
  Path file=new Path(workDir,"test.txt");
  Reporter reporter=Reporter.NULL;
  int seed=new Random().nextInt();
  LOG.info("seed = " + seed);
  Random random=new Random(seed);
  localFs.delete(workDir,true);
  FileInputFormat.setInputPaths(job,workDir);
  for (int length=0; length < MAX_LENGTH; length+=random.nextInt(MAX_LENGTH / 10) + 1) {
    LOG.debug("creating; entries = " + length);
    Writer writer=new OutputStreamWriter(localFs.create(file));
    try {
      for (int i=0; i < length; i++) {
        writer.write(Integer.toString(i));
        writer.write("\n");
      }
    }
  finally {
      writer.close();
    }
    TextInputFormat format=new TextInputFormat();
    format.configure(job);
    LongWritable key=new LongWritable();
    Text value=new Text();
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(MAX_LENGTH / 20) + 1;
      LOG.debug("splitting: requesting = " + numSplits);
      InputSplit[] splits=format.getSplits(job,numSplits);
      LOG.debug("splitting: got =        " + splits.length);
      if (length == 0) {
        assertEquals("Files of length 0 are not returned from FileInputFormat.getSplits().",1,splits.length);
        assertEquals("Empty file length == 0",0,splits[0].getLength());
      }
      BitSet bits=new BitSet(length);
      for (int j=0; j < splits.length; j++) {
        LOG.debug("split[" + j + "]= "+ splits[j]);
        RecordReader<LongWritable,Text> reader=format.getRecordReader(splits[j],job,reporter);
        try {
          int count=0;
          while (reader.next(key,value)) {
            int v=Integer.parseInt(value.toString());
            LOG.debug("read " + v);
            if (bits.get(v)) {
              LOG.warn("conflict with " + v + " in split "+ j+ " at position "+ reader.getPos());
            }
            assertFalse("Key in multiple partitions.",bits.get(v));
            bits.set(v);
            count++;
          }
          LOG.debug("splits[" + j + "]="+ splits[j]+ " count="+ count);
        }
  finally {
          reader.close();
        }
      }
      assertEquals("Some keys in no partition.",length,bits.cardinality());
    }
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 type-12 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies values related to public fields.
"></span><br>
@Test public void testMRMaxLine() throws Exception {
  final int MAXPOS=1024 * 1024;
  final int MAXLINE=10 * 1024;
  final int BUF=64 * 1024;
  final InputStream infNull=new InputStream(){
    int position=0;
    final int MAXPOSBUF=1024 * 1024 + BUF;
    @Override public int read(){
      ++position;
      return 0;
    }
    @Override public int read(    byte[] b){
      assertTrue("Read too many bytes from the stream",position < MAXPOSBUF);
      Arrays.fill(b,(byte)0);
      position+=b.length;
      return b.length;
    }
  }
;
  final LongWritable key=new LongWritable();
  final Text val=new Text();
  LOG.info("Reading a line from /dev/null");
  final Configuration conf=new Configuration(false);
  conf.setInt(org.apache.hadoop.mapreduce.lib.input.LineRecordReader.MAX_LINE_LENGTH,MAXLINE);
  conf.setInt("io.file.buffer.size",BUF);
  final LineRecordReader lrr=new LineRecordReader(infNull,0,MAXPOS,conf);
  assertFalse("Read a line from null",lrr.next(key,val));
}

</code></pre>

<br>
<pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSplitableCodecs() throws IOException {
  JobConf conf=new JobConf(defaultConf);
  int seed=new Random().nextInt();
  CompressionCodec codec=null;
  try {
    codec=(CompressionCodec)ReflectionUtils.newInstance(conf.getClassByName("org.apache.hadoop.io.compress.BZip2Codec"),conf);
  }
 catch (  ClassNotFoundException cnfe) {
    throw new IOException("Illegal codec!");
  }
  Path file=new Path(workDir,"test" + codec.getDefaultExtension());
  Reporter reporter=Reporter.NULL;
  LOG.info("seed = " + seed);
  Random random=new Random(seed);
  FileSystem localFs=FileSystem.getLocal(conf);
  localFs.delete(workDir,true);
  FileInputFormat.setInputPaths(conf,workDir);
  final int MAX_LENGTH=500000;
  for (int length=MAX_LENGTH / 2; length < MAX_LENGTH; length+=random.nextInt(MAX_LENGTH / 4) + 1) {
    LOG.info("creating; entries = " + length);
    Writer writer=new OutputStreamWriter(codec.createOutputStream(localFs.create(file)));
    try {
      for (int i=0; i < length; i++) {
        writer.write(Integer.toString(i));
        writer.write("\n");
      }
    }
  finally {
      writer.close();
    }
    TextInputFormat format=new TextInputFormat();
    format.configure(conf);
    LongWritable key=new LongWritable();
    Text value=new Text();
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(MAX_LENGTH / 2000) + 1;
      LOG.info("splitting: requesting = " + numSplits);
      InputSplit[] splits=format.getSplits(conf,numSplits);
      LOG.info("splitting: got =        " + splits.length);
      BitSet bits=new BitSet(length);
      for (int j=0; j < splits.length; j++) {
        LOG.debug("split[" + j + "]= "+ splits[j]);
        RecordReader<LongWritable,Text> reader=format.getRecordReader(splits[j],conf,reporter);
        try {
          int counter=0;
          while (reader.next(key,value)) {
            int v=Integer.parseInt(value.toString());
            LOG.debug("read " + v);
            if (bits.get(v)) {
              LOG.warn("conflict with " + v + " in split "+ j+ " at position "+ reader.getPos());
            }
            assertFalse("Key in multiple partitions.",bits.get(v));
            bits.set(v);
            counter++;
          }
          if (counter > 0) {
            LOG.info("splits[" + j + "]="+ splits[j]+ " count="+ counter);
          }
 else {
            LOG.debug("splits[" + j + "]="+ splits[j]+ " count="+ counter);
          }
        }
  finally {
          reader.close();
        }
      }
      assertEquals("Some keys in no partition.",length,bits.cardinality());
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestUserLogCleanup </h4><pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Tests job user-log directory deletion.
 * Adds two jobs for log deletion. One with one hour retain hours, other with
 * two retain hours. After an hour,
 * TaskLogCleanupThread.processCompletedJobs() call,
 * makes sure job with 1hr retain hours is removed and other is retained.
 * After one more hour, job with 2hr retain hours is also removed.
 * @throws IOException
 */
@Test public void testJobLogCleanup() throws IOException {
  File jobUserlog1=localizeJob(jobid1);
  File jobUserlog2=localizeJob(jobid2);
  jobFinished(jobid1,2);
  jobFinished(jobid2,1);
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertTrue(jobUserlog1 + " got deleted",jobUserlog1.exists());
  assertFalse(jobUserlog2 + " still exists.",jobUserlog2.exists());
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1 + " still exists.",jobUserlog1.exists());
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Tests user-log directory cleanup on a TT restart.
 * Adds job1 deletion before the restart with 2 hour retain hours.
 * Adds job2 for which there are no tasks/killJobAction after the restart.
 * Adds job3 for which there is localizeJob followed by killJobAction after
 * the restart with 3 hours retain hours.
 * Adds job4 for which there are some tasks after the restart.
 * @throws IOException
 */
@Test public void testUserLogCleanupAfterRestart() throws IOException {
  File jobUserlog1=localizeJob(jobid1);
  File jobUserlog2=localizeJob(jobid2);
  File jobUserlog3=localizeJob(jobid3);
  File jobUserlog4=localizeJob(jobid4);
  foo.mkdirs();
  bar.createNewFile();
  jobFinished(jobid1,2);
  myClock.advance(ONE_HOUR);
  Configuration conf=new Configuration();
  conf.setInt(MRJobConfig.USER_LOG_RETAIN_HOURS,3);
  taskLogCleanupThread=new UserLogCleaner(conf);
  myClock=new FakeClock();
  taskLogCleanupThread.setClock(myClock);
  taskLogCleanupThread.clearOldUserLogs(conf);
  tt.setTaskLogCleanupThread(taskLogCleanupThread);
  assertFalse(foo.exists());
  assertFalse(bar.exists());
  assertTrue(jobUserlog1.exists());
  assertTrue(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  assertTrue(new File(TaskLog.getUserLogDir(),MRAsyncDiskService.TOBEDELETED).exists());
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertTrue(jobUserlog1.exists());
  assertTrue(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  jobUserlog3=localizeJob(jobid3);
  jobFinished(jobid3,3);
  jobUserlog4=localizeJob(jobid4);
  myClock.advance(2 * ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1.exists());
  assertFalse(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1.exists());
  assertFalse(jobUserlog2.exists());
  assertFalse(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Tests user-log directory cleanup on a TT re-init with 3 hours as log
 * retain hours for tracker. 
 * Adds job1 deletion before the re-init with 2 hour retain hours. 
 * Adds job2 for which there are no tasks/killJobAction after the re-init.
 * Adds job3 for which there is localizeJob followed by killJobAction 
 * with 3 hours as retain hours.
 * Adds job4 for which there are some tasks after the re-init.
 * @throws IOException
 */
@Test public void testUserLogCleanup() throws IOException {
  File jobUserlog1=localizeJob(jobid1);
  File jobUserlog2=localizeJob(jobid2);
  File jobUserlog3=localizeJob(jobid3);
  File jobUserlog4=localizeJob(jobid4);
  foo.mkdirs();
  bar.createNewFile();
  jobFinished(jobid1,2);
  myClock.advance(ONE_HOUR);
  Configuration conf=new Configuration();
  conf.setInt(MRJobConfig.USER_LOG_RETAIN_HOURS,3);
  taskLogCleanupThread.clearOldUserLogs(conf);
  assertFalse(foo.exists());
  assertFalse(bar.exists());
  assertTrue(jobUserlog1.exists());
  assertTrue(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  assertTrue(new File(TaskLog.getUserLogDir(),MRAsyncDiskService.TOBEDELETED).exists());
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1.exists());
  assertTrue(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  jobUserlog3=localizeJob(jobid3);
  jobFinished(jobid3,3);
  jobUserlog4=localizeJob(jobid4);
  myClock.advance(2 * ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1.exists());
  assertFalse(jobUserlog2.exists());
  assertTrue(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
  myClock.advance(ONE_HOUR);
  taskLogCleanupThread.processCompletedJobs();
  assertFalse(jobUserlog1.exists());
  assertFalse(jobUserlog2.exists());
  assertFalse(jobUserlog3.exists());
  assertTrue(jobUserlog4.exists());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.TestUtils </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testOutputFilesFilter(){
  PathFilter filter=new Utils.OutputFileUtils.OutputFilesFilter();
  for (  Path p : LOG_PATHS) {
    assertFalse(filter.accept(p));
  }
  for (  Path p : SUCCEEDED_PATHS) {
    assertFalse(filter.accept(p));
  }
  for (  Path p : PASS_PATHS) {
    assertTrue(filter.accept(p));
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testLogFilter(){
  PathFilter filter=new Utils.OutputFileUtils.OutputLogFilter();
  for (  Path p : LOG_PATHS) {
    assertFalse(filter.accept(p));
  }
  for (  Path p : SUCCEEDED_PATHS) {
    assertTrue(filter.accept(p));
  }
  for (  Path p : PASS_PATHS) {
    assertTrue(filter.accept(p));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Test compression ratio with multiple compression ratios.
 */
@Test public void testCompressionRatios() throws Exception {
  testCompressionRatioConfigure(0F);
  testCompressionRatioConfigure(0.2F);
  testCompressionRatioConfigure(0.4F);
  testCompressionRatioConfigure(0.65F);
  testCompressionRatioConfigure(0.682F);
  testCompressionRatioConfigure(0.567F);
  boolean failed=false;
  try {
    testCompressionRatioConfigure(0.01F);
  }
 catch (  RuntimeException re) {
    failed=true;
  }
  assertTrue("Compression ratio min value (0.07) check failed!",failed);
  failed=false;
  try {
    testCompressionRatioConfigure(0.7F);
  }
 catch (  RuntimeException re) {
    failed=true;
  }
  assertTrue("Compression ratio max value (0.68) check failed!",failed);
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test compressible {@link GridmixRecord}.
 */
@Test public void testCompressibleGridmixRecord() throws IOException {
  JobConf conf=new JobConf();
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  CompressionEmulationUtil.setInputCompressionEmulationEnabled(conf,true);
  FileSystem lfs=FileSystem.getLocal(conf);
  int dataSize=1024 * 1024 * 10;
  float ratio=0.357F;
  Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  Path tempDir=new Path(rootTempDir,"TestPossiblyCompressibleGridmixRecord");
  lfs.delete(tempDir,true);
  GridmixRecord record=new GridmixRecord(dataSize,0);
  record.setCompressibility(true,ratio);
  conf.setClass(FileOutputFormat.COMPRESS_CODEC,GzipCodec.class,CompressionCodec.class);
  org.apache.hadoop.mapred.FileOutputFormat.setCompressOutput(conf,true);
  Path recordFile=new Path(tempDir,"record");
  OutputStream outStream=CompressionEmulationUtil.getPossiblyCompressedOutputStream(recordFile,conf);
  DataOutputStream out=new DataOutputStream(outStream);
  record.write(out);
  out.close();
  outStream.close();
  Path actualRecordFile=recordFile.suffix(".gz");
  InputStream in=CompressionEmulationUtil.getPossiblyDecompressedInputStream(actualRecordFile,conf,0);
  long compressedFileSize=lfs.listStatus(actualRecordFile)[0].getLen();
  GridmixRecord recordRead=new GridmixRecord();
  recordRead.readFields(new DataInputStream(in));
  assertEquals("Record size mismatch in a compressible GridmixRecord",dataSize,recordRead.getSize());
  assertTrue("Failed to generate a compressible GridmixRecord",recordRead.getSize() > compressedFileSize);
  float seenRatio=((float)compressedFileSize) / dataSize;
  assertEquals(CompressionEmulationUtil.standardizeCompressionRatio(ratio),CompressionEmulationUtil.standardizeCompressionRatio(seenRatio),1.0D);
}

</code></pre>

<br>
<pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test if {@link CompressionEmulationUtil#configureCompressionEmulation(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobConf)}can extract compression related configuration parameters.
 */
@Test public void testExtractCompressionConfigs(){
  JobConf source=new JobConf();
  JobConf target=new JobConf();
  source.setBoolean(FileOutputFormat.COMPRESS,false);
  source.set(FileOutputFormat.COMPRESS_CODEC,"MyDefaultCodec");
  source.set(FileOutputFormat.COMPRESS_TYPE,"MyDefaultType");
  source.setBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS,false);
  source.set(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC,"MyDefaultCodec2");
  CompressionEmulationUtil.configureCompressionEmulation(source,target);
  assertFalse(target.getBoolean(FileOutputFormat.COMPRESS,true));
  assertEquals("MyDefaultCodec",target.get(FileOutputFormat.COMPRESS_CODEC));
  assertEquals("MyDefaultType",target.get(FileOutputFormat.COMPRESS_TYPE));
  assertFalse(target.getBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS,true));
  assertEquals("MyDefaultCodec2",target.get(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC));
  assertFalse(CompressionEmulationUtil.isInputCompressionEmulationEnabled(target));
  source.setBoolean(FileOutputFormat.COMPRESS,true);
  source.set(FileOutputFormat.COMPRESS_CODEC,"MyCodec");
  source.set(FileOutputFormat.COMPRESS_TYPE,"MyType");
  source.setBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS,true);
  source.set(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC,"MyCodec2");
  org.apache.hadoop.mapred.FileInputFormat.setInputPaths(source,"file.gz");
  target=new JobConf();
  CompressionEmulationUtil.configureCompressionEmulation(source,target);
  assertTrue(target.getBoolean(FileOutputFormat.COMPRESS,false));
  assertEquals("MyCodec",target.get(FileOutputFormat.COMPRESS_CODEC));
  assertEquals("MyType",target.get(FileOutputFormat.COMPRESS_TYPE));
  assertTrue(target.getBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS,false));
  assertEquals("MyCodec2",target.get(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC));
  assertTrue(CompressionEmulationUtil.isInputCompressionEmulationEnabled(target));
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test {@link RandomTextDataMapper} via {@link CompressionEmulationUtil}.
 */
@Test public void testRandomCompressedTextDataGenerator() throws Exception {
  int wordSize=10;
  int listSize=20;
  long dataSize=10 * 1024 * 1024;
  Configuration conf=new Configuration();
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  CompressionEmulationUtil.setInputCompressionEmulationEnabled(conf,true);
  conf.setInt(RandomTextDataGenerator.GRIDMIX_DATAGEN_RANDOMTEXT_LISTSIZE,listSize);
  conf.setInt(RandomTextDataGenerator.GRIDMIX_DATAGEN_RANDOMTEXT_WORDSIZE,wordSize);
  conf.setLong(GenerateData.GRIDMIX_GEN_BYTES,dataSize);
  FileSystem lfs=FileSystem.getLocal(conf);
  Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  Path tempDir=new Path(rootTempDir,"TestRandomCompressedTextDataGenr");
  lfs.delete(tempDir,true);
  runDataGenJob(conf,tempDir);
  FileStatus[] files=lfs.listStatus(tempDir,new Utils.OutputFileUtils.OutputFilesFilter());
  long size=0;
  long maxLineSize=0;
  for (  FileStatus status : files) {
    InputStream in=CompressionEmulationUtil.getPossiblyDecompressedInputStream(status.getPath(),conf,0);
    BufferedReader reader=new BufferedReader(new InputStreamReader(in));
    String line=reader.readLine();
    if (line != null) {
      long lineSize=line.getBytes().length;
      if (lineSize > maxLineSize) {
        maxLineSize=lineSize;
      }
      while (line != null) {
        for (        String word : line.split("\\s")) {
          size+=word.getBytes().length;
        }
        line=reader.readLine();
      }
    }
    reader.close();
  }
  assertTrue(size >= dataSize);
  assertTrue(size <= dataSize + maxLineSize);
}

</code></pre>

<br>
<pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Test {@link CompressionEmulationUtil#isCompressionEmulationEnabled(org.apache.hadoop.conf.Configuration)}.
 */
@Test public void testIsCompressionEmulationEnabled(){
  Configuration conf=new Configuration();
  assertTrue(CompressionEmulationUtil.isCompressionEmulationEnabled(conf));
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,false);
  assertFalse(CompressionEmulationUtil.isCompressionEmulationEnabled(conf));
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  assertTrue(CompressionEmulationUtil.isCompressionEmulationEnabled(conf));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation </h4><pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Test if Gridmix can configure config properties related to Distributed
 * Cache properly. Also verify if Gridmix can handle deprecated config
 * properties related to Distributed Cache.
 * @throws IOException
 */
@Test public void testDistCacheFilesConfiguration() throws IOException {
  Configuration conf=new Configuration();
  JobConf jobConf=GridmixTestUtils.mrCluster.createJobConf(new JobConf(conf));
  Path ioPath=new Path("testDistCacheEmulationConfigurability").makeQualified(GridmixTestUtils.dfs);
  FileSystem fs=FileSystem.get(jobConf);
  FileSystem.mkdirs(fs,ioPath,new FsPermission((short)0777));
  dce=createDistributedCacheEmulator(jobConf,ioPath,false);
  assertTrue("Default configuration of " + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + " is wrong.",dce.shouldEmulateDistCacheLoad());
  validateJobConfWithOutDCFiles(conf,jobConf);
  validateJobConfWithDCFiles(conf,jobConf);
  validateWithOutVisibilities();
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test the configuration property for disabling/enabling emulation of
 * distributed cache load.
 */
@Test public void testDistCacheEmulationConfigurability() throws IOException {
  Configuration conf=new Configuration();
  JobConf jobConf=GridmixTestUtils.mrCluster.createJobConf(new JobConf(conf));
  Path ioPath=new Path("testDistCacheEmulationConfigurability").makeQualified(GridmixTestUtils.dfs);
  FileSystem fs=FileSystem.get(jobConf);
  FileSystem.mkdirs(fs,ioPath,new FsPermission((short)0777));
  dce=createDistributedCacheEmulator(jobConf,ioPath,false);
  assertTrue("Default configuration of " + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + " is wrong.",dce.shouldEmulateDistCacheLoad());
  jobConf.setBoolean(DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE,false);
  dce=createDistributedCacheEmulator(jobConf,ioPath,false);
  assertFalse("Disabling of emulation of distributed cache load by setting " + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + " to false is not working.",dce.shouldEmulateDistCacheLoad());
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Validate GenerateDistCacheData job if it creates dist cache files properly.
 * @throws Exception
 */
@Test public void testGenerateDistCacheData() throws Exception {
  long[] sortedFileSizes=new long[5];
  JobConf jobConf=runSetupGenerateDistCacheData(true,sortedFileSizes);
  GridmixJob gridmixJob=new GenerateDistCacheData(jobConf);
  Job job=gridmixJob.call();
  assertEquals("Number of reduce tasks in GenerateDistCacheData is not 0.",0,job.getNumReduceTasks());
  assertTrue("GenerateDistCacheData job failed.",job.waitForCompletion(false));
  validateDistCacheData(jobConf,sortedFileSizes);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestFilePool </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testPool() throws Exception {
  final Random r=new Random();
  final Configuration conf=new Configuration();
  conf.setLong(FilePool.GRIDMIX_MIN_FILE,3 * 1024);
  final FilePool pool=new FilePool(conf,base);
  pool.refresh();
  final ArrayList<FileStatus> files=new ArrayList<FileStatus>();
  final int expectedPoolSize=(NFILES / 2 * (NFILES / 2 + 1) - 6) * 1024;
  assertEquals(expectedPoolSize,pool.getInputFiles(Long.MAX_VALUE,files));
  assertEquals(NFILES - 4,files.size());
  files.clear();
  assertEquals(expectedPoolSize,pool.getInputFiles(expectedPoolSize,files));
  files.clear();
  final long rand=r.nextInt(expectedPoolSize);
  assertTrue("Missed: " + rand,(NFILES / 2) * 1024 > rand - pool.getInputFiles(rand,files));
  conf.setLong(FilePool.GRIDMIX_MIN_FILE,0);
  pool.refresh();
  files.clear();
  assertEquals((NFILES / 2 * (NFILES / 2 + 1)) * 1024,pool.getInputFiles(Long.MAX_VALUE,files));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestHighRamJob </h4><pre class="type-7 type-6 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests high ram job properties configuration.
 */
@SuppressWarnings("deprecation") @Test public void testHighRamFeatureEmulation() throws IOException {
  Configuration gridmixConf=new Configuration();
  gridmixConf.setBoolean(GridmixJob.GRIDMIX_HIGHRAM_EMULATION_ENABLE,false);
  testHighRamConfig(10,20,5,10,JobConf.DISABLED_MEMORY_LIMIT,JobConf.DISABLED_MEMORY_LIMIT,JobConf.DISABLED_MEMORY_LIMIT,JobConf.DISABLED_MEMORY_LIMIT,gridmixConf);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY,20 * 1024 * 1024);
  testHighRamConfig(10,20,5,10,5,10,10,20,gridmixConf);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JTConfig.JT_MAX_MAPMEMORY_MB,100);
  gridmixConf.setLong(JTConfig.JT_MAX_REDUCEMEMORY_MB,300);
  testHighRamConfig(10,45,5,15,50,100,100,300,gridmixConf);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY,70 * 1024 * 1024);
  Boolean failed=null;
  try {
    testHighRamConfig(10,45,5,15,50,100,100,300,gridmixConf);
    failed=false;
  }
 catch (  Exception e) {
    failed=true;
  }
  assertNotNull(failed);
  assertTrue("Exception expected for exceeding map memory limit " + "(deprecation)!",failed);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY,150 * 1024 * 1024);
  failed=null;
  try {
    testHighRamConfig(10,45,5,15,50,100,100,300,gridmixConf);
    failed=false;
  }
 catch (  Exception e) {
    failed=true;
  }
  assertNotNull(failed);
  assertTrue("Exception expected for exceeding reduce memory limit " + "(deprecation)!",failed);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JTConfig.JT_MAX_MAPMEMORY_MB,70);
  failed=null;
  try {
    testHighRamConfig(10,45,5,15,50,100,100,300,gridmixConf);
    failed=false;
  }
 catch (  Exception e) {
    failed=true;
  }
  assertNotNull(failed);
  assertTrue("Exception expected for exceeding map memory limit!",failed);
  gridmixConf=new Configuration();
  gridmixConf.setLong(JTConfig.JT_MAX_REDUCEMEMORY_MB,200);
  failed=null;
  try {
    testHighRamConfig(10,45,5,15,50,100,100,300,gridmixConf);
    failed=false;
  }
 catch (  Exception e) {
    failed=true;
  }
  assertNotNull(failed);
  assertTrue("Exception expected for exceeding reduce memory limit!",failed);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestRandomTextDataGenerator </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test if {@link RandomTextDataGenerator} can generate same words given the
 * same list-size, word-length and seed.
 */
@Test public void testRandomTextDataGeneratorRepeatability(){
  RandomTextDataGenerator rtdg1=new RandomTextDataGenerator(10,0L,5);
  List<String> words1=rtdg1.getRandomWords();
  RandomTextDataGenerator rtdg2=new RandomTextDataGenerator(10,0L,5);
  List<String> words2=rtdg2.getRandomWords();
  assertTrue("List mismatch",words1.equals(words2));
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test if {@link RandomTextDataGenerator} can generate different words given 
 * different seeds.
 */
@Test public void testRandomTextDataGeneratorUniqueness(){
  RandomTextDataGenerator rtdg1=new RandomTextDataGenerator(10,1L,5);
  Set<String> words1=new HashSet(rtdg1.getRandomWords());
  RandomTextDataGenerator rtdg2=new RandomTextDataGenerator(10,0L,5);
  Set<String> words2=new HashSet(rtdg2.getRandomWords());
  assertFalse("List size mismatch across lists",words1.equals(words2));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapred.gridmix.TestUserResolve </h4><pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSubmitterResolver() throws Exception {
  final UserResolver rslv=new SubmitterUserResolver();
  assertFalse(rslv.needsTargetUsersList());
  UserGroupInformation ugi=UserGroupInformation.getCurrentUser();
  assertEquals(ugi,rslv.getTargetUgi((UserGroupInformation)null));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.TestLocalRunner </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Run a test with a misconfigured number of mappers.
 * Expect failure.
 */
@Test public void testInvalidMultiMapParallelism() throws Exception {
  Job job=Job.getInstance();
  Path inputPath=createMultiMapsInput();
  Path outputPath=getOutputPath();
  Configuration conf=new Configuration();
  FileSystem fs=FileSystem.getLocal(conf);
  if (fs.exists(outputPath)) {
    fs.delete(outputPath,true);
  }
  job.setMapperClass(StressMapper.class);
  job.setReducerClass(CountingReducer.class);
  job.setNumReduceTasks(1);
  LocalJobRunner.setLocalMaxRunningMaps(job,-6);
  FileInputFormat.addInputPath(job,inputPath);
  FileOutputFormat.setOutputPath(job,outputPath);
  boolean success=job.waitForCompletion(true);
  assertFalse("Job succeeded somehow",success);
}

</code></pre>

<br>
<pre class="type-4 type-7 type-6 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that the GC counter actually increments when we know that we've
 * spent some time in the GC during the mapper.
 */
@Test public void testGcCounter() throws Exception {
  Path inputPath=getInputPath();
  Path outputPath=getOutputPath();
  Configuration conf=new Configuration();
  FileSystem fs=FileSystem.getLocal(conf);
  if (fs.exists(outputPath)) {
    fs.delete(outputPath,true);
  }
  if (fs.exists(inputPath)) {
    fs.delete(inputPath,true);
  }
  createInputFile(inputPath,0,20);
  Job job=Job.getInstance();
  job.setMapperClass(GCMapper.class);
  job.setNumReduceTasks(0);
  job.getConfiguration().set("io.sort.mb","25");
  FileInputFormat.addInputPath(job,inputPath);
  FileOutputFormat.setOutputPath(job,outputPath);
  boolean ret=job.waitForCompletion(true);
  assertTrue("job failed",ret);
  Counter gcCounter=job.getCounters().findCounter(TaskCounter.GC_TIME_MILLIS);
  assertNotNull(gcCounter);
  assertTrue("No time spent in gc",gcCounter.getValue() > 0);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.TestMRJobClient </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testMissingProfileOutput() throws Exception {
  Configuration conf=createJobConf();
  final String input="hello1\n";
  Job job=MapReduceTestUtil.createJob(conf,getInputDir(),getOutputDir(),1,1,input);
  job.setJobName("disable-profile-fetch");
  job.setProfileEnabled(true);
  job.setProfileParams("-agentlib:,verbose=n,file=%s");
  job.setMaxMapAttempts(1);
  job.setMaxReduceAttempts(1);
  job.setJobSetupCleanupNeeded(false);
  job.waitForCompletion(true);
  Job job2=MapReduceTestUtil.createJob(conf,getInputDir(),getOutputDir(),1,1,input);
  job2.setJobName("enable-profile-fetch");
  job2.setProfileEnabled(true);
  job2.setProfileParams("-agentlib:hprof=cpu=samples,heap=sites,force=n," + "thread=y,verbose=n,file=%s");
  job2.setProfileTaskRange(true,"0-1");
  job2.setProfileTaskRange(false,"");
  job2.setMaxMapAttempts(1);
  job2.setMaxReduceAttempts(1);
  job2.setJobSetupCleanupNeeded(false);
  job2.waitForCompletion(true);
  TaskReport[] reports=job2.getTaskReports(TaskType.MAP);
  assertTrue("No task reports found!",reports.length > 0);
  TaskReport report=reports[0];
  TaskID id=report.getTaskId();
  assertTrue(TaskType.MAP == id.getTaskType());
  System.out.println("Using task id: " + id);
  TaskAttemptID attemptId=new TaskAttemptID(id,0);
  File profileOutFile=new File(attemptId.toString() + ".profile");
  assertTrue("Couldn't find profiler output",profileOutFile.exists());
  assertTrue("Couldn't remove profiler output",profileOutFile.delete());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.TestTaskContext </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests context.setStatus method.
 * @throws IOException
 * @throws InterruptedException
 * @throws ClassNotFoundException
 */
@Test public void testContextStatus() throws IOException, InterruptedException, ClassNotFoundException {
  Path test=new Path(testRootTempDir,"testContextStatus");
  int numMaps=1;
  Job job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numMaps,0);
  job.setMapperClass(MyMapper.class);
  job.waitForCompletion(true);
  assertTrue("Job failed",job.isSuccessful());
  TaskReport[] reports=job.getTaskReports(TaskType.MAP);
  assertEquals(numMaps,reports.length);
  assertEquals(myStatus,reports[0].getState());
  int numReduces=1;
  job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numMaps,numReduces);
  job.setMapperClass(DataCopyMapper.class);
  job.setReducerClass(DataCopyReducer.class);
  job.setMapOutputKeyClass(Text.class);
  job.setMapOutputValueClass(Text.class);
  job.setOutputKeyClass(Text.class);
  job.setOutputValueClass(Text.class);
  job.setMaxMapAttempts(1);
  job.setMaxReduceAttempts(0);
  job.waitForCompletion(true);
  assertTrue("Job failed",job.isSuccessful());
  reports=job.getTaskReports(TaskType.MAP);
  assertEquals(numMaps,reports.length);
  assertEquals("map > sort",reports[0].getState());
  reports=job.getTaskReports(TaskType.REDUCE);
  assertEquals(numReduces,reports.length);
  assertEquals("reduce > reduce",reports[0].getState());
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Tests new MapReduce reduce task's context.getProgress() method.
 * @throws IOException
 * @throws InterruptedException
 * @throws ClassNotFoundException
 */
@Test public void testReduceContextProgress() throws IOException, InterruptedException, ClassNotFoundException {
  int numTasks=1;
  Path test=new Path(testRootTempDir,"testReduceContextProgress");
  Job job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numTasks,numTasks,INPUT);
  job.setMapperClass(ProgressCheckerMapper.class);
  job.setReducerClass(ProgressCheckerReducer.class);
  job.setMapOutputKeyClass(Text.class);
  job.setMaxMapAttempts(1);
  job.setMaxReduceAttempts(1);
  job.waitForCompletion(true);
  assertTrue("Job failed",job.isSuccessful());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.filecache.TestURIFragments </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Tests {@link DistributedCache#checkURIs(URI[], URI[]).}
 */
@Test public void testURIs() throws URISyntaxException {
  assertTrue(DistributedCache.checkURIs(null,null));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile.txt")},null));
  assertFalse(DistributedCache.checkURIs(null,new URI[]{new URI("file://foo/bar/myCacheArchive.txt")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file"),new URI("file://foo/bar/myCacheFile2.txt")},null));
  assertFalse(DistributedCache.checkURIs(null,new URI[]{new URI("file://foo/bar/myCacheArchive1.txt"),new URI("file://foo/bar/myCacheArchive2.txt#archive")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile.txt")},new URI[]{new URI("file://foo/bar/myCacheArchive.txt")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file"),new URI("file://foo/bar/myCacheFile2.txt#file")},null));
  assertFalse(DistributedCache.checkURIs(null,new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive"),new URI("file://foo/bar/myCacheArchive2.txt#archive")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile.txt#cache")},new URI[]{new URI("file://foo/bar/myCacheArchive.txt#cache")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#file2")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive"),new URI("file://foo/bar/myCacheArchive2.txt#archive")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file"),new URI("file://foo/bar/myCacheFile2.txt#file")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive1"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#cache")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#cache"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file"),new URI("file://foo/bar/myCacheFile2.txt#FILE")},null));
  assertFalse(DistributedCache.checkURIs(null,new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive"),new URI("file://foo/bar/myCacheArchive2.txt#ARCHIVE")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile.txt#cache")},new URI[]{new URI("file://foo/bar/myCacheArchive.txt#CACHE")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#file2")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#ARCHIVE"),new URI("file://foo/bar/myCacheArchive2.txt#archive")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#FILE"),new URI("file://foo/bar/myCacheFile2.txt#file")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive1"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
  assertFalse(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#CACHE")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#cache"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
  assertTrue(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#file2")},null));
  assertTrue(DistributedCache.checkURIs(null,new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive1"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
  assertTrue(DistributedCache.checkURIs(new URI[]{new URI("file://foo/bar/myCacheFile1.txt#file1"),new URI("file://foo/bar/myCacheFile2.txt#file2")},new URI[]{new URI("file://foo/bar/myCacheArchive1.txt#archive1"),new URI("file://foo/bar/myCacheArchive2.txt#archive2")}));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat </h4><pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFormat() throws Exception {
  Job job=Job.getInstance(new Configuration(defaultConf));
  Path file=new Path(workDir,"test.txt");
  int seed=new Random().nextInt();
  LOG.info("seed = " + seed);
  Random random=new Random(seed);
  localFs.delete(workDir,true);
  FileInputFormat.setInputPaths(job,workDir);
  final int MAX_LENGTH=10000;
  for (int length=0; length < MAX_LENGTH; length+=random.nextInt(MAX_LENGTH / 10) + 1) {
    LOG.debug("creating; entries = " + length);
    Writer writer=new OutputStreamWriter(localFs.create(file));
    try {
      for (int i=0; i < length; i++) {
        writer.write(Integer.toString(i * 2));
        writer.write("\t");
        writer.write(Integer.toString(i));
        writer.write("\n");
      }
    }
  finally {
      writer.close();
    }
    KeyValueTextInputFormat format=new KeyValueTextInputFormat();
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(MAX_LENGTH / 20) + 1;
      LOG.debug("splitting: requesting = " + numSplits);
      List<InputSplit> splits=format.getSplits(job);
      LOG.debug("splitting: got =        " + splits.size());
      BitSet bits=new BitSet(length);
      for (int j=0; j < splits.size(); j++) {
        LOG.debug("split[" + j + "]= "+ splits.get(j));
        TaskAttemptContext context=MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration());
        RecordReader<Text,Text> reader=format.createRecordReader(splits.get(j),context);
        Class<?> clazz=reader.getClass();
        assertEquals("reader class is KeyValueLineRecordReader.",KeyValueLineRecordReader.class,clazz);
        MapContext<Text,Text,Text,Text> mcontext=new MapContextImpl<Text,Text,Text,Text>(job.getConfiguration(),context.getTaskAttemptID(),reader,null,null,MapReduceTestUtil.createDummyReporter(),splits.get(j));
        reader.initialize(splits.get(j),mcontext);
        Text key=null;
        Text value=null;
        try {
          int count=0;
          while (reader.nextKeyValue()) {
            key=reader.getCurrentKey();
            clazz=key.getClass();
            assertEquals("Key class is Text.",Text.class,clazz);
            value=reader.getCurrentValue();
            clazz=value.getClass();
            assertEquals("Value class is Text.",Text.class,clazz);
            final int k=Integer.parseInt(key.toString());
            final int v=Integer.parseInt(value.toString());
            assertEquals("Bad key",0,k % 2);
            assertEquals("Mismatched key/value",k / 2,v);
            LOG.debug("read " + v);
            assertFalse("Key in multiple partitions.",bits.get(v));
            bits.set(v);
            count++;
          }
          LOG.debug("splits[" + j + "]="+ splits.get(j)+ " count="+ count);
        }
  finally {
          reader.close();
        }
      }
      assertEquals("Some keys in no partition.",length,bits.cardinality());
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSplitableCodecs() throws Exception {
  final Job job=Job.getInstance(defaultConf);
  final Configuration conf=job.getConfiguration();
  CompressionCodec codec=null;
  try {
    codec=(CompressionCodec)ReflectionUtils.newInstance(conf.getClassByName("org.apache.hadoop.io.compress.BZip2Codec"),conf);
  }
 catch (  ClassNotFoundException cnfe) {
    throw new IOException("Illegal codec!");
  }
  Path file=new Path(workDir,"test" + codec.getDefaultExtension());
  int seed=new Random().nextInt();
  LOG.info("seed = " + seed);
  Random random=new Random(seed);
  localFs.delete(workDir,true);
  FileInputFormat.setInputPaths(job,workDir);
  final int MAX_LENGTH=500000;
  FileInputFormat.setMaxInputSplitSize(job,MAX_LENGTH / 20);
  for (int length=0; length < MAX_LENGTH; length+=random.nextInt(MAX_LENGTH / 4) + 1) {
    LOG.info("creating; entries = " + length);
    Writer writer=new OutputStreamWriter(codec.createOutputStream(localFs.create(file)));
    try {
      for (int i=0; i < length; i++) {
        writer.write(Integer.toString(i * 2));
        writer.write("\t");
        writer.write(Integer.toString(i));
        writer.write("\n");
      }
    }
  finally {
      writer.close();
    }
    KeyValueTextInputFormat format=new KeyValueTextInputFormat();
    assertTrue("KVTIF claims not splittable",format.isSplitable(job,file));
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(MAX_LENGTH / 2000) + 1;
      LOG.info("splitting: requesting = " + numSplits);
      List<InputSplit> splits=format.getSplits(job);
      LOG.info("splitting: got =        " + splits.size());
      BitSet bits=new BitSet(length);
      for (int j=0; j < splits.size(); j++) {
        LOG.debug("split[" + j + "]= "+ splits.get(j));
        TaskAttemptContext context=MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration());
        RecordReader<Text,Text> reader=format.createRecordReader(splits.get(j),context);
        Class<?> clazz=reader.getClass();
        MapContext<Text,Text,Text,Text> mcontext=new MapContextImpl<Text,Text,Text,Text>(job.getConfiguration(),context.getTaskAttemptID(),reader,null,null,MapReduceTestUtil.createDummyReporter(),splits.get(j));
        reader.initialize(splits.get(j),mcontext);
        Text key=null;
        Text value=null;
        try {
          int count=0;
          while (reader.nextKeyValue()) {
            key=reader.getCurrentKey();
            value=reader.getCurrentValue();
            final int k=Integer.parseInt(key.toString());
            final int v=Integer.parseInt(value.toString());
            assertEquals("Bad key",0,k % 2);
            assertEquals("Mismatched key/value",k / 2,v);
            LOG.debug("read " + k + ","+ v);
            assertFalse(k + "," + v+ " in multiple partitions.",bits.get(v));
            bits.set(v);
            count++;
          }
          if (count > 0) {
            LOG.info("splits[" + j + "]="+ splits.get(j)+ " count="+ count);
          }
 else {
            LOG.debug("splits[" + j + "]="+ splits.get(j)+ " count="+ count);
          }
        }
  finally {
          reader.close();
        }
      }
      assertEquals("Some keys in no partition.",length,bits.cardinality());
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.lib.input.TestMultipleInputs </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testDoMultipleInputs() throws IOException {
  Path in1Dir=getDir(IN1_DIR);
  Path in2Dir=getDir(IN2_DIR);
  Path outDir=getDir(OUT_DIR);
  Configuration conf=createJobConf();
  FileSystem fs=FileSystem.get(conf);
  fs.delete(outDir,true);
  DataOutputStream file1=fs.create(new Path(in1Dir,"part-0"));
  file1.writeBytes("a\nb\nc\nd\ne");
  file1.close();
  DataOutputStream file2=fs.create(new Path(in2Dir,"part-0"));
  file2.writeBytes("a\tblah\nb\tblah\nc\tblah\nd\tblah\ne\tblah");
  file2.close();
  Job job=Job.getInstance(conf);
  job.setJobName("mi");
  MultipleInputs.addInputPath(job,in1Dir,TextInputFormat.class,MapClass.class);
  MultipleInputs.addInputPath(job,in2Dir,KeyValueTextInputFormat.class,KeyValueMapClass.class);
  job.setMapOutputKeyClass(Text.class);
  job.setMapOutputValueClass(Text.class);
  job.setOutputKeyClass(NullWritable.class);
  job.setOutputValueClass(Text.class);
  job.setReducerClass(ReducerClass.class);
  FileOutputFormat.setOutputPath(job,outDir);
  boolean success=false;
  try {
    success=job.waitForCompletion(true);
  }
 catch (  InterruptedException ie) {
    throw new RuntimeException(ie);
  }
catch (  ClassNotFoundException instante) {
    throw new RuntimeException(instante);
  }
  if (!success)   throw new RuntimeException("Job failed!");
  BufferedReader output=new BufferedReader(new InputStreamReader(fs.open(new Path(outDir,"part-r-00000"))));
  assertTrue(output.readLine().equals("a 2"));
  assertTrue(output.readLine().equals("b 2"));
  assertTrue(output.readLine().equals("c 2"));
  assertTrue(output.readLine().equals("d 2"));
  assertTrue(output.readLine().equals("e 2"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.lib.jobcontrol.TestControlledJob </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testAddingDependingJobToRunningJobFails() throws Exception {
  Configuration conf=new Configuration();
  ControlledJob job1=new ControlledJob(conf);
  job1.setJobState(ControlledJob.State.RUNNING);
  assertFalse(job1.addDependingJob(new ControlledJob(conf)));
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testAddingDependingJobToCompletedJobFails() throws Exception {
  Configuration conf=new Configuration();
  ControlledJob job1=new ControlledJob(conf);
  job1.setJobState(ControlledJob.State.SUCCESS);
  assertFalse(job1.addDependingJob(new ControlledJob(conf)));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.lib.jobcontrol.TestMapReduceJobControlWithMocks </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFailedJob() throws Exception {
  JobControl jobControl=new JobControl("Test");
  ControlledJob job1=createFailedControlledJob(jobControl);
  ControlledJob job2=createSuccessfulControlledJob(jobControl);
  ControlledJob job3=createSuccessfulControlledJob(jobControl,job1,job2);
  ControlledJob job4=createSuccessfulControlledJob(jobControl,job3);
  runJobControl(jobControl);
  assertEquals("Success list",1,jobControl.getSuccessfulJobList().size());
  assertEquals("Failed list",3,jobControl.getFailedJobList().size());
  assertTrue(job1.getJobState() == ControlledJob.State.FAILED);
  assertTrue(job2.getJobState() == ControlledJob.State.SUCCESS);
  assertTrue(job3.getJobState() == ControlledJob.State.DEPENDENT_FAILED);
  assertTrue(job4.getJobState() == ControlledJob.State.DEPENDENT_FAILED);
  jobControl.stop();
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSuccessfulJobs() throws Exception {
  JobControl jobControl=new JobControl("Test");
  ControlledJob job1=createSuccessfulControlledJob(jobControl);
  ControlledJob job2=createSuccessfulControlledJob(jobControl);
  ControlledJob job3=createSuccessfulControlledJob(jobControl,job1,job2);
  ControlledJob job4=createSuccessfulControlledJob(jobControl,job3);
  runJobControl(jobControl);
  assertEquals("Success list",4,jobControl.getSuccessfulJobList().size());
  assertEquals("Failed list",0,jobControl.getFailedJobList().size());
  assertTrue(job1.getJobState() == ControlledJob.State.SUCCESS);
  assertTrue(job2.getJobState() == ControlledJob.State.SUCCESS);
  assertTrue(job3.getJobState() == ControlledJob.State.SUCCESS);
  assertTrue(job4.getJobState() == ControlledJob.State.SUCCESS);
  jobControl.stop();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.security.TestTokenCache </h4><pre class="type-10 type-4 type-7 type-6 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGetTokensForNamenodes() throws IOException {
  Credentials credentials=new Credentials();
  TokenCache.obtainTokensForNamenodesInternal(credentials,new Path[]{p1,p2},jConf);
  String fs_addr=SecurityUtil.buildDTServiceName(p1.toUri(),NameNode.DEFAULT_PORT);
  Token<DelegationTokenIdentifier> nnt=TokenCache.getDelegationToken(credentials,fs_addr);
  System.out.println("dt for " + p1 + "("+ fs_addr+ ")"+ " = "+ nnt);
  assertNotNull("Token for nn is null",nnt);
  Collection<Token<? extends TokenIdentifier>> tns=credentials.getAllTokens();
  assertEquals("number of tokens is not 1",1,tns.size());
  boolean found=false;
  for (  Token<? extends TokenIdentifier> t : tns) {
    if (t.getKind().equals(DelegationTokenIdentifier.HDFS_DELEGATION_KIND) && t.getService().equals(new Text(fs_addr))) {
      found=true;
    }
    assertTrue("didn't find token for " + p1,found);
  }
}

</code></pre>

<br>
<pre class="type-10 type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGetTokensForHftpFS() throws IOException, URISyntaxException {
  HftpFileSystem hfs=mock(HftpFileSystem.class);
  DelegationTokenSecretManager dtSecretManager=dfsCluster.getNamesystem().getDelegationTokenSecretManager();
  String renewer="renewer";
  jConf.set(JTConfig.JT_USER_NAME,renewer);
  DelegationTokenIdentifier dtId=new DelegationTokenIdentifier(new Text("user"),new Text(renewer),null);
  final Token<DelegationTokenIdentifier> t=new Token<DelegationTokenIdentifier>(dtId,dtSecretManager);
  final URI uri=new URI("hftp://host:2222/file1");
  final String fs_addr=SecurityUtil.buildDTServiceName(uri,NameNode.DEFAULT_PORT);
  t.setService(new Text(fs_addr));
  Mockito.doAnswer(new Answer<URI>(){
    @Override public URI answer(    InvocationOnMock invocation) throws Throwable {
      return uri;
    }
  }
).when(hfs).getUri();
  Mockito.doAnswer(new Answer<Token<DelegationTokenIdentifier>>(){
    @Override public Token<DelegationTokenIdentifier> answer(    InvocationOnMock invocation) throws Throwable {
      return t;
    }
  }
).when(hfs).getDelegationToken(renewer);
  Mockito.doAnswer(new Answer<String>(){
    @Override public String answer(    InvocationOnMock invocation) throws Throwable {
      return fs_addr;
    }
  }
).when(hfs).getCanonicalServiceName();
  Credentials credentials=new Credentials();
  Path p=new Path(uri.toString());
  System.out.println("Path for hftp=" + p + "; fs_addr="+ fs_addr+ "; rn="+ renewer);
  TokenCache.obtainTokensForNamenodesInternal(hfs,credentials,jConf);
  Collection<Token<? extends TokenIdentifier>> tns=credentials.getAllTokens();
  assertEquals("number of tokens is not 1",1,tns.size());
  boolean found=false;
  for (  Token<? extends TokenIdentifier> tt : tns) {
    System.out.println("token=" + tt);
    if (tt.getKind().equals(DelegationTokenIdentifier.HDFS_DELEGATION_KIND) && tt.getService().equals(new Text(fs_addr))) {
      found=true;
      assertEquals("different token",tt,t);
    }
    assertTrue("didn't find token for " + p,found);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Basic idea of the test:
 * 1. create tokens.
 * 2. Mark one of them to be renewed in 2 seconds (istead of
 * 24 hourse)
 * 3. register them for renewal
 * 4. sleep for 3 seconds
 * 5. count number of renewals (should 3 initial ones + one extra)
 * 6. register another token for 2 seconds 
 * 7. cancel it immediately
 * 8. Sleep and check that the 2 seconds renew didn't happen 
 * (totally 5 reneals)
 * 9. check cancelation
 * @throws IOException
 * @throws URISyntaxException
 */
@Test public void testDTRenewal() throws IOException, URISyntaxException {
  MyFS dfs=(MyFS)FileSystem.get(conf);
  System.out.println("dfs=" + (Object)dfs);
  MyToken token1, token2, token3;
  token1=dfs.getDelegationToken(new Text("user1"));
  token2=dfs.getDelegationToken(new Text("user2"));
  token3=dfs.getDelegationToken(new Text("user3"));
  dfs.setTokenToRenewIn2Sec(token1);
  System.out.println("token=" + token1 + " should be renewed for 2 secs");
  String nn1=DelegationTokenRenewal.SCHEME + "://host1:0";
  String nn2=DelegationTokenRenewal.SCHEME + "://host2:0";
  String nn3=DelegationTokenRenewal.SCHEME + "://host3:0";
  Credentials ts=new Credentials();
  ts.addToken(new Text(nn1),token1);
  ts.addToken(new Text(nn2),token2);
  ts.addToken(new Text(nn3),token3);
  DelegationTokenRenewal.registerDelegationTokensForRenewal(new JobID("job1",1),ts,conf);
  int numberOfExpectedRenewals=3 + 1;
  int attempts=10;
  while (attempts-- > 0) {
    try {
      Thread.sleep(3 * 1000);
    }
 catch (    InterruptedException e) {
    }
    if (dfs.getCounter() == numberOfExpectedRenewals)     break;
  }
  System.out.println("Counter = " + dfs.getCounter() + ";t="+ dfs.getToken());
  assertEquals("renew wasn't called as many times as expected(4):",numberOfExpectedRenewals,dfs.getCounter());
  assertEquals("most recently renewed token mismatch",dfs.getToken(),token1);
  ts=new Credentials();
  MyToken token4=dfs.getDelegationToken(new Text("user4"));
  dfs.setTokenToRenewIn2Sec(token4);
  System.out.println("token=" + token4 + " should be renewed for 2 secs");
  String nn4=DelegationTokenRenewal.SCHEME + "://host4:0";
  ts.addToken(new Text(nn4),token4);
  JobID jid2=new JobID("job2",1);
  DelegationTokenRenewal.registerDelegationTokensForRenewal(jid2,ts,conf);
  DelegationTokenRenewal.removeDelegationTokenRenewalForJob(jid2);
  numberOfExpectedRenewals=dfs.getCounter();
  try {
    Thread.sleep(6 * 1000);
  }
 catch (  InterruptedException e) {
  }
  System.out.println("Counter = " + dfs.getCounter() + ";t="+ dfs.getToken());
  assertEquals("renew wasn't called as many times as expected",numberOfExpectedRenewals,dfs.getCounter());
  boolean exception=false;
  try {
    dfs.renewDelegationToken(token4);
  }
 catch (  InvalidToken ite) {
    exception=true;
  }
  assertTrue("Renew of canceled token didn't fail",exception);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.security.token.delegation.TestDelegationToken </h4><pre class="type-14 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDelegationToken() throws Exception {
  JobClient client;
  client=user1.doAs(new PrivilegedExceptionAction<JobClient>(){
    @Override public JobClient run() throws Exception {
      return new JobClient(cluster.createJobConf());
    }
  }
);
  JobClient bobClient;
  bobClient=user2.doAs(new PrivilegedExceptionAction<JobClient>(){
    @Override public JobClient run() throws Exception {
      return new JobClient(cluster.createJobConf());
    }
  }
);
  Token<DelegationTokenIdentifier> token=client.getDelegationToken(new Text(user1.getUserName()));
  DataInputBuffer inBuf=new DataInputBuffer();
  byte[] bytes=token.getIdentifier();
  inBuf.reset(bytes,bytes.length);
  DelegationTokenIdentifier ident=new DelegationTokenIdentifier();
  ident.readFields(inBuf);
  assertEquals("alice",ident.getUser().getUserName());
  long createTime=ident.getIssueDate();
  long maxTime=ident.getMaxDate();
  long currentTime=System.currentTimeMillis();
  System.out.println("create time: " + createTime);
  System.out.println("current time: " + currentTime);
  System.out.println("max time: " + maxTime);
  assertTrue("createTime < current",createTime < currentTime);
  assertTrue("current < maxTime",currentTime < maxTime);
  client.renewDelegationToken(token);
  client.renewDelegationToken(token);
  try {
    bobClient.renewDelegationToken(token);
    Assert.fail("bob renew");
  }
 catch (  AccessControlException ace) {
  }
  try {
    bobClient.cancelDelegationToken(token);
    Assert.fail("bob renew");
  }
 catch (  AccessControlException ace) {
  }
  client.cancelDelegationToken(token);
  try {
    client.cancelDelegationToken(token);
    Assert.fail("second alice cancel");
  }
 catch (  InvalidToken it) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * This test creates some directories inside the toBeDeleted directory and
 * then start the asyncDiskService.
 * AsyncDiskService will create tasks to delete the content inside the
 * toBeDeleted directories.
 */
@Test public void testMRAsyncDiskServiceStartupCleaning() throws Throwable {
  FileSystem localFileSystem=FileSystem.getLocal(new Configuration());
  String[] vols=new String[]{TEST_ROOT_DIR + "/0",TEST_ROOT_DIR + "/1"};
  String a="a";
  String b="b";
  String c="b/c";
  String d="d";
  String suffix=Path.SEPARATOR_CHAR + MRAsyncDiskService.TOBEDELETED;
  File fa=new File(vols[0] + suffix,a);
  File fb=new File(vols[1] + suffix,b);
  File fc=new File(vols[1] + suffix,c);
  File fd=new File(vols[1] + suffix,d);
  fa.mkdirs();
  fb.mkdirs();
  fc.mkdirs();
  fd.mkdirs();
  assertTrue(fa.exists());
  assertTrue(fb.exists());
  assertTrue(fc.exists());
  assertTrue(fd.exists());
  MRAsyncDiskService service=new MRAsyncDiskService(localFileSystem,vols);
  makeSureCleanedUp(vols,service);
}

</code></pre>

<br>
<pre class="type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testToleratesSomeUnwritableVolumes() throws Throwable {
  FileSystem localFileSystem=FileSystem.getLocal(new Configuration());
  String[] vols=new String[]{TEST_ROOT_DIR + "/0",TEST_ROOT_DIR + "/1"};
  assertTrue(new File(vols[0]).mkdirs());
  assertEquals(0,FileUtil.chmod(vols[0],"400"));
  try {
    new MRAsyncDiskService(localFileSystem,vols);
  }
  finally {
    FileUtil.chmod(vols[0],"755");
  }
}

</code></pre>

<br>
<pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * This test creates some directories inside the volume roots, and then 
 * call asyncDiskService.MoveAndDeleteAllVolumes.
 * We should be able to delete all files/dirs inside the volumes except
 * the toBeDeleted directory.
 */
@Test public void testMRAsyncDiskServiceMoveAndDeleteAllVolumes() throws Throwable {
  FileSystem localFileSystem=FileSystem.getLocal(new Configuration());
  String[] vols=new String[]{TEST_ROOT_DIR + "/0",TEST_ROOT_DIR + "/1"};
  MRAsyncDiskService service=new MRAsyncDiskService(localFileSystem,vols);
  String a="a";
  String b="b";
  String c="b/c";
  String d="d";
  File fa=new File(vols[0],a);
  File fb=new File(vols[1],b);
  File fc=new File(vols[1],c);
  File fd=new File(vols[1],d);
  fa.mkdirs();
  fb.mkdirs();
  fc.mkdirs();
  fd.mkdirs();
  assertTrue(fa.exists());
  assertTrue(fb.exists());
  assertTrue(fc.exists());
  assertTrue(fd.exists());
  service.cleanupAllVolumes();
  assertFalse(fa.exists());
  assertFalse(fb.exists());
  assertFalse(fc.exists());
  assertFalse(fd.exists());
  makeSureCleanedUp(vols,service);
}

</code></pre>

<br>
<pre class="type-4 type-7 type-6 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test creates some directories and then removes them through 
 * MRAsyncDiskService. 
 */
@Test public void testMRAsyncDiskService() throws Throwable {
  FileSystem localFileSystem=FileSystem.getLocal(new Configuration());
  String[] vols=new String[]{TEST_ROOT_DIR + "/0",TEST_ROOT_DIR + "/1"};
  MRAsyncDiskService service=new MRAsyncDiskService(localFileSystem,vols);
  String a="a";
  String b="b";
  String c="b/c";
  String d="d";
  File fa=new File(vols[0],a);
  File fb=new File(vols[1],b);
  File fc=new File(vols[1],c);
  File fd=new File(vols[1],d);
  fa.mkdirs();
  fb.mkdirs();
  fc.mkdirs();
  fd.mkdirs();
  assertTrue(fa.exists());
  assertTrue(fb.exists());
  assertTrue(fc.exists());
  assertTrue(fd.exists());
  service.moveAndDeleteRelativePath(vols[0],a);
  assertFalse(fa.exists());
  service.moveAndDeleteRelativePath(vols[1],b);
  assertFalse(fb.exists());
  assertFalse(fc.exists());
  assertFalse(service.moveAndDeleteRelativePath(vols[1],"not_exists"));
  IOException ee=null;
  try {
    service.moveAndDeleteAbsolutePath(TEST_ROOT_DIR + "/2");
  }
 catch (  IOException e) {
    ee=e;
  }
  assertNotNull("asyncDiskService should not be able to delete files " + "outside all volumes",ee);
  assertTrue(service.moveAndDeleteAbsolutePath(vols[1] + Path.SEPARATOR_CHAR + d));
  makeSureCleanedUp(vols,service);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.raid.TestBlockFixer </h4><pre class="type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the filtering of trash files from the list of corrupt files.
 */
@Test public void testTrashFilter(){
  List<Path> files=new LinkedList<Path>();
  Path p1=new Path("/user/raid/raidtest/f1");
  Path p2=new Path("/user/.Trash/");
  Path p3=new Path("/user/raid/.Trash/raidtest/f1");
  Path p4=new Path("/user/raid/.Trash/");
  files.add(p1);
  files.add(p3);
  files.add(p4);
  files.add(p2);
  Configuration conf=new Configuration();
  RaidUtils.filterTrash(conf,files);
  assertEquals("expected 2 non-trash files but got " + files.size(),2,files.size());
  for (  Path p : files) {
    assertTrue("wrong file returned by filterTrash",p == p1 || p == p2);
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Tests isXorParityFile and isRsParityFile
 */
@Test public void testIsParityFile() throws IOException {
  Configuration testConf=new Configuration();
  testConf.set("hdfs.raid.locations","/raid");
  testConf.set("hdfs.raidrs.locations","/raidrs");
  BlockFixer.BlockFixerHelper helper=new BlockFixer.BlockFixerHelper(testConf);
  assertFalse("incorrectly identified rs parity file as xor parity file",helper.isXorParityFile(new Path("/raidrs/test/test")));
  assertTrue("could not identify rs parity file",helper.isRsParityFile(new Path("/raidrs/test/test")));
  assertTrue("could not identify xor parity file",helper.isXorParityFile(new Path("/raid/test/test")));
  assertFalse("incorrectly identified xor parity file as rs parity file",helper.isRsParityFile(new Path("/raid/test/test")));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.raid.TestBlockFixerDistConcurrency </h4><pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * tests that we can have 2 concurrent jobs fixing files 
 * (dist block fixer)
 */
@Test public void testConcurrentJobs() throws Exception {
  LOG.info("Test testConcurrentJobs started.");
  long blockSize=8192L;
  int stripeLength=3;
  mySetup(stripeLength,-1);
  Path file1=new Path("/user/dhruba/raidtest/file1");
  Path file2=new Path("/user/dhruba/raidtest/file2");
  Path destPath=new Path("/destraid/user/dhruba/raidtest");
  long crc1=TestRaidDfs.createTestFilePartialLastBlock(fileSys,file1,1,20,blockSize);
  long crc2=TestRaidDfs.createTestFilePartialLastBlock(fileSys,file2,1,20,blockSize);
  long file1Len=fileSys.getFileStatus(file1).getLen();
  long file2Len=fileSys.getFileStatus(file2).getLen();
  LOG.info("Test testConcurrentJobs created test files");
  Configuration localConf=new Configuration(conf);
  localConf.set(RaidNode.RAID_LOCATION_KEY,"/destraid");
  localConf.setInt("raid.blockfix.interval",1000);
  localConf.set("raid.blockfix.classname","org.apache.hadoop.raid.DistBlockFixer");
  localConf.setLong("raid.blockfix.filespertask",2L);
  try {
    cnode=RaidNode.createRaidNode(null,localConf);
    TestRaidDfs.waitForFileRaided(LOG,fileSys,file1,destPath);
    TestRaidDfs.waitForFileRaided(LOG,fileSys,file2,destPath);
    cnode.stop();
    cnode.join();
    FileStatus file1Stat=fileSys.getFileStatus(file1);
    FileStatus file2Stat=fileSys.getFileStatus(file2);
    DistributedFileSystem dfs=(DistributedFileSystem)fileSys;
    LocatedBlocks file1Loc=RaidDFSUtil.getBlockLocations(dfs,file1.toUri().getPath(),0,file1Stat.getLen());
    LocatedBlocks file2Loc=RaidDFSUtil.getBlockLocations(dfs,file2.toUri().getPath(),0,file2Stat.getLen());
    String[] corruptFiles=RaidDFSUtil.getCorruptFiles(dfs);
    assertEquals("no corrupt files expected",0,corruptFiles.length);
    assertEquals("filesFixed() should return 0 before fixing files",0,cnode.blockFixer.filesFixed());
    int[] corruptBlockIdxs=new int[]{0,4,6};
    for (    int idx : corruptBlockIdxs)     corruptBlock(file1Loc.get(idx).getBlock());
    reportCorruptBlocks(dfs,file1,corruptBlockIdxs,blockSize);
    cnode=RaidNode.createRaidNode(null,localConf);
    DistBlockFixer blockFixer=(DistBlockFixer)cnode.blockFixer;
    long start=System.currentTimeMillis();
    while (blockFixer.jobsRunning() < 1 && System.currentTimeMillis() - start < 240000) {
      LOG.info("Test testBlockFix waiting for fixing job 1 to start");
      Thread.sleep(10);
    }
    assertEquals("job 1 not running",1,blockFixer.jobsRunning());
    for (    int idx : corruptBlockIdxs)     corruptBlock(file2Loc.get(idx).getBlock());
    reportCorruptBlocks(dfs,file2,corruptBlockIdxs,blockSize);
    while (blockFixer.jobsRunning() < 2 && System.currentTimeMillis() - start < 240000) {
      LOG.info("Test testBlockFix waiting for fixing job 2 to start");
      Thread.sleep(10);
    }
    assertEquals("2 jobs not running",2,blockFixer.jobsRunning());
    while (blockFixer.filesFixed() < 2 && System.currentTimeMillis() - start < 240000) {
      LOG.info("Test testBlockFix waiting for files to be fixed.");
      Thread.sleep(10);
    }
    assertEquals("files not fixed",2,blockFixer.filesFixed());
    dfs=getDFS(conf,dfs);
    try {
      Thread.sleep(5 * 1000);
    }
 catch (    InterruptedException ignore) {
    }
    assertTrue("file not fixed",TestRaidDfs.validateFile(dfs,file1,file1Len,crc1));
    assertTrue("file not fixed",TestRaidDfs.validateFile(dfs,file2,file2Len,crc2));
  }
 catch (  Exception e) {
    LOG.info("Test testConcurrentJobs exception " + e + StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    myTearDown();
  }
}

</code></pre>

<br>
<pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * tests that the distributed block fixer obeys
 * the limit on how many files to fix simultaneously
 */
@Test public void testMaxPendingFiles() throws Exception {
  LOG.info("Test testMaxPendingFiles started.");
  long blockSize=8192L;
  int stripeLength=3;
  mySetup(stripeLength,-1);
  Path file1=new Path("/user/dhruba/raidtest/file1");
  Path file2=new Path("/user/dhruba/raidtest/file2");
  Path destPath=new Path("/destraid/user/dhruba/raidtest");
  long crc1=TestRaidDfs.createTestFilePartialLastBlock(fileSys,file1,1,20,blockSize);
  long crc2=TestRaidDfs.createTestFilePartialLastBlock(fileSys,file2,1,20,blockSize);
  long file1Len=fileSys.getFileStatus(file1).getLen();
  long file2Len=fileSys.getFileStatus(file2).getLen();
  LOG.info("Test testMaxPendingFiles created test files");
  Configuration localConf=new Configuration(conf);
  localConf.set(RaidNode.RAID_LOCATION_KEY,"/destraid");
  localConf.setInt("raid.blockfix.interval",1000);
  localConf.set("raid.blockfix.classname","org.apache.hadoop.raid.DistBlockFixer");
  localConf.setLong("raid.blockfix.filespertask",2L);
  localConf.setLong("raid.blockfix.maxpendingfiles",1L);
  try {
    cnode=RaidNode.createRaidNode(null,localConf);
    TestRaidDfs.waitForFileRaided(LOG,fileSys,file1,destPath);
    TestRaidDfs.waitForFileRaided(LOG,fileSys,file2,destPath);
    cnode.stop();
    cnode.join();
    FileStatus file1Stat=fileSys.getFileStatus(file1);
    FileStatus file2Stat=fileSys.getFileStatus(file2);
    DistributedFileSystem dfs=(DistributedFileSystem)fileSys;
    LocatedBlocks file1Loc=RaidDFSUtil.getBlockLocations(dfs,file1.toUri().getPath(),0,file1Stat.getLen());
    LocatedBlocks file2Loc=RaidDFSUtil.getBlockLocations(dfs,file2.toUri().getPath(),0,file2Stat.getLen());
    String[] corruptFiles=RaidDFSUtil.getCorruptFiles(dfs);
    assertEquals("no corrupt files expected",0,corruptFiles.length);
    assertEquals("filesFixed() should return 0 before fixing files",0,cnode.blockFixer.filesFixed());
    int[] corruptBlockIdxs=new int[]{0,4,6};
    for (    int idx : corruptBlockIdxs)     corruptBlock(file1Loc.get(idx).getBlock());
    reportCorruptBlocks(dfs,file1,corruptBlockIdxs,blockSize);
    corruptFiles=RaidDFSUtil.getCorruptFiles(dfs);
    cnode=RaidNode.createRaidNode(null,localConf);
    DistBlockFixer blockFixer=(DistBlockFixer)cnode.blockFixer;
    long start=System.currentTimeMillis();
    while (blockFixer.jobsRunning() < 1 && System.currentTimeMillis() - start < 240000) {
      LOG.info("Test testBlockFix waiting for fixing job 1 to start");
      Thread.sleep(10);
    }
    assertEquals("job not running",1,blockFixer.jobsRunning());
    for (    int idx : corruptBlockIdxs)     corruptBlock(file2Loc.get(idx).getBlock());
    reportCorruptBlocks(dfs,file2,corruptBlockIdxs,blockSize);
    corruptFiles=RaidDFSUtil.getCorruptFiles(dfs);
    while (blockFixer.filesFixed() < 2 && System.currentTimeMillis() - start < 240000) {
      assertTrue("too many jobs running",blockFixer.jobsRunning() <= 1);
      Thread.sleep(10);
    }
    assertEquals("files not fixed",2,blockFixer.filesFixed());
    dfs=getDFS(conf,dfs);
    try {
      Thread.sleep(5 * 1000);
    }
 catch (    InterruptedException ignore) {
    }
    assertTrue("file not fixed",TestRaidDfs.validateFile(dfs,file1,file1Len,crc1));
    assertTrue("file not fixed",TestRaidDfs.validateFile(dfs,file2,file2Len,crc2));
  }
 catch (  Exception e) {
    LOG.info("Test testMaxPendingFiles exception " + e + StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    myTearDown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.raid.TestRaidShellFsck </h4><pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with missing block in file block but not in parity block
 */
@Test public void testFileBlockMissing() throws Exception {
  LOG.info("testFileBlockMissing");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,0,0);
  waitUntilCorruptFileCount(dfs,1);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with missing block in parity block but not in file block
 */
@Test public void testParityBlockMissing() throws Exception {
  LOG.info("testParityBlockMissing");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeParityBlock(FILE_PATH0,0);
  waitUntilCorruptFileCount(dfs,1);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with file block missing (HAR)
 * use 2 files to verify HAR offset logic in RaidShell fsck
 * parity blocks in har (file.stripe):
 * +-----+-----+-----+  +-----+
 * | 0.0 | 0.1 | 1.0 |  | 1.1 |
 * +-----+-----+-----+  +-----+
 * 0                    1
 * corrupt file 0, stripe 0 file block 0
 * corrupt file 0, stripe 1 file block 0
 * corrupt file 1, stripe 0 file block 0
 * corrupt file 1, stripe 1 file block 0
 * corrupt har block 0
 * both files should be corrupt
 */
@Test public void testFileBlockAndParityBlockMissingHar1() throws Exception {
  LOG.info("testFileBlockAndParityBlockMissingHar1");
  setUp(true);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,0,0);
  removeFileBlock(FILE_PATH0,1,0);
  removeFileBlock(FILE_PATH1,0,0);
  removeFileBlock(FILE_PATH1,1,0);
  removeHarParityBlock(0);
  waitUntilCorruptFileCount(dfs,3);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 2, but returns " + Integer.toString(result),result == 2);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with missing block in both file block and parity block
 * in same stripe
 */
@Test public void testFileBlockAndParityBlockMissingInSameStripe() throws Exception {
  LOG.info("testFileBlockAndParityBlockMissingInSameStripe");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeParityBlock(FILE_PATH0,1);
  waitUntilCorruptFileCount(dfs,1);
  removeFileBlock(FILE_PATH0,1,0);
  waitUntilCorruptFileCount(dfs,2);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 1, but returns " + Integer.toString(result),result == 1);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with two missing file blocks in different stripes
 */
@Test public void test2FileBlocksMissingInDifferentStripes() throws Exception {
  LOG.info("test2FileBlocksMissingInDifferentStripes");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,1,1);
  waitUntilCorruptFileCount(dfs,1);
  removeFileBlock(FILE_PATH0,0,0);
  waitUntilCorruptFileCount(dfs,1);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with no missing blocks
 */
@Test public void testClean() throws Exception {
  LOG.info("testClean");
  setUp(false);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with missing block in both file block and parity block
 * in different stripes
 */
@Test public void testFileBlockAndParityBlockMissingInDifferentStripes() throws Exception {
  LOG.info("testFileBlockAndParityBlockMissingInDifferentStripes");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,0,0);
  waitUntilCorruptFileCount(dfs,1);
  removeParityBlock(FILE_PATH0,1);
  waitUntilCorruptFileCount(dfs,2);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with file block missing (HAR)
 * use 2 files to verify HAR offset logic in RaidShell fsck
 * both files have one corrupt block, parity blocks are clean
 * parity blocks in har (file.stripe):
 * +-----+-----+-----+  +-----+
 * | 0.0 | 0.1 | 1.0 |  | 1.1 |
 * +-----+-----+-----+  +-----+
 * 0                    1
 */
@Test public void testFileBlockMissingHar() throws Exception {
  LOG.info("testFileBlockMissingHar");
  setUp(true);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,1,1);
  removeFileBlock(FILE_PATH1,1,1);
  waitUntilCorruptFileCount(dfs,2);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks that fsck does not report corrupt file that is not in
 * the specified path
 */
@Test public void testPathFilter() throws Exception {
  LOG.info("testPathFilter");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeParityBlock(FILE_PATH0,1);
  waitUntilCorruptFileCount(dfs,1);
  removeFileBlock(FILE_PATH0,1,0);
  waitUntilCorruptFileCount(dfs,2);
  String[] otherArgs=new String[2];
  otherArgs[0]="-fsck";
  otherArgs[1]="/user/pkling/other";
  int result=ToolRunner.run(shell,otherArgs);
  assertTrue("fsck should return 0, but returns " + Integer.toString(result),result == 0);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with file block missing (HAR)
 * use 2 files to verify HAR offset logic in RaidShell fsck
 * parity blocks in har (file.stripe):
 * +-----+-----+-----+  +-----+
 * | 0.0 | 0.1 | 1.0 |  | 1.1 |
 * +-----+-----+-----+  +-----+
 * 0                    1
 * corrupt file 0, stripe 0 file block 0
 * corrupt file 0, stripe 1 file block 0
 * corrupt file 1, stripe 0 file block 0
 * corrupt file 1, stripe 1 file block 0
 * corrupt har block 1
 * only file 2 should be corrupt
 */
@Test public void testFileBlockAndParityBlockMissingHar2() throws Exception {
  LOG.info("testFileBlockAndParityBlockMissingHar2");
  setUp(true);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,0,0);
  removeFileBlock(FILE_PATH0,1,0);
  removeFileBlock(FILE_PATH1,0,0);
  removeFileBlock(FILE_PATH1,1,0);
  removeHarParityBlock(1);
  waitUntilCorruptFileCount(dfs,3);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 1, but returns " + Integer.toString(result),result == 1);
}

</code></pre>

<br>
<pre class="type-10 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * checks fsck with two missing file blocks in same stripe
 */
@Test public void test2FileBlocksMissingInSameStripe() throws Exception {
  LOG.info("test2FileBlocksMissingInSameStripe");
  setUp(false);
  waitUntilCorruptFileCount(dfs,0);
  removeFileBlock(FILE_PATH0,1,1);
  waitUntilCorruptFileCount(dfs,1);
  removeFileBlock(FILE_PATH0,1,0);
  waitUntilCorruptFileCount(dfs,1);
  int result=ToolRunner.run(shell,args);
  assertTrue("fsck should return 1, but returns " + Integer.toString(result),result == 1);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.security.TestMapredGroupMappingServiceRefresh </h4><pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGroupMappingRefresh() throws Exception {
  MRAdmin admin=new MRAdmin(config);
  String[] args=new String[]{"-refreshUserToGroupsMappings"};
  Groups groups=Groups.getUserToGroupsMappingService(config);
  String user=UserGroupInformation.getLoginUser().getShortUserName();
  System.out.println("first attempt:");
  List<String> g1=groups.getGroups(user);
  String[] str_groups=new String[g1.size()];
  g1.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  System.out.println("second attempt, should be same:");
  List<String> g2=groups.getGroups(user);
  g2.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g2.size(); i++) {
    assertEquals("Should be same group ",g1.get(i),g2.get(i));
  }
  admin.run(args);
  System.out.println("third attempt(after refresh command), should be different:");
  List<String> g3=groups.getGroups(user);
  g3.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g3.size(); i++) {
    assertFalse("Should be different group ",g1.get(i).equals(g3.get(i)));
  }
  System.out.println("");
  Thread.sleep(groupRefreshTimeoutSec * 1100);
  System.out.println("fourth attempt(after timeout), should be different:");
  List<String> g4=groups.getGroups(user);
  g4.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g4.size(); i++) {
    assertFalse("Should be different group ",g3.get(i).equals(g4.get(i)));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestAutoInputFormat </h4><pre class="type-11 type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@SuppressWarnings({"unchecked","deprecation"}) @Test public void testFormat() throws IOException {
  JobConf job=new JobConf(conf);
  FileSystem fs=FileSystem.getLocal(conf);
  Path dir=new Path(System.getProperty("test.build.data",".") + "/mapred");
  Path txtFile=new Path(dir,"auto.txt");
  Path seqFile=new Path(dir,"auto.seq");
  fs.delete(dir,true);
  FileInputFormat.setInputPaths(job,dir);
  Writer txtWriter=new OutputStreamWriter(fs.create(txtFile));
  try {
    for (int i=0; i < LINES_COUNT; i++) {
      txtWriter.write("" + (10 * i));
      txtWriter.write("\n");
    }
  }
  finally {
    txtWriter.close();
  }
  SequenceFile.Writer seqWriter=SequenceFile.createWriter(fs,conf,seqFile,IntWritable.class,LongWritable.class);
  try {
    for (int i=0; i < RECORDS_COUNT; i++) {
      IntWritable key=new IntWritable(11 * i);
      LongWritable value=new LongWritable(12 * i);
      seqWriter.append(key,value);
    }
  }
  finally {
    seqWriter.close();
  }
  AutoInputFormat format=new AutoInputFormat();
  InputSplit[] splits=format.getSplits(job,SPLITS_COUNT);
  for (  InputSplit split : splits) {
    RecordReader reader=format.getRecordReader(split,job,Reporter.NULL);
    Object key=reader.createKey();
    Object value=reader.createValue();
    try {
      while (reader.next(key,value)) {
        if (key instanceof LongWritable) {
          assertEquals("Wrong value class.",Text.class,value.getClass());
          assertTrue("Invalid value",Integer.parseInt(((Text)value).toString()) % 10 == 0);
        }
 else {
          assertEquals("Wrong key class.",IntWritable.class,key.getClass());
          assertEquals("Wrong value class.",LongWritable.class,value.getClass());
          assertTrue("Invalid key.",((IntWritable)key).get() % 11 == 0);
          assertTrue("Invalid value.",((LongWritable)value).get() % 12 == 0);
        }
      }
    }
  finally {
      reader.close();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestDumpTypedBytes </h4><pre class="type-10 type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDumping() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=new MiniDFSCluster(conf,2,true,null);
  FileSystem fs=cluster.getFileSystem();
  PrintStream psBackup=System.out;
  ByteArrayOutputStream out=new ByteArrayOutputStream();
  PrintStream psOut=new PrintStream(out);
  System.setOut(psOut);
  DumpTypedBytes dumptb=new DumpTypedBytes(conf);
  try {
    Path root=new Path("/typedbytestest");
    assertTrue(fs.mkdirs(root));
    assertTrue(fs.exists(root));
    OutputStreamWriter writer=new OutputStreamWriter(fs.create(new Path(root,"test.txt")));
    try {
      for (int i=0; i < 100; i++) {
        writer.write("" + (10 * i) + "\n");
      }
    }
  finally {
      writer.close();
    }
    String[] args=new String[1];
    args[0]="/typedbytestest";
    int ret=dumptb.run(args);
    assertEquals("Return value != 0.",0,ret);
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TypedBytesInput tbinput=new TypedBytesInput(new DataInputStream(in));
    int counter=0;
    Object key=tbinput.read();
    while (key != null) {
      assertEquals(Long.class,key.getClass());
      Object value=tbinput.read();
      assertEquals(String.class,value.getClass());
      assertTrue("Invalid output.",Integer.parseInt(value.toString()) % 10 == 0);
      counter++;
      key=tbinput.read();
    }
    assertEquals("Wrong number of outputs.",100,counter);
  }
  finally {
    try {
      fs.close();
    }
 catch (    Exception e) {
    }
    System.setOut(psBackup);
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestLoadTypedBytes </h4><pre class="type-11 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testLoading() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=new MiniDFSCluster(conf,2,true,null);
  FileSystem fs=cluster.getFileSystem();
  ByteArrayOutputStream out=new ByteArrayOutputStream();
  TypedBytesOutput tboutput=new TypedBytesOutput(new DataOutputStream(out));
  for (int i=0; i < 100; i++) {
    tboutput.write(new Long(i));
    tboutput.write("" + (10 * i));
  }
  InputStream isBackup=System.in;
  ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
  System.setIn(in);
  LoadTypedBytes loadtb=new LoadTypedBytes(conf);
  try {
    Path root=new Path("/typedbytestest");
    assertTrue(fs.mkdirs(root));
    assertTrue(fs.exists(root));
    String[] args=new String[1];
    args[0]="/typedbytestest/test.seq";
    int ret=loadtb.run(args);
    assertEquals("Return value != 0.",0,ret);
    Path file=new Path(root,"test.seq");
    assertTrue(fs.exists(file));
    SequenceFile.Reader reader=new SequenceFile.Reader(fs,file,conf);
    int counter=0;
    TypedBytesWritable key=new TypedBytesWritable();
    TypedBytesWritable value=new TypedBytesWritable();
    while (reader.next(key,value)) {
      assertEquals(Long.class,key.getValue().getClass());
      assertEquals(String.class,value.getValue().getClass());
      assertTrue("Invalid record.",Integer.parseInt(value.toString()) % 10 == 0);
      counter++;
    }
    assertEquals("Wrong number of records.",100,counter);
  }
  finally {
    try {
      fs.close();
    }
 catch (    Exception e) {
    }
    System.setIn(isBackup);
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestStreaming </h4><pre class="type-3 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void setUp() throws IOException {
  UtilTest.recursiveDelete(TEST_DIR);
  assertTrue("Creating " + TEST_DIR,TEST_DIR.mkdirs());
  args.clear();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestStreamingBackground </h4><pre class="type-3 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void setUp() throws IOException {
  UtilTest.recursiveDelete(TEST_DIR);
  assertTrue(TEST_DIR.mkdirs());
  FileOutputStream out=new FileOutputStream(INPUT_FILE.getAbsoluteFile());
  out.write("hello\n".getBytes());
  out.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestStreamingCombiner </h4><pre class="type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testCommandLine() throws Exception {
  super.testCommandLine();
  String counterGrp="org.apache.hadoop.mapred.Task$Counter";
  Counters counters=job.running_.getCounters();
  assertTrue(counters.findCounter(counterGrp,"COMBINE_INPUT_RECORDS").getValue() != 0);
  assertTrue(counters.findCounter(counterGrp,"COMBINE_OUTPUT_RECORDS").getValue() != 0);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestStreamingExitStatus </h4><pre class="type-3 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void setUp() throws IOException {
  UtilTest.recursiveDelete(TEST_DIR);
  assertTrue(TEST_DIR.mkdirs());
  FileOutputStream out=new FileOutputStream(INPUT_FILE.getAbsoluteFile());
  out.write("hello\n".getBytes());
  out.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestStreamingTaskLog </h4><pre class="type-10 type-14 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test validates the setting of HADOOP_ROOT_LOGGER to 'INFO,TLA' and the
 * dependent properties
 * (a) hadoop.tasklog.taskid and
 * (b) hadoop.tasklog.totalLogFileSize
 * for the children of java tasks in streaming jobs.
 */
@Test public void testStreamingTaskLogWithHadoopCmd(){
  try {
    final int numSlaves=1;
    JobConf conf=new JobConf();
    fs=FileSystem.getLocal(conf);
    Path testDir=new Path(System.getProperty("test.build.data","/tmp"));
    if (fs.exists(testDir)) {
      fs.delete(testDir,true);
    }
    fs.mkdirs(testDir);
    File scriptFile=createScript(testDir.toString() + "/testTaskLog.sh");
    conf.setBoolean(JTConfig.JT_PERSIST_JOBSTATUS,false);
    mr=new MiniMRCluster(numSlaves,fs.getUri().toString(),1,null,null,conf);
    writeInputFile(fs,inputPath);
    map=scriptFile.getAbsolutePath();
    runStreamJobAndValidateEnv();
    fs.delete(outputPath,true);
    assertFalse("output not cleaned up",fs.exists(outputPath));
    mr.waitUntilIdle();
  }
 catch (  IOException e) {
    fail(e.toString());
  }
 finally {
    if (mr != null) {
      mr.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.streaming.TestUlimit </h4><pre class="type-14 type-4 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This tests the setting of memory limit for streaming processes.
 * This will launch a streaming app which will allocate 10MB memory.
 * First, program is launched with sufficient memory. And test expects
 * it to succeed. Then program is launched with insufficient memory and 
 * is expected to be a failure.  
 */
@Test public void testCommandLine(){
  if (UtilTest.isCygwin()) {
    return;
  }
  try {
    final int numSlaves=2;
    Configuration conf=new Configuration();
    dfs=new MiniDFSCluster(conf,numSlaves,true,null);
    fs=dfs.getFileSystem();
    mr=new MiniMRCluster(numSlaves,fs.getUri().toString(),1);
    writeInputFile(fs,inputPath);
    map=UtilTest.makeJavaCommand(UlimitApp.class,new String[]{});
    runProgram(SET_MEMORY_LIMIT);
    fs.delete(outputPath,true);
    assertFalse("output not cleaned up",fs.exists(outputPath));
    mr.waitUntilIdle();
  }
 catch (  IOException e) {
    fail(StringUtils.stringifyException(e));
  }
 finally {
    if (mr != null) {
      mr.shutdown();
    }
    if (dfs != null) {
      dfs.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.rumen.TestHistograms </h4><pre class="type-10 type-11 type-13 type-14 type-4 type-7 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * @throws IOExceptionThere should be files in the directory named by
 * ${test.build.data}/rumen/histogram-test .
 * There will be pairs of files, inputXxx.json and goldXxx.json .
 * We read the input file as a HistogramRawTestData in json. Then we
 * create a Histogram using the data field, and then a
 * LoggedDiscreteCDF using the percentiles and scale field. Finally,
 * we read the corresponding goldXxx.json as a LoggedDiscreteCDF and
 * deepCompare them.
 */
@Test public void testHistograms() throws IOException {
  final Configuration conf=new Configuration();
  final FileSystem lfs=FileSystem.getLocal(conf);
  final Path rootInputDir=new Path(System.getProperty("test.tools.input.dir","")).makeQualified(lfs);
  final Path rootInputFile=new Path(rootInputDir,"rumen/histogram-tests");
  FileStatus[] tests=lfs.listStatus(rootInputFile);
  for (int i=0; i < tests.length; ++i) {
    Path filePath=tests[i].getPath();
    String fileName=filePath.getName();
    if (fileName.startsWith("input")) {
      String testName=fileName.substring("input".length());
      Path goldFilePath=new Path(rootInputFile,"gold" + testName);
      assertTrue("Gold file dies not exist",lfs.exists(goldFilePath));
      LoggedDiscreteCDF newResult=histogramFileToCDF(filePath,lfs);
      System.out.println("Testing a Histogram for " + fileName);
      FSDataInputStream goldStream=lfs.open(goldFilePath);
      JsonObjectMapperParser<LoggedDiscreteCDF> parser=new JsonObjectMapperParser<LoggedDiscreteCDF>(goldStream,LoggedDiscreteCDF.class);
      try {
        LoggedDiscreteCDF dcdf=parser.getNext();
        dcdf.deepCompare(newResult,new TreePath(null,"<root>"));
      }
 catch (      DeepInequalityException e) {
        fail(e.path.toString());
      }
 finally {
        parser.close();
      }
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.rumen.TestPiecewiseLinearInterpolation </h4><pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
@Test public void testOneRun(){
  LoggedDiscreteCDF input=new LoggedDiscreteCDF();
  input.setMinimum(100000L);
  input.setMaximum(1100000L);
  ArrayList<LoggedSingleRelativeRanking> rankings=new ArrayList<LoggedSingleRelativeRanking>();
  rankings.add(makeRR(0.1,200000L));
  rankings.add(makeRR(0.5,800000L));
  rankings.add(makeRR(0.9,1000000L));
  input.setRankings(rankings);
  input.setNumberValues(3);
  CDFRandomGenerator gen=new CDFPiecewiseLinearRandomGenerator(input);
  Histogram values=new Histogram();
  for (int i=0; i < 1000000; ++i) {
    long value=gen.randomValue();
    values.enter(value);
  }
  int[] percentiles=new int[99];
  for (int i=0; i < 99; ++i) {
    percentiles[i]=i + 1;
  }
  long[] result=values.getCDF(100,percentiles);
  long sumErrorSquares=0L;
  for (int i=0; i < 10; ++i) {
    long error=result[i] - (10000L * i + 100000L);
    System.out.println("element " + i + ", got "+ result[i]+ ", expected "+ (10000L * i + 100000L)+ ", error = "+ error);
    sumErrorSquares+=error * error;
  }
  for (int i=10; i < 50; ++i) {
    long error=result[i] - (15000L * i + 50000L);
    System.out.println("element " + i + ", got "+ result[i]+ ", expected "+ (15000L * i + 50000L)+ ", error = "+ error);
    sumErrorSquares+=error * error;
  }
  for (int i=50; i < 90; ++i) {
    long error=result[i] - (5000L * i + 550000L);
    System.out.println("element " + i + ", got "+ result[i]+ ", expected "+ (5000L * i + 550000L)+ ", error = "+ error);
    sumErrorSquares+=error * error;
  }
  for (int i=90; i <= 100; ++i) {
    long error=result[i] - (10000L * i + 100000L);
    System.out.println("element " + i + ", got "+ result[i]+ ", expected "+ (10000L * i + 100000L)+ ", error = "+ error);
    sumErrorSquares+=error * error;
  }
  double realSumErrorSquares=(double)sumErrorSquares;
  double normalizedError=realSumErrorSquares / 100 / rankings.get(1).getDatum()/ rankings.get(1).getDatum();
  double RMSNormalizedError=Math.sqrt(normalizedError);
  System.out.println("sumErrorSquares = " + sumErrorSquares);
  System.out.println("normalizedError: " + normalizedError + ", RMSNormalizedError: "+ RMSNormalizedError);
  System.out.println("Cumulative error is " + RMSNormalizedError);
  assertTrue("The RMS relative error per bucket, " + RMSNormalizedError + ", exceeds our tolerance of "+ maximumRelativeError,RMSNormalizedError <= maximumRelativeError);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.rumen.TestRandomSeedGenerator </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testSeedGeneration(){
  long masterSeed1=42;
  long masterSeed2=43;
  assertTrue("Deterministic seeding",getSeed("stream1",masterSeed1) == getSeed("stream1",masterSeed1));
  assertTrue("Deterministic seeding",getSeed("stream2",masterSeed2) == getSeed("stream2",masterSeed2));
  assertTrue("Different streams",getSeed("stream1",masterSeed1) != getSeed("stream2",masterSeed1));
  assertTrue("Different master seeds",getSeed("stream1",masterSeed1) != getSeed("stream1",masterSeed2));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.rumen.TestRumenJobTraces </h4><pre class="type-13 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testTopologyBuilder() throws Exception {
  final TopologyBuilder subject=new TopologyBuilder();
  subject.process(new Properties());
  subject.process(new TaskAttemptFinishedEvent(TaskAttemptID.forName("attempt_200904211745_0003_m_000004_0"),TaskType.valueOf("MAP"),"STATUS",1234567890L,"/194\\.6\\.134\\.64/cluster50261\\.secondleveldomain\\.com","SUCCESS",null));
  subject.process(new TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID.forName("attempt_200904211745_0003_m_000004_1"),TaskType.valueOf("MAP"),"STATUS",1234567890L,"/194\\.6\\.134\\.80/cluster50262\\.secondleveldomain\\.com","MACHINE_EXPLODED"));
  subject.process(new TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID.forName("attempt_200904211745_0003_m_000004_2"),TaskType.valueOf("MAP"),"STATUS",1234567890L,"/194\\.6\\.134\\.80/cluster50263\\.secondleveldomain\\.com","MACHINE_EXPLODED"));
  subject.process(new TaskStartedEvent(TaskID.forName("task_200904211745_0003_m_000004"),1234567890L,TaskType.valueOf("MAP"),"/194\\.6\\.134\\.80/cluster50263\\.secondleveldomain\\.com"));
  final LoggedNetworkTopology topology=subject.build();
  List<LoggedNetworkTopology> racks=topology.getChildren();
  assertEquals("Wrong number of racks",2,racks.size());
  boolean sawSingleton=false;
  boolean sawDoubleton=false;
  for (  LoggedNetworkTopology rack : racks) {
    List<LoggedNetworkTopology> nodes=rack.getChildren();
    if (rack.getName().endsWith(".64")) {
      assertEquals("The singleton rack has the wrong number of elements",1,nodes.size());
      sawSingleton=true;
    }
 else     if (rack.getName().endsWith(".80")) {
      assertEquals("The doubleton rack has the wrong number of elements",2,nodes.size());
      sawDoubleton=true;
    }
 else {
      assertTrue("Unrecognized rack name",false);
    }
  }
  assertTrue("Did not see singleton rack",sawSingleton);
  assertTrue("Did not see doubleton rack",sawDoubleton);
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests if {@link TraceBuilder} can correctly identify and parse jobhistory
 * filenames. The testcase checks if {@link TraceBuilder}- correctly identifies a jobhistory filename without suffix
 * - correctly parses a jobhistory filename without suffix to extract out 
 * the jobid
 * - correctly identifies a jobhistory filename with suffix
 * - correctly parses a jobhistory filename with suffix to extract out the 
 * jobid
 * - correctly identifies a job-configuration filename stored along with the 
 * jobhistory files
 */
@Test public void testJobHistoryFilenameParsing() throws IOException {
  final Configuration conf=new Configuration();
  final FileSystem lfs=FileSystem.getLocal(conf);
  String user="test";
  org.apache.hadoop.mapred.JobID jid=new org.apache.hadoop.mapred.JobID("12345",1);
  final Path rootInputDir=new Path(System.getProperty("test.tools.input.dir","")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  Path jhFilename=JobHistory.getJobHistoryFile(rootInputDir,jid,user);
  JobID extractedJID=JobID.forName(TraceBuilder.extractJobID(jhFilename.getName()));
  assertEquals("TraceBuilder failed to parse the current JH filename",jid,extractedJID);
  jhFilename=jhFilename.suffix(JobHistory.getOldFileSuffix("123"));
  extractedJID=JobID.forName(TraceBuilder.extractJobID(jhFilename.getName()));
  assertEquals("TraceBuilder failed to parse the current JH filename" + "(old-suffix)",jid,extractedJID);
  Path jhConfFilename=JobHistory.getConfFile(rootInputDir,jid);
  assertTrue("TraceBuilder failed to parse the current JH conf filename",TraceBuilder.isJobConfXml(jhConfFilename.getName(),null));
  jhConfFilename=jhConfFilename.suffix(JobHistory.getOldFileSuffix("123"));
  assertTrue("TraceBuilder failed to parse the current JH conf filename" + " (old suffix)",TraceBuilder.isJobConfXml(jhConfFilename.getName(),null));
}

</code></pre>

<br>
<pre class="type-10 type-4 type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
"></span><br>
/** 
 * Test if {@link CurrentJHParser} can read events from current JH files.
 */
@Test public void testCurrentJHParser() throws Exception {
  final Configuration conf=new Configuration();
  final FileSystem lfs=FileSystem.getLocal(conf);
  final Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  final Path tempDir=new Path(rootTempDir,"TestCurrentJHParser");
  lfs.delete(tempDir,true);
  conf.setInt(TTConfig.TT_MAP_SLOTS,1);
  conf.setInt(TTConfig.TT_REDUCE_SLOTS,1);
  MiniMRCluster mrCluster=new MiniMRCluster(1,"file:///",1,null,null,new JobConf(conf));
  Path inDir=new Path(tempDir,"input");
  Path outDir=new Path(tempDir,"output");
  JobHistoryParser parser=null;
  RewindableInputStream ris=null;
  ArrayList<String> seenEvents=new ArrayList<String>(15);
  try {
    JobConf jConf=mrCluster.createJobConf();
    Job job=MapReduceTestUtil.createJob(jConf,inDir,outDir,1,1);
    job.setJobSetupCleanupNeeded(false);
    job.setOutputFormatClass(MyOutputFormat.class);
    job.waitForCompletion(false);
    assertTrue("Job failed",job.isSuccessful());
    JobID id=job.getJobID();
    JobClient jc=new JobClient(jConf);
    String user=jc.getAllJobs()[0].getUsername();
    Path jhPath=new Path(mrCluster.getJobTrackerRunner().getJobTracker().getJobHistoryDir());
    Path inputPath=JobHistory.getJobHistoryFile(jhPath,id,user);
    for (int i=0; i < 100; ++i) {
      if (lfs.exists(inputPath)) {
        break;
      }
      TimeUnit.MILLISECONDS.wait(100);
    }
    assertTrue("Missing job history file",lfs.exists(inputPath));
    ris=getRewindableInputStream(inputPath,conf);
    parser=JobHistoryParserFactory.getParser(ris);
    JobBuilder builder=new JobBuilder(id.toString());
    getHistoryEvents(parser,seenEvents,builder);
    System.out.println("testCurrentJHParser validating using gold std ");
    String[] goldLinesExpected=new String[]{JSE,JPCE,JIE,JSCE,TSE,ASE,MFE,TFE,TSE,ASE,RFE,TFE,JFE};
    validateSeenHistoryEvents(seenEvents,goldLinesExpected);
    Counters counters=job.getTaskReports(TaskType.MAP)[0].getTaskCounters();
    LoggedJob loggedJob=builder.build();
    LoggedTaskAttempt attempt=loggedJob.getMapTasks().get(0).getAttempts().get(0);
    ResourceUsageMetrics metrics=attempt.getResourceUsageMetrics();
    testResourceUsageMetricViaDeepCompare(metrics,counters.findCounter(TaskCounter.CPU_MILLISECONDS).getValue(),counters.findCounter(TaskCounter.VIRTUAL_MEMORY_BYTES).getValue(),counters.findCounter(TaskCounter.PHYSICAL_MEMORY_BYTES).getValue(),counters.findCounter(TaskCounter.COMMITTED_HEAP_BYTES).getValue(),true);
  }
  finally {
    mrCluster.shutdown();
    if (ris != null) {
      ris.close();
    }
    if (parser != null) {
      parser.close();
    }
    lfs.delete(tempDir,true);
  }
}

</code></pre>

<br>
<pre class="type-4 type-7 type-5 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test if the {@link JobConfigurationParser} can correctly extract out 
 * key-value pairs from the job configuration.
 */
@Test public void testJobConfigurationParsing() throws Exception {
  final FileSystem lfs=FileSystem.getLocal(new Configuration());
  final Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  final Path tempDir=new Path(rootTempDir,"TestJobConfigurationParser");
  lfs.delete(tempDir,true);
  JobConf jConf=new JobConf(false);
  String key="test.data";
  String value="hello world";
  jConf.set(key,value);
  Path jobConfPath=new Path(tempDir.toString(),"job.xml");
  lfs.delete(jobConfPath,false);
  DataOutputStream jobConfStream=lfs.create(jobConfPath);
  jConf.writeXml(jobConfStream);
  jobConfStream.close();
  Properties properties=JobConfigurationParser.parse(lfs.open(jobConfPath));
  assertEquals("Total number of extracted properties (" + properties.size() + ") doesn't match the expected size of 1 ["+ "JobConfigurationParser]",1,properties.size());
  assertTrue("Key " + key + " is missing in the configuration extracted "+ "[JobConfigurationParser]",properties.keySet().contains(key));
  assertEquals("JobConfigurationParser couldn't recover the parameters" + " correctly",value,properties.get(key));
  LoggedJob job=new LoggedJob();
  job.setJobProperties(properties);
  ZombieJob zjob=new ZombieJob(job,null);
  Configuration zconf=zjob.getJobConf();
  assertEquals("ZombieJob couldn't recover the parameters correctly",value,zconf.get(key));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.typedbytes.TestIO </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCustomTypesIO() throws IOException {
  byte[] rawBytes=new byte[]{100,0,0,0,3,1,2,3};
  FileOutputStream ostream=new FileOutputStream(tmpfile);
  DataOutputStream dostream=new DataOutputStream(ostream);
  TypedBytesOutput out=new TypedBytesOutput(dostream);
  out.writeRaw(rawBytes);
  dostream.close();
  ostream.close();
  FileInputStream istream=new FileInputStream(tmpfile);
  DataInputStream distream=new DataInputStream(istream);
  TypedBytesInput in=new TypedBytesInput(distream);
  assertTrue(Arrays.equals(rawBytes,in.readRaw()));
  distream.close();
  istream.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.util.TestReflectionUtils </h4><pre class="type-7 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * This is to test backward compatibility of ReflectionUtils for 
 * JobConfigurable objects. 
 * This should be made deprecated along with the mapred package HADOOP-1230. 
 * Should be removed when mapred package is removed.
 */
@Test public void testSetConf(){
  JobConfigurableOb ob=new JobConfigurableOb();
  ReflectionUtils.setConf(ob,new Configuration());
  assertFalse(ob.configured);
  ReflectionUtils.setConf(ob,new JobConf());
  assertTrue(ob.configured);
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

<h3 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUpgrade (2 methods) </h3><br><pre style="padding:0"><code class="html"><div id="tags"><button id="1"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('1')" data-toggle="tooltip" title="Executes methods or other tests from the same test unit"><kbd id="tag-1"class="label-info"style="display: inline-block;font-size:7pt" >ExecutionTester&nbsp;(1)</kbd></button>&nbsp;<button id="15"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('15')" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution"><kbd id="tag-15"class="label-info"style="display: inline-block;font-size:7pt" >ExceptionVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="2"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('2')" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes"><kbd id="tag-2"class="label-info"style="display: inline-block;font-size:7pt" >HybridVerifier&nbsp;(1)</kbd></button>&nbsp;<button id="3"style="border-width:0;padding:0;background:#282B2E"  onclick="filter('3')" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure"><kbd id="tag-3"class="label-info"style="display: inline-block;font-size:7pt" >UtilityVerifier&nbsp;(1)</kbd></button>&nbsp;</div></code></pre><center><button onclick="showBlocks()" style="margin:6px">Update filter <span class="glyphicon glyphicon-refresh" aria-hidden="true"></span> </button></center><br>
<pre class="type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * This test attempts to upgrade the NameNode and DataNode under
 * a number of valid and invalid conditions.
 */
@Test public void testUpgrade() throws Exception {
  File[] baseDirs;
  UpgradeUtilities.initialize();
  StorageInfo storageInfo=null;
  for (int numDirs=1; numDirs <= 2; numDirs++) {
    conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    String[] nameNodeDirs=conf.getStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY);
    String[] dataNodeDirs=conf.getStrings(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY);
    log("Normal NameNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    checkNameNode(nameNodeDirs);
    if (numDirs > 1)     TestParallelImageWrite.checkImages(cluster.getNamesystem(),numDirs);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("Normal DataNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
    checkDataNode(dataNodeDirs,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode upgrade with existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("DataNode upgrade with existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"previous");
    cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
    checkDataNode(dataNodeDirs,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode upgrade with future stored layout version in current",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    storageInfo=new StorageInfo(Integer.MIN_VALUE,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),UpgradeUtilities.getCurrentFsscTime(cluster));
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.REGULAR,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode upgrade with newer fsscTime in current",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    storageInfo=new StorageInfo(UpgradeUtilities.getCurrentLayoutVersion(),UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),Long.MAX_VALUE);
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.REGULAR,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode upgrade with no edits file",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    for (    File f : baseDirs) {
      FileUtil.fullyDelete(new File(f,"edits"));
    }
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with no image file",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    for (    File f : baseDirs) {
      FileUtil.fullyDelete(new File(f,"fsimage"));
    }
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with corrupt version file",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    for (    File f : baseDirs) {
      UpgradeUtilities.corruptFile(new File(f,"VERSION"));
    }
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with old layout version in current",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    storageInfo=new StorageInfo(Storage.LAST_UPGRADABLE_LAYOUT_VERSION + 1,UpgradeUtilities.getCurrentNamespaceID(null),UpgradeUtilities.getCurrentClusterID(null),UpgradeUtilities.getCurrentFsscTime(null));
    UpgradeUtilities.createNameNodeVersionFile(conf,baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with future layout version in current",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    storageInfo=new StorageInfo(Integer.MIN_VALUE,UpgradeUtilities.getCurrentNamespaceID(null),UpgradeUtilities.getCurrentClusterID(null),UpgradeUtilities.getCurrentFsscTime(null));
    UpgradeUtilities.createNameNodeVersionFile(conf,baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
  }
  int numDirs=4;
{
    conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    String[] nameNodeDirs=conf.getStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY);
    log("Normal NameNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    checkNameNode(nameNodeDirs);
    TestParallelImageWrite.checkImages(cluster.getNamesystem(),numDirs);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
  }
}

</code></pre>

<pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test(expected=IOException.class) public void testUpgradeFromPreUpgradeLVFails() throws IOException {
  Storage.checkVersionUpgradable(Storage.LAST_PRE_UPGRADE_LAYOUT_VERSION + 1);
  fail("Expected IOException is not thrown");
}

</code></pre>

<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

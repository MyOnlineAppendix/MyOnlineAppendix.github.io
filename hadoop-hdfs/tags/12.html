<h3><span class=" glyphicon glyphicon-tag"/>&nbspBranchVerifier</h3><kbd>Verifies assertions inside branch conditions</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.fs.TestResolveHdfsSymlink </h4><pre class="type-12 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests resolution of an hdfs symlink to the local file system.
 * @throws IOException
 * @throws InterruptedException
 */
@Test public void testFcResolveAfs() throws IOException, InterruptedException {
  Configuration conf=new Configuration();
  FileContext fcLocal=FileContext.getLocalFSFileContext();
  FileContext fcHdfs=FileContext.getFileContext(cluster.getFileSystem().getUri());
  Path alphaLocalPath=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp/alpha");
  DFSTestUtil.createFile(FileSystem.getLocal(conf),alphaLocalPath,16,(short)1,2);
  Path linkTarget=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp");
  Path hdfsLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString(),"/tmp/link");
  fcHdfs.createSymlink(linkTarget,hdfsLink,true);
  Path alphaHdfsPathViaLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString() + "/tmp/link/alpha");
  Set<AbstractFileSystem> afsList=fcHdfs.resolveAbstractFileSystems(alphaHdfsPathViaLink);
  Assert.assertEquals(2,afsList.size());
  for (  AbstractFileSystem afs : afsList) {
    if ((!afs.equals(fcHdfs.getDefaultFileSystem())) && (!afs.equals(fcLocal.getDefaultFileSystem()))) {
      Assert.fail("Failed to resolve AFS correctly");
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRenewer </h4><pre class="type-12 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testRenewal() throws Exception {
  final AtomicInteger leaseRenewalCount=new AtomicInteger();
  Mockito.doAnswer(new Answer<Void>(){
    @Override public Void answer(    InvocationOnMock invocation) throws Throwable {
      leaseRenewalCount.incrementAndGet();
      return null;
    }
  }
).when(MOCK_DFSCLIENT).renewLease();
  DFSOutputStream mockStream=Mockito.mock(DFSOutputStream.class);
  String filePath="/foo";
  renewer.put(filePath,mockStream,MOCK_DFSCLIENT);
  long failTime=System.currentTimeMillis() + 5000;
  while (System.currentTimeMillis() < failTime && leaseRenewalCount.get() == 0) {
    Thread.sleep(50);
  }
  if (leaseRenewalCount.get() == 0) {
    Assert.fail("Did not renew lease at all!");
  }
  renewer.closeFile(filePath,MOCK_DFSCLIENT);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestParallelRead </h4><pre class="type-12 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * Do parallel read several times with different number of files and threads.
 * Note that while this is the only "test" in a junit sense, we're actually
 * dispatching a lot more. Failures in the other methods (and other threads)
 * need to be manually collected, which is inconvenient.
 */
@Test public void testParallelRead() throws IOException {
  if (!runParallelRead(1,4)) {
    fail("Check log for errors");
  }
  if (!runParallelRead(1,16)) {
    fail("Check log for errors");
  }
  if (!runParallelRead(2,4)) {
    fail("Check log for errors");
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.token.block.TestBlockToken </h4><pre class="type-16 type-10 type-12 type-3 type-9 type-18 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Sets implicit assumptions 
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that fast repeated invocations of createClientDatanodeProtocolProxy
 * will not end up using up thousands of sockets. This is a regression test for
 * HDFS-1965.
 */
@Test public void testBlockTokenRpcLeak() throws Exception {
  Assume.assumeTrue(FD_DIR.exists());
  BlockTokenSecretManager sm=new BlockTokenSecretManager(true,blockKeyUpdateInterval,blockTokenLifetime);
  Token<BlockTokenIdentifier> token=sm.generateToken(block3,EnumSet.allOf(BlockTokenSecretManager.AccessMode.class));
  final Server server=createMockDatanode(sm,token);
  server.start();
  final InetSocketAddress addr=NetUtils.getConnectAddress(server);
  DatanodeID fakeDnId=new DatanodeID("localhost:" + addr.getPort(),"fake-storage",0,addr.getPort());
  ExtendedBlock b=new ExtendedBlock("fake-pool",new Block(12345L));
  LocatedBlock fakeBlock=new LocatedBlock(b,new DatanodeInfo[0]);
  fakeBlock.setBlockToken(token);
  ClientDatanodeProtocol proxyToNoWhere=RPC.getProxy(ClientDatanodeProtocol.class,ClientDatanodeProtocol.versionID,new InetSocketAddress("1.1.1.1",1),UserGroupInformation.createRemoteUser("junk"),conf,NetUtils.getDefaultSocketFactory(conf));
  ClientDatanodeProtocol proxy=null;
  int fdsAtStart=countOpenFileDescriptors();
  try {
    long endTime=System.currentTimeMillis() + 3000;
    while (System.currentTimeMillis() < endTime) {
      proxy=DFSTestUtil.createClientDatanodeProtocolProxy(fakeDnId,conf,1000,fakeBlock);
      assertEquals(block3.getBlockId(),proxy.getReplicaVisibleLength(block3));
      if (proxy != null) {
        RPC.stopProxy(proxy);
      }
      LOG.info("Num open fds:" + countOpenFileDescriptors());
    }
    int fdsAtEnd=countOpenFileDescriptors();
    if (fdsAtEnd - fdsAtStart > 50) {
      fail("Leaked " + (fdsAtEnd - fdsAtStart) + " fds!");
    }
  }
  finally {
    server.stop();
  }
  RPC.stopProxy(proxyToNoWhere);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery </h4><pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of datanode
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (dn != null) {
    try {
      dn.shutdown();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(DATA_DIR);
      if (dir.exists())       Assert.assertTrue("Cannot delete data-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlocksWithNotEnoughRacks </h4><pre class="type-16 type-10 type-12 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testCorruptBlockRereplicatedAcrossRacks() throws Exception {
  Configuration conf=getConf();
  short REPLICATION_FACTOR=2;
  int fileLen=512;
  final Path filePath=new Path("/testFile");
  String racks[]={"/rack1","/rack1","/rack2","/rack2"};
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(racks.length).racks(racks).build();
  final FSNamesystem ns=cluster.getNameNode().getNamesystem();
  try {
    final FileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,filePath,fileLen,REPLICATION_FACTOR,1L);
    final String fileContent=DFSTestUtil.readFile(fs,filePath);
    ExtendedBlock b=DFSTestUtil.getFirstBlock(fs,filePath);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    int dnToCorrupt=DFSTestUtil.firstDnWithBlock(cluster,b);
    assertTrue(MiniDFSCluster.corruptReplica(dnToCorrupt,b));
    cluster.restartDataNode(dnToCorrupt);
    DFSTestUtil.waitCorruptReplicas(fs,ns,filePath,b,1);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    for (int i=0; i < racks.length; i++) {
      String blockContent=cluster.readBlockOnDataNode(i,b);
      if (blockContent != null && i != dnToCorrupt) {
        assertEquals("Corrupt replica",fileContent,blockContent);
      }
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus </h4><pre class="type-16 type-12 type-9 type-6 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies assertions inside branch conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
"></span><br>
/** 
 * Tests Decommissioning Status in DFS.
 */
@Test public void testDecommissionStatus() throws IOException, InterruptedException {
  InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
  DFSClient client=new DFSClient(addr,conf);
  DatanodeInfo[] info=client.datanodeReport(DatanodeReportType.LIVE);
  assertEquals("Number of Datanodes ",2,info.length);
  FileSystem fileSys=cluster.getFileSystem();
  short replicas=2;
  Path file1=new Path("decommission.dat");
  writeFile(fileSys,file1,replicas);
  Path file2=new Path("decommission1.dat");
  FSDataOutputStream st1=writeIncompleteFile(fileSys,file2,replicas);
  Thread.sleep(5000);
  FSNamesystem fsn=cluster.getNamesystem();
  for (int iteration=0; iteration < numDatanodes; iteration++) {
    String downnode=decommissionNode(fsn,conf,client,localFileSys,iteration);
    decommissionedNodes.add(downnode);
    Thread.sleep(5000);
    ArrayList<DatanodeDescriptor> decommissioningNodes=fsn.getDecommissioningNodes();
    if (iteration == 0) {
      assertEquals(decommissioningNodes.size(),1);
      DatanodeDescriptor decommNode=decommissioningNodes.get(0);
      checkDecommissionStatus(decommNode,4,0,2);
    }
 else {
      assertEquals(decommissioningNodes.size(),2);
      DatanodeDescriptor decommNode1=decommissioningNodes.get(0);
      DatanodeDescriptor decommNode2=decommissioningNodes.get(1);
      checkDecommissionStatus(decommNode1,4,4,2);
      checkDecommissionStatus(decommNode2,4,4,2);
    }
  }
  writeConfigFile(localFileSys,excludeFile,null);
  fsn.refreshNodes(conf);
  st1.close();
  cleanupFile(fileSys,file1);
  cleanupFile(fileSys,file2);
  cleanupFile(localFileSys,dir);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks </h4><pre class="type-16 type-10 type-12 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * check if nn.getCorruptFiles() returns a file that has corrupted blocks 
 */
@Test public void testListCorruptFilesCorruptedBlock() throws Exception {
  MiniDFSCluster cluster=null;
  Random random=new Random();
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil("testCorruptFilesCorruptedBlock",2,1,512);
    util.createFiles(fs,"/srcdat10");
    final NameNode namenode=cluster.getNameNode();
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting None.",badFiles.size() == 0);
    String bpid=cluster.getNamesystem().getBlockPoolId();
    File storageDir=MiniDFSCluster.getStorageDir(0,1);
    File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
    assertTrue("data directory does not exist",data_dir.exists());
    File[] blocks=data_dir.listFiles();
    assertTrue("Blocks do not exist in data-dir",(blocks != null) && (blocks.length > 0));
    for (int idx=0; idx < blocks.length; idx++) {
      if (blocks[idx].getName().startsWith("blk_") && blocks[idx].getName().endsWith(".meta")) {
        RandomAccessFile file=new RandomAccessFile(blocks[idx],"rw");
        FileChannel channel=file.getChannel();
        long position=channel.size() - 2;
        int length=2;
        byte[] buffer=new byte[length];
        random.nextBytes(buffer);
        channel.write(ByteBuffer.wrap(buffer),position);
        file.close();
        LOG.info("Deliberately corrupting file " + blocks[idx].getName() + " at offset "+ position+ " length "+ length);
        try {
          util.checkFiles(fs,"/srcdat10");
        }
 catch (        BlockMissingException e) {
          System.out.println("Received BlockMissingException as expected.");
        }
catch (        IOException e) {
          assertTrue("Corrupted replicas not handled properly. Expecting BlockMissingException " + " but received IOException " + e,false);
        }
        break;
      }
    }
    badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    util.cleanup(fs,"/srcdat10");
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-12 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Check that listCorruptFileBlocks works while the namenode is still in safemode.
 */
@Test public void testListCorruptFileBlocksInSafeMode() throws Exception {
  MiniDFSCluster cluster=null;
  Random random=new Random();
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY,1.5f);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_REPL_QUEUE_THRESHOLD_PCT_KEY,0f);
    cluster=new MiniDFSCluster.Builder(conf).waitSafeMode(false).build();
    cluster.getNameNode().setSafeMode(FSConstants.SafeModeAction.SAFEMODE_LEAVE);
    FileSystem fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil("testListCorruptFileBlocksInSafeMode",2,1,512);
    util.createFiles(fs,"/srcdat10");
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting None.",badFiles.size() == 0);
    File storageDir=MiniDFSCluster.getStorageDir(0,0);
    File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,cluster.getNamesystem().getBlockPoolId());
    assertTrue("data directory does not exist",data_dir.exists());
    File[] blocks=data_dir.listFiles();
    assertTrue("Blocks do not exist in data-dir",(blocks != null) && (blocks.length > 0));
    for (int idx=0; idx < blocks.length; idx++) {
      if (blocks[idx].getName().startsWith("blk_") && blocks[idx].getName().endsWith(".meta")) {
        RandomAccessFile file=new RandomAccessFile(blocks[idx],"rw");
        FileChannel channel=file.getChannel();
        long position=channel.size() - 2;
        int length=2;
        byte[] buffer=new byte[length];
        random.nextBytes(buffer);
        channel.write(ByteBuffer.wrap(buffer),position);
        file.close();
        LOG.info("Deliberately corrupting file " + blocks[idx].getName() + " at offset "+ position+ " length "+ length);
        try {
          util.checkFiles(fs,"/srcdat10");
        }
 catch (        BlockMissingException e) {
          System.out.println("Received BlockMissingException as expected.");
        }
catch (        IOException e) {
          assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
        }
        break;
      }
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    cluster.restartNameNode(0);
    fs=cluster.getFileSystem();
    while (!cluster.getNameNode().namesystem.isPopulatingReplQueues()) {
      try {
        LOG.info("waiting for replication queues");
        Thread.sleep(1000);
      }
 catch (      InterruptedException ignore) {
      }
    }
    try {
      util.checkFiles(fs,"/srcdat10");
    }
 catch (    BlockMissingException e) {
      System.out.println("Received BlockMissingException as expected.");
    }
catch (    IOException e) {
      assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    assertTrue("Namenode is not in safe mode",cluster.getNameNode().isInSafeMode());
    cluster.getNameNode().setSafeMode(FSConstants.SafeModeAction.SAFEMODE_LEAVE);
    util.cleanup(fs,"/srcdat10");
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNNLeaseRecovery </h4><pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of FSNamesystem
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (fsn != null) {
    try {
      fsn.close();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(NAME_DIR);
      if (dir != null)       assertTrue("Cannot delete name-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

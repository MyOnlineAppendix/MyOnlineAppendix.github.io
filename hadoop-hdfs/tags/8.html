<h3><span class=" glyphicon glyphicon-tag"/>&nbspBooleanVerifier</h3><kbd>Verifies boolean conditions</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.cli.TestHDFSCLI </h4><pre class="type-10 type-7 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before @Override public void setUp() throws Exception {
  super.setUp();
  conf.setClass(PolicyProvider.POLICY_PROVIDER_CONFIG,HDFSPolicyProvider.class,PolicyProvider.class);
  conf.setInt(DFSConfigKeys.DFS_REPLICATION_KEY,1);
  String[] racks={"/rack1","/rack1","/rack2","/rack2","/rack2","/rack3","/rack4","/rack4"};
  String[] hosts={"host1","host2","host3","host4","host5","host6","host7","host8"};
  dfsCluster=new MiniDFSCluster.Builder(conf).numDataNodes(8).racks(racks).hosts(hosts).build();
  dfsCluster.waitClusterUp();
  namenode=conf.get(DFSConfigKeys.FS_DEFAULT_NAME_KEY,"file:///");
  username=System.getProperty("user.name");
  fs=dfsCluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFiListPath </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Remove the target directory after the getListing RPC 
 */
@Test public void testTargetDeletionForListLocatedStatus() throws Exception {
  LOG.info("Test Target Delete For listLocatedStatus");
  RemoteIterator<LocatedFileStatus> itor=fs.listLocatedStatus(TEST_PATH);
  itor.next();
  assertFalse(itor.hasNext());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFiRename </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Rename test where both src and dst are files 
 */
@Test public void testDeletionOfDstFile() throws Exception {
  Path src=getTestPath("testDeletionOfDstFile/dir/src");
  Path dst=getTestPath("testDeletionOfDstFile/newdir/dst");
  createFile(src);
  createFile(dst);
  final FSNamesystem namesystem=cluster.getNamesystem();
  final long blocks=namesystem.getBlocksTotal();
  final long fileCount=namesystem.getFilesTotal();
  rename(src,dst,false,false,true,Rename.OVERWRITE);
  Assert.assertEquals(blocks - 1,namesystem.getBlocksTotal());
  Assert.assertEquals(fileCount - 1,namesystem.getFilesTotal());
  restartCluster(false);
  int count=0;
  boolean exception=true;
  src=getTestPath("testDeletionOfDstFile/dir/src");
  dst=getTestPath("testDeletionOfDstFile/newdir/dst");
  while (exception && count < 5) {
    try {
      exists(fc,src);
      exception=false;
    }
 catch (    Exception e) {
      LOG.warn("Exception " + " count " + count + " "+ e.getMessage());
      Thread.sleep(1000);
      count++;
    }
  }
  Assert.assertFalse(exists(fc,src));
  Assert.assertTrue(exists(fc,dst));
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Rename test where both src and dst are directories 
 */
@Test public void testDeletionOfDstDirectory() throws Exception {
  Path src=getTestPath("testDeletionOfDstDirectory/dir/src");
  Path dst=getTestPath("testDeletionOfDstDirectory/newdir/dst");
  fc.mkdir(src,FileContext.DEFAULT_PERM,true);
  fc.mkdir(dst,FileContext.DEFAULT_PERM,true);
  FSNamesystem namesystem=cluster.getNamesystem();
  long fileCount=namesystem.getFilesTotal();
  rename(src,dst,false,false,true,Rename.OVERWRITE);
  Assert.assertEquals(fileCount - 1,namesystem.getFilesTotal());
  restartCluster(false);
  src=getTestPath("testDeletionOfDstDirectory/dir/src");
  dst=getTestPath("testDeletionOfDstDirectory/newdir/dst");
  int count=0;
  boolean exception=true;
  while (exception && count < 5) {
    try {
      exists(fc,src);
      exception=false;
    }
 catch (    Exception e) {
      LOG.warn("Exception " + " count " + count + " "+ e.getMessage());
      Thread.sleep(1000);
      count++;
    }
  }
  Assert.assertFalse(exists(fc,src));
  Assert.assertTrue(exists(fc,dst));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestHDFSFileContextMainOperations </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Perform operations such as setting quota, deletion of files, rename and
 * ensure system can apply edits log during startup.
 */
@Test public void testEditsLogRename() throws Exception {
  DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
  Path src1=getTestRootPath(fc,"testEditsLogRename/srcdir/src1");
  Path dst1=getTestRootPath(fc,"testEditsLogRename/dstdir/dst1");
  createFile(src1);
  fs.mkdirs(dst1.getParent());
  createFile(dst1);
  fs.setQuota(dst1.getParent(),2,FSConstants.QUOTA_DONT_SET);
  fs.delete(dst1,true);
  rename(src1,dst1,true,true,false,Rename.OVERWRITE);
  restartCluster();
  fs=(DistributedFileSystem)cluster.getFileSystem();
  src1=getTestRootPath(fc,"testEditsLogRename/srcdir/src1");
  dst1=getTestRootPath(fc,"testEditsLogRename/dstdir/dst1");
  Assert.assertFalse(fs.exists(src1));
  Assert.assertTrue(fs.exists(dst1));
}

</code></pre>

<br>
<pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Perform operations such as setting quota, deletion of files, rename and
 * ensure system can apply edits log during startup.
 */
@Test public void testEditsLogOldRename() throws Exception {
  DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
  Path src1=getTestRootPath(fc,"testEditsLogOldRename/srcdir/src1");
  Path dst1=getTestRootPath(fc,"testEditsLogOldRename/dstdir/dst1");
  createFile(src1);
  fs.mkdirs(dst1.getParent());
  createFile(dst1);
  fs.setQuota(dst1.getParent(),2,FSConstants.QUOTA_DONT_SET);
  fs.delete(dst1,true);
  oldRename(src1,dst1,true,false);
  restartCluster();
  fs=(DistributedFileSystem)cluster.getFileSystem();
  src1=getTestRootPath(fc,"testEditsLogOldRename/srcdir/src1");
  dst1=getTestRootPath(fc,"testEditsLogOldRename/dstdir/dst1");
  Assert.assertFalse(fs.exists(src1));
  Assert.assertTrue(fs.exists(dst1));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGetNewStamp() throws IOException {
  int numDataNodes=1;
  Configuration conf=new HdfsConfiguration();
  conf.setBoolean("dfs.support.append",true);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
  try {
    cluster.waitActive();
    FileSystem fileSys=cluster.getFileSystem();
    NameNode namenode=cluster.getNameNode();
    Path file=new Path("dataprotocol.dat");
    DFSTestUtil.createFile(fileSys,file,1L,(short)numDataNodes,0L);
    ExtendedBlock firstBlock=DFSTestUtil.getFirstBlock(fileSys,file);
    try {
      namenode.updateBlockForPipeline(firstBlock,"");
      Assert.fail("Can not get a new GS from a finalized block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("is not under Construction"));
    }
    try {
      long newBlockId=firstBlock.getBlockId() + 1;
      ExtendedBlock newBlock=new ExtendedBlock(firstBlock.getBlockPoolId(),newBlockId,0,firstBlock.getGenerationStamp());
      namenode.updateBlockForPipeline(newBlock,"");
      Assert.fail("Cannot get a new GS from a non-existent block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("does not exist"));
    }
    DFSOutputStream out=null;
    try {
      out=(DFSOutputStream)(fileSys.append(file).getWrappedStream());
      out.write(1);
      out.hflush();
      FSDataInputStream in=null;
      try {
        in=fileSys.open(file);
        firstBlock=DFSTestUtil.getAllBlocks(in).get(0).getBlock();
      }
  finally {
        IOUtils.closeStream(in);
      }
      DFSClient dfs=((DistributedFileSystem)fileSys).dfs;
      try {
        namenode.updateBlockForPipeline(firstBlock,"test" + dfs.clientName);
        Assert.fail("Cannot get a new GS for a non lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      try {
        namenode.updateBlockForPipeline(firstBlock,null);
        Assert.fail("Cannot get a new GS for a null lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      namenode.updateBlockForPipeline(firstBlock,dfs.clientName);
    }
  finally {
      IOUtils.closeStream(out);
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestConnCache </h4><pre class="type-10 type-8 type-9 type-13 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether two objects/variables are the same">IdentityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether two objects/variables are the same
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the SocketCache itself.
 */
@Test public void testSocketCache() throws IOException {
  final int CACHE_SIZE=4;
  SocketCache cache=new SocketCache(CACHE_SIZE);
  InetSocketAddress nnAddr=new InetSocketAddress("localhost",cluster.getNameNodePort());
  DFSClient client=new DFSClient(nnAddr,conf);
  LocatedBlock block=client.getNamenode().getBlockLocations(testFile.toString(),0,FILE_SIZE).getLocatedBlocks().get(0);
  DataNode dn=util.getDataNode(block);
  InetSocketAddress dnAddr=dn.getSelfAddr();
  Socket[] dnSockets=new Socket[CACHE_SIZE];
  for (int i=0; i < dnSockets.length; ++i) {
    dnSockets[i]=client.socketFactory.createSocket(dnAddr.getAddress(),dnAddr.getPort());
  }
  Socket nnSock=new Socket(nnAddr.getAddress(),nnAddr.getPort());
  cache.put(nnSock);
  assertSame("Read the write",nnSock,cache.get(nnAddr));
  cache.put(nnSock);
  for (  Socket dnSock : dnSockets) {
    cache.put(dnSock);
  }
  assertEquals("NN socket evicted",null,cache.get(nnAddr));
  assertTrue("Evicted socket closed",nnSock.isClosed());
  for (  Socket dnSock : dnSockets) {
    assertEquals("Retrieve cached sockets",dnSock,cache.get(dnAddr));
    dnSock.close();
  }
  assertEquals("Cache is empty",0,cache.size());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUtil </h4><pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Test for{@link DFSUtil#isDefaultNamenodeAddress(Configuration,InetSocketAddress,String)}
 */
@Test public void testSingleNamenode(){
  HdfsConfiguration conf=new HdfsConfiguration();
  final String DEFAULT_ADDRESS="localhost:9000";
  final String NN2_ADDRESS="localhost:9001";
  conf.set(DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY,DEFAULT_ADDRESS);
  InetSocketAddress testAddress1=NetUtils.createSocketAddr(DEFAULT_ADDRESS);
  boolean isDefault=DFSUtil.isDefaultNamenodeAddress(conf,testAddress1,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertTrue(isDefault);
  InetSocketAddress testAddress2=NetUtils.createSocketAddr(NN2_ADDRESS);
  isDefault=DFSUtil.isDefaultNamenodeAddress(conf,testAddress2,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertFalse(isDefault);
}

</code></pre>

<br>
<pre class="type-10 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test conversion of LocatedBlock to BlockLocation
 */
@Test public void testLocatedBlocks2Locations(){
  DatanodeInfo d=new DatanodeInfo();
  DatanodeInfo[] ds=new DatanodeInfo[1];
  ds[0]=d;
  ExtendedBlock b1=new ExtendedBlock("bpid",1,1,1);
  LocatedBlock l1=new LocatedBlock(b1,ds,0,false);
  ExtendedBlock b2=new ExtendedBlock("bpid",2,1,1);
  LocatedBlock l2=new LocatedBlock(b2,ds,0,true);
  List<LocatedBlock> ls=Arrays.asList(l1,l2);
  LocatedBlocks lbs=new LocatedBlocks(10,false,ls,l2,true);
  BlockLocation[] bs=DFSUtil.locatedBlocks2Locations(lbs);
  assertTrue("expected 2 blocks but got " + bs.length,bs.length == 2);
  int corruptCount=0;
  for (  BlockLocation b : bs) {
    if (b.isCorrupt()) {
      corruptCount++;
    }
  }
  assertTrue("expected 1 corrupt files but got " + corruptCount,corruptCount == 1);
  bs=DFSUtil.locatedBlocks2Locations(new LocatedBlocks());
  assertEquals(0,bs.length);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDataTransferProtocol </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testPacketHeader() throws IOException {
  PacketHeader hdr=new PacketHeader(4,1024,100,false,4096);
  ByteArrayOutputStream baos=new ByteArrayOutputStream();
  hdr.write(new DataOutputStream(baos));
  PacketHeader readBack=new PacketHeader();
  ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray());
  readBack.readFields(new DataInputStream(bais));
  assertEquals(hdr,readBack);
  readBack=new PacketHeader();
  readBack.readFields(ByteBuffer.wrap(baos.toByteArray()));
  assertEquals(hdr,readBack);
  assertTrue(hdr.sanityCheck(99));
  assertFalse(hdr.sanityCheck(100));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDatanodeConfig </h4><pre class="type-10 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that a data-node does not start if configuration specifies
 * incorrect URI scheme in data directory.
 * Test that a data-node starts if data directory is specified as
 * URI = "file:///path" or as a non URI path.
 */
@Test public void testDataDirectories() throws IOException {
  File dataDir=new File(BASE_DIR,"data").getCanonicalFile();
  Configuration conf=cluster.getConfiguration(0);
  String dnDir=makeURI("shv",null,fileAsURI(dataDir).getPath());
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir);
  DataNode dn=null;
  try {
    dn=DataNode.createDataNode(new String[]{},conf);
  }
 catch (  IOException e) {
  }
  if (dn != null)   dn.shutdown();
  assertNull("Data-node startup should have failed.",dn);
  String dnDir1=fileAsURI(dataDir).toString() + "1";
  String dnDir2=makeURI("file","localhost",fileAsURI(dataDir).getPath() + "2");
  String dnDir3=dataDir.getAbsolutePath() + "3";
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir1 + "," + dnDir2+ ","+ dnDir3);
  cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
  assertTrue("Data-node should startup.",cluster.isDataNodeUp());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDistributedFileSystem </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testDFSSeekExceptions() throws IOException {
  Configuration conf=getTestConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  FileSystem fileSys=cluster.getFileSystem();
  try {
    String file="/test/fileclosethenseek/file-0";
    Path path=new Path(file);
    FSDataOutputStream output=fileSys.create(path);
    output.writeBytes("Some test data to write longer than 10 bytes");
    output.close();
    FSDataInputStream input=fileSys.open(path);
    input.seek(10);
    boolean threw=false;
    try {
      input.seek(100);
    }
 catch (    IOException e) {
      threw=true;
    }
    assertTrue("Failed to throw IOE when seeking past end",threw);
    input.close();
    threw=false;
    try {
      input.seek(1);
    }
 catch (    IOException e) {
      threw=true;
    }
    assertTrue("Failed to throw IOE when seeking after close",threw);
    fileSys.close();
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDFSClient() throws Exception {
  Configuration conf=getTestConfiguration();
  final long grace=1000L;
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
    final String filepathstring="/test/LeaseChecker/foo";
    final Path[] filepaths=new Path[4];
    for (int i=0; i < filepaths.length; i++) {
      filepaths[i]=new Path(filepathstring + i);
    }
    final long millis=System.currentTimeMillis();
{
      DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      dfs.dfs.leaserenewer.setGraceSleepPeriod(grace);
      assertFalse(dfs.dfs.leaserenewer.isRunning());
{
        final FSDataOutputStream out=dfs.create(filepaths[0]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out.close();
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        for (int i=0; i < 3; i++) {
          if (dfs.dfs.leaserenewer.isRunning()) {
            Thread.sleep(grace / 2);
          }
        }
        assertFalse(dfs.dfs.leaserenewer.isRunning());
      }
{
        final FSDataOutputStream out1=dfs.create(filepaths[1]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        final FSDataOutputStream out2=dfs.create(filepaths[2]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out1.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out1.close();
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out2.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out2.close();
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
      }
{
        final FSDataOutputStream out3=dfs.create(filepaths[3]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out3.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out3.close();
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        for (int i=0; i < 3; i++) {
          if (dfs.dfs.leaserenewer.isRunning()) {
            Thread.sleep(grace / 2);
          }
        }
        assertFalse(dfs.dfs.leaserenewer.isRunning());
      }
      dfs.close();
    }
{
      FileSystem fs=cluster.getFileSystem();
      Path dir=new Path("/wrwelkj");
      assertFalse("File should not exist for test.",fs.exists(dir));
      try {
        FSDataInputStream in=fs.open(dir);
        try {
          in.close();
          fs.close();
        }
  finally {
          assertTrue("Did not get a FileNotFoundException for non-existing" + " file.",false);
        }
      }
 catch (      FileNotFoundException fnf) {
      }
    }
{
      DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      FSDataInputStream in=dfs.open(filepaths[0]);
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      assertEquals(millis,in.readLong());
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      in.close();
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      dfs.close();
    }
{
      String uri="hdfs://127.0.0.1:" + cluster.getNameNodePort() + "/test/ipAddress/file";
      Path path=new Path(uri);
      FileSystem fs=FileSystem.get(path.toUri(),conf);
      FSDataOutputStream out=fs.create(path);
      byte[] buf=new byte[1024];
      out.write(buf);
      out.close();
      FSDataInputStream in=fs.open(path);
      in.readFully(buf);
      in.close();
      fs.close();
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFiPipelines </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * This quite tricky test prevents acknowledgement packets from a datanode
 * This should block any write attempts after ackQueue is full.
 * Test is blocking, so the MiniDFSCluster has to be killed harshly.
 * @throws IOException in case of an error
 */
@Test public void pipeline_06() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  final int MAX_PACKETS=80;
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + METHOD_NAME);
  }
  final PipelinesTestUtil.PipelinesTest pipst=(PipelinesTestUtil.PipelinesTest)PipelinesTestUtil.initTest();
  pipst.setSuspend(true);
  Path filePath=new Path("/" + METHOD_NAME + ".dat");
  FSDataOutputStream fsOut=fs.create(filePath);
  int cnt=0;
  try {
    QueueChecker cq=new QueueChecker(pipst,MAX_PACKETS);
    cq.start();
    int bytesToSend=700;
    while (cnt < 100 && pipst.getSuspend()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("_06(): " + cnt++ + " sending another "+ bytesToSend+ " bytes");
      }
      TestPipelines.writeData(fsOut,bytesToSend);
    }
  }
 catch (  Exception e) {
    LOG.warn("Getting unexpected exception: ",e);
  }
  if (LOG.isDebugEnabled()) {
    LOG.debug("Last queued packet number " + pipst.getLastQueued());
  }
  assertTrue("Shouldn't be able to send more than 81 packet",pipst.getLastQueued() <= 81);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend </h4><pre class="type-16 type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Test that copy on write for blocks works correctly
 * @throws IOException an exception might be thrown
 */
@Test public void testCopyOnWrite() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    conf.setBoolean(SimulatedFSDataset.CONFIG_PROPERTY_SIMULATED,true);
  }
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
  DFSClient client=new DFSClient(addr,conf);
  try {
    Path file1=new Path("/filestatus.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    writeFile(stm);
    stm.close();
    DataNode[] dn=cluster.listDataNodes();
    assertTrue("There should be only one datanode but found " + dn.length,dn.length == 1);
    LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
    List<LocatedBlock> blocks=locations.getLocatedBlocks();
    FSDataset dataset=(FSDataset)dn[0].data;
    for (int i=0; i < blocks.size(); i=i + 2) {
      ExtendedBlock b=blocks.get(i).getBlock();
      File f=dataset.getFile(b.getBlockPoolId(),b.getLocalBlock());
      File link=new File(f.toString() + ".link");
      System.out.println("Creating hardlink for File " + f + " to "+ link);
      HardLink.createHardLink(f,link);
    }
    for (int i=0; i < blocks.size(); i++) {
      ExtendedBlock b=blocks.get(i).getBlock();
      System.out.println("testCopyOnWrite detaching block " + b);
      assertTrue("Detaching block " + b + " should have returned true",dataset.unlinkBlock(b,1));
    }
    for (int i=0; i < blocks.size(); i++) {
      ExtendedBlock b=blocks.get(i).getBlock();
      System.out.println("testCopyOnWrite detaching block " + b);
      assertTrue("Detaching block " + b + " should have returned false",!dataset.unlinkBlock(b,1));
    }
  }
  finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend4 </h4><pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, recovers a file from another writer,
 * starts writing from that writer, and then has the old lease holder
 * call completeFile
 */
@Test(timeout=60000) public void testCompleteOtherLeaseHoldersFile() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testCompleteOtherLease");
    final OutputStream stm=client.create("/testCompleteOtherLease",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Opening file for append from new fs");
    FSDataOutputStream appenderStream=fs2.append(file1);
    LOG.info("Writing some data from new appender");
    AppendTestUtil.write(appenderStream,0,4096);
    LOG.info("Telling old close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("Lease mismatch"))     throw thrownByClose;
    appenderStream.close();
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, and then tries to recover
 * the lease from another thread.
 */
@Test(timeout=60000) public void testRecoverFinalizedBlock() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testRecoverFinalized");
    final OutputStream stm=client.create("/testRecoverFinalized",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Telling close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("No lease on /testRecoverFinalized"))     throw thrownByClose;
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileStatus </h4><pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test FileStatus objects obtained from a directory 
 */
@Test public void testGetFileStatusOnDir() throws Exception {
  Path dir=new Path("/test/mkdirs");
  assertTrue("mkdir failed",fs.mkdirs(dir));
  assertTrue("mkdir failed",fs.exists(dir));
  FileStatus status=fs.getFileStatus(dir);
  assertTrue(dir + " should be a directory",status.isDirectory());
  assertTrue(dir + " should be zero size ",status.getLen() == 0);
  assertEquals(dir.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
  FileStatus[] stats=fs.listStatus(dir);
  assertEquals(dir + " should be empty",0,stats.length);
  assertEquals(dir + " should be zero size ",0,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " should be zero size using hftp",0,hftpfs.getContentSummary(dir).getLength());
  RemoteIterator<FileStatus> itor=fc.listStatus(dir);
  assertFalse(dir + " should be empty",itor.hasNext());
  Path file2=new Path(dir,"filestatus2.dat");
  writeFile(fs,file2,1,blockSize / 4,blockSize);
  checkFile(fs,file2,1);
  status=fs.getFileStatus(file2);
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  file2=fs.makeQualified(file2);
  assertEquals(file2.toString(),status.getPath().toString());
  Path file3=new Path(dir,"filestatus3.dat");
  writeFile(fs,file3,1,blockSize / 4,blockSize);
  checkFile(fs,file3,1);
  file3=fs.makeQualified(file3);
  final int expected=blockSize / 2;
  assertEquals(dir + " size should be " + expected,expected,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " size should be " + expected+ " using hftp",expected,hftpfs.getContentSummary(dir).getLength());
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have two entries",2,stats.length);
  assertEquals(file2.toString(),stats[0].getPath().toString());
  assertEquals(file3.toString(),stats[1].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir3=fs.makeQualified(new Path(dir,"dir3"));
  fs.mkdirs(dir3);
  dir3=fs.makeQualified(dir3);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have three entries",3,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(file2.toString(),stats[1].getPath().toString());
  assertEquals(file3.toString(),stats[2].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir4=fs.makeQualified(new Path(dir,"dir4"));
  fs.mkdirs(dir4);
  dir4=fs.makeQualified(dir4);
  Path dir5=fs.makeQualified(new Path(dir,"dir5"));
  fs.mkdirs(dir5);
  dir5=fs.makeQualified(dir5);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have five entries",5,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(dir4.toString(),stats[1].getPath().toString());
  assertEquals(dir5.toString(),stats[2].getPath().toString());
  assertEquals(file2.toString(),stats[3].getPath().toString());
  assertEquals(file3.toString(),stats[4].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(dir4.toString(),itor.next().getPath().toString());
  assertEquals(dir5.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse(itor.hasNext());
{
    fs.setPermission(dir,new FsPermission((short)0));
    try {
      final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
      final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,conf,0,"somegroup");
      hftp2.getContentSummary(dir);
      fail();
    }
 catch (    IOException ioe) {
      FileSystem.LOG.info("GOOD: getting an exception",ioe);
    }
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the FileStatus obtained calling getFileStatus on a file 
 */
@Test public void testGetFileStatusOnFile() throws IOException {
  checkFile(fs,file1,1);
  FileStatus status=fs.getFileStatus(file1);
  assertFalse(file1 + " should be a file",status.isDirectory());
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  assertEquals(fileSize,status.getLen());
  assertEquals(file1.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
}

</code></pre>

<br>
<pre class="type-3 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test getting a FileStatus object using a non-existant path 
 */
@Test public void testGetFileStatusOnNonExistantFileDir() throws IOException {
  Path dir=new Path("/test/mkdirs");
  try {
    fs.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fc.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fs.getFileStatus(dir);
    fail("getFileStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertTrue("Exception doesn't indicate non-existant path",fe.getMessage().startsWith("File does not exist"));
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the FileStatus obtained calling listStatus on a file 
 */
@Test public void testListStatusOnFile() throws IOException {
  FileStatus[] stats=fs.listStatus(file1);
  assertEquals(1,stats.length);
  FileStatus status=stats[0];
  assertFalse(file1 + " should be a file",status.isDirectory());
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  assertEquals(fileSize,status.getLen());
  assertEquals(file1.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
  RemoteIterator<FileStatus> itor=fc.listStatus(file1);
  status=itor.next();
  assertEquals(stats[0],status);
  assertFalse(file1 + " should be a file",status.isDirectory());
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test calling getFileInfo directly on the client 
 */
@Test public void testGetFileInfo() throws IOException {
  Path path=new Path("/");
  assertTrue("/ should be a directory",fs.getFileStatus(path).isDirectory());
  HdfsFileStatus fileInfo=dfsClient.getFileInfo("/noSuchFile");
  assertEquals("Non-existant file should result in null",null,fileInfo);
  try {
    dfsClient.getFileInfo("non-absolute");
    fail("getFileInfo for a non-absolute path did not throw IOException");
  }
 catch (  RemoteException re) {
    assertTrue("Wrong exception for invalid file name",re.toString().contains("Invalid file name"));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestHFlush </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testHFlushInterrupted() throws Exception {
  final int DATANODE_NUM=2;
  final int fileLen=6;
  byte[] fileContents=AppendTestUtil.initBuffer(fileLen);
  Configuration conf=new HdfsConfiguration();
  final Path p=new Path("/hflush-interrupted");
  System.out.println("p=" + p);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
  try {
    DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,p,DATANODE_NUM);
    stm.write(fileContents,0,2);
    Thread.currentThread().interrupt();
    try {
      stm.hflush();
      assertTrue(Thread.currentThread().interrupted());
    }
 catch (    InterruptedIOException ie) {
      System.out.println("Got expected exception during flush");
    }
    assertFalse(Thread.currentThread().interrupted());
    stm.hflush();
    stm.write(fileContents,2,2);
    stm.hflush();
    stm.write(fileContents,4,2);
    Thread.currentThread().interrupt();
    try {
      stm.close();
      assertTrue(Thread.currentThread().interrupted());
    }
 catch (    InterruptedIOException ioe) {
      System.out.println("Got expected exception during close");
      assertFalse(Thread.currentThread().interrupted());
      stm.close();
    }
    AppendTestUtil.checkFullFile(fs,p,fileLen,fileContents,"Failed to deal with thread interruptions");
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLease </h4><pre class="type-10 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFactory() throws Exception {
  final String[] groups=new String[]{"supergroup"};
  final UserGroupInformation[] ugi=new UserGroupInformation[3];
  for (int i=0; i < ugi.length; i++) {
    ugi[i]=UserGroupInformation.createUserForTesting("user" + i,groups);
  }
  final Configuration conf=new Configuration();
  final DFSClient c1=createDFSClientAs(ugi[0],conf);
  final DFSClient c2=createDFSClientAs(ugi[0],conf);
  Assert.assertEquals(c1.leaserenewer,c2.leaserenewer);
  final DFSClient c3=createDFSClientAs(ugi[1],conf);
  Assert.assertTrue(c1.leaserenewer != c3.leaserenewer);
  final DFSClient c4=createDFSClientAs(ugi[1],conf);
  Assert.assertEquals(c3.leaserenewer,c4.leaserenewer);
  final DFSClient c5=createDFSClientAs(ugi[2],conf);
  Assert.assertTrue(c1.leaserenewer != c5.leaserenewer);
  Assert.assertTrue(c3.leaserenewer != c5.leaserenewer);
}

</code></pre>

<br>
<pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testLease() throws Exception {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    Assert.assertTrue(fs.mkdirs(dir));
    Path a=new Path(dir,"a");
    Path b=new Path(dir,"b");
    DataOutputStream a_out=fs.create(a);
    a_out.writeBytes("something");
    Assert.assertTrue(hasLease(cluster,a));
    Assert.assertTrue(!hasLease(cluster,b));
    DataOutputStream b_out=fs.create(b);
    b_out.writeBytes("something");
    Assert.assertTrue(hasLease(cluster,a));
    Assert.assertTrue(hasLease(cluster,b));
    a_out.close();
    b_out.close();
    Assert.assertTrue(!hasLease(cluster,a));
    Assert.assertTrue(!hasLease(cluster,b));
    fs.delete(dir,true);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRecovery2 </h4><pre class="type-16 type-10 type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the soft lease expiration period to be short 1s. Thus triggering
 * soft lease expiration to happen immediately by having another client
 * trying to create the same file.
 * The test makes sure that the lease recovery completes.
 * @throws Exception
 */
@Test public void testSoftLeaseRecovery() throws Exception {
  Map<String,String[]> u2g_map=new HashMap<String,String[]>(1);
  u2g_map.put(fakeUsername,new String[]{fakeGroup});
  DFSTestUtil.updateConfWithFakeGroupMapping(conf,u2g_map);
  String filestr="/foo" + AppendTestUtil.nextInt();
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
{
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting(fakeUsername,new String[]{fakeGroup});
    FileSystem dfs2=DFSTestUtil.getFileSystemAs(ugi,conf);
    boolean done=false;
    for (int i=0; i < 10 && !done; i++) {
      AppendTestUtil.LOG.info("i=" + i);
      try {
        dfs2.create(filepath,false,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
        fail("Creation of an existing file should never succeed.");
      }
 catch (      FileAlreadyExistsException ex) {
        done=true;
      }
catch (      AlreadyBeingCreatedException ex) {
        AppendTestUtil.LOG.info("GOOD! got " + ex.getMessage());
      }
catch (      IOException ioe) {
        AppendTestUtil.LOG.warn("UNEXPECTED IOException",ioe);
      }
      if (!done) {
        AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
        try {
          Thread.sleep(5000);
        }
 catch (        InterruptedException e) {
        }
      }
    }
    assertTrue(done);
  }
  AppendTestUtil.LOG.info("Lease for file " + filepath + " is recovered. "+ "Validating its contents now...");
  long fileSize=dfs.getFileStatus(filepath).getLen();
  assertTrue("File should be " + size + " bytes, but is actually "+ " found to be "+ fileSize+ " bytes",fileSize == size);
  AppendTestUtil.LOG.info("File size is good. " + "Now validating data and sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the hard lease expiration period to be short 1s. Thus triggering
 * lease expiration to happen while the client is still alive.
 * The test makes sure that the lease recovery completes and the client
 * fails if it continues to write to the file.
 * @throws Exception
 */
@Test public void testHardLeaseRecovery() throws Exception {
  String filestr="/hardLeaseRecovery";
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
  LocatedBlocks locatedBlocks;
  do {
    Thread.sleep(SHORT_LEASE_PERIOD);
    locatedBlocks=DFSClient.callGetBlockLocations(dfs.dfs.namenode,filestr,0L,size);
  }
 while (locatedBlocks.isUnderConstruction());
  assertEquals(size,locatedBlocks.getFileLength());
  try {
    stm.write('b');
    stm.close();
    fail("Writer thread should have been killed");
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
  AppendTestUtil.LOG.info("File size is good. Now validating sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRenewer </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testClientName() throws IOException {
  String clientName=renewer.getClientName("NONMAPREDUCE");
  Assert.assertTrue("bad client name: " + clientName,clientName.startsWith("DFSClient_NONMAPREDUCE_"));
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testThreadName() throws Exception {
  DFSOutputStream mockStream=Mockito.mock(DFSOutputStream.class);
  String filePath="/foo";
  Assert.assertFalse("Renewer not initially running",renewer.isRunning());
  Mockito.doReturn(false).when(MOCK_DFSCLIENT).isFilesBeingWrittenEmpty();
  renewer.put(filePath,mockStream,MOCK_DFSCLIENT);
  Assert.assertTrue("Renewer should have started running",renewer.isRunning());
  String threadName=renewer.getDaemonName();
  Assert.assertEquals("LeaseRenewer:myuser@hdfs://nn1/",threadName);
  Mockito.doReturn(true).when(MOCK_DFSCLIENT).isFilesBeingWrittenEmpty();
  renewer.closeFile(filePath,MOCK_DFSCLIENT);
  long failTime=System.currentTimeMillis() + 5000;
  while (renewer.isRunning() && System.currentTimeMillis() < failTime) {
    Thread.sleep(50);
  }
  Assert.assertFalse(renewer.isRunning());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestListFilesInFileContext </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input patch has a symbolic links as its children 
 */
@Test public void testSymbolicLinks() throws IOException {
  writeFile(fc,FILE1,FILE_LEN);
  writeFile(fc,FILE2,FILE_LEN);
  writeFile(fc,FILE3,FILE_LEN);
  Path dir4=new Path(TEST_DIR,"dir4");
  Path dir5=new Path(dir4,"dir5");
  Path file4=new Path(dir4,"file4");
  fc.createSymlink(DIR1,dir5,true);
  fc.createSymlink(FILE1,file4,true);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(dir4,true);
  LocatedFileStatus stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE3),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(dir4,false);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
}

</code></pre>

<br>
<pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input path is a file 
 */
@Test public void testFile() throws IOException {
  fc.mkdir(TEST_DIR,FsPermission.getDefault(),true);
  writeFile(fc,FILE1,FILE_LEN);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(FILE1,true);
  LocatedFileStatus stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  itor=fc.util().listFiles(FILE1,false);
  stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
}

</code></pre>

<br>
<pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input path is a directory 
 */
@Test public void testDirectory() throws IOException {
  fc.mkdir(DIR1,FsPermission.getDefault(),true);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(DIR1,true);
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(DIR1,false);
  assertFalse(itor.hasNext());
  writeFile(fc,FILE2,FILE_LEN);
  itor=fc.util().listFiles(DIR1,true);
  LocatedFileStatus stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  itor=fc.util().listFiles(DIR1,false);
  stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  writeFile(fc,FILE1,FILE_LEN);
  writeFile(fc,FILE3,FILE_LEN);
  itor=fc.util().listFiles(TEST_DIR,true);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE3),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(TEST_DIR,false);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestPipelines </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Creates and closes a file of certain length.
 * Calls append to allow next write() operation to add to the end of it
 * After write() invocation, calls hflush() to make sure that data sunk through
 * the pipeline and check the state of the last block's replica.
 * It supposes to be in RBW state
 * @throws IOException in case of an error
 */
@Test public void pipeline_01() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + METHOD_NAME);
  }
  Path filePath=new Path("/" + METHOD_NAME + ".dat");
  DFSTestUtil.createFile(fs,filePath,FILE_SIZE,REPL_FACTOR,rand.nextLong());
  if (LOG.isDebugEnabled()) {
    LOG.debug("Invoking append but doing nothing otherwise...");
  }
  FSDataOutputStream ofs=fs.append(filePath);
  ofs.writeBytes("Some more stuff to write");
  ((DFSOutputStream)ofs.getWrappedStream()).hflush();
  List<LocatedBlock> lb=cluster.getNameNode().getBlockLocations(filePath.toString(),FILE_SIZE - 1,FILE_SIZE).getLocatedBlocks();
  String bpid=cluster.getNamesystem().getBlockPoolId();
  for (  DataNode dn : cluster.getDataNodes()) {
    Replica r=DataNodeAdapter.fetchReplicaInfo(dn,bpid,lb.get(0).getBlock().getBlockId());
    assertTrue("Replica on DN " + dn + " shouldn't be null",r != null);
    assertEquals("Should be RBW replica on " + dn + " after sequence of calls append()/write()/hflush()",HdfsConstants.ReplicaState.RBW,r.getState());
  }
  ofs.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestQuota </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test commands that change the size of the name space:
 * mkdirs, rename, and delete 
 */
@Test public void testNamespaceCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  try {
    assertTrue(dfs.mkdirs(new Path("/nqdir0/qdir1/qdir20/nqdir30")));
    final Path quotaDir1=new Path("/nqdir0/qdir1");
    dfs.setQuota(quotaDir1,6,FSConstants.QUOTA_DONT_SET);
    ContentSummary c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),6);
    final Path quotaDir2=new Path("/nqdir0/qdir1/qdir20");
    dfs.setQuota(quotaDir2,7,FSConstants.QUOTA_DONT_SET);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    final Path quotaDir3=new Path("/nqdir0/qdir1/qdir21");
    assertTrue(dfs.mkdirs(quotaDir3));
    dfs.setQuota(quotaDir3,2,FSConstants.QUOTA_DONT_SET);
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),2);
    Path tempPath=new Path(quotaDir3,"nqdir32");
    assertTrue(dfs.mkdirs(tempPath));
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),2);
    tempPath=new Path(quotaDir3,"nqdir33");
    boolean hasException=false;
    try {
      assertFalse(dfs.mkdirs(tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),2);
    tempPath=new Path(quotaDir2,"nqdir31");
    assertTrue(dfs.mkdirs(tempPath));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
    tempPath=new Path(quotaDir2,"nqdir33");
    hasException=false;
    try {
      assertFalse(dfs.mkdirs(tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    tempPath=new Path(quotaDir2,"nqdir30");
    dfs.rename(new Path(quotaDir3,"nqdir32"),tempPath);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
    hasException=false;
    try {
      assertFalse(dfs.rename(tempPath,quotaDir3));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.exists(tempPath));
    assertFalse(dfs.exists(new Path(quotaDir3,"nqdir30")));
    hasException=false;
    try {
      assertFalse(dfs.rename(tempPath,new Path(quotaDir3,"nqdir32")));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.exists(tempPath));
    assertFalse(dfs.exists(new Path(quotaDir3,"nqdir32")));
    assertTrue(dfs.rename(tempPath,new Path("/nqdir0")));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),6);
    assertTrue(dfs.mkdirs(new Path("/nqdir0/nqdir30/nqdir33")));
    hasException=false;
    try {
      assertFalse(dfs.rename(new Path("/nqdir0/nqdir30"),tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.rename(quotaDir3,quotaDir2));
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),6);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),7);
    tempPath=new Path(quotaDir2,"qdir21");
    c=dfs.getContentSummary(tempPath);
    assertEquals(c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),2);
    dfs.delete(tempPath,true);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),6);
    assertTrue(dfs.rename(new Path("/nqdir0/nqdir30"),quotaDir2));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),5);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Like the previous test but create many files. This covers bugs where
 * the quota adjustment is incorrect but it takes many files to accrue 
 * a big enough accounting error to violate the quota.
 */
@Test public void testMultipleFilesSmallerThanOneBlock() throws Exception {
  Configuration conf=new HdfsConfiguration();
  final int BLOCK_SIZE=6 * 1024;
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  cluster.waitActive();
  FileSystem fs=cluster.getFileSystem();
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    Path dir=new Path("/test");
    boolean exceededQuota=false;
    ContentSummary c;
    final int FILE_SIZE=1024;
    final int QUOTA_SIZE=32 * (int)fs.getDefaultBlockSize();
    assertEquals(6 * 1024,fs.getDefaultBlockSize());
    assertEquals(192 * 1024,QUOTA_SIZE);
    assertTrue(fs.mkdirs(dir));
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(QUOTA_SIZE),dir.toString());
    for (int i=0; i < 59; i++) {
      Path file=new Path("/test/test" + i);
      DFSTestUtil.createFile(fs,file,FILE_SIZE,(short)3,1L);
      DFSTestUtil.waitReplication(fs,file,(short)3);
    }
    c=fs.getContentSummary(dir);
    assertEquals("Invalid space consumed",59 * FILE_SIZE * 3,c.getSpaceConsumed());
    assertEquals("Invalid space consumed",QUOTA_SIZE - (59 * FILE_SIZE * 3),3 * (fs.getDefaultBlockSize() - FILE_SIZE));
    try {
      Path file=new Path("/test/test59");
      DFSTestUtil.createFile(fs,file,FILE_SIZE,(short)3,1L);
      DFSTestUtil.waitReplication(fs,file,(short)3);
    }
 catch (    QuotaExceededException e) {
      exceededQuota=true;
    }
    assertTrue("Quota not exceeded",exceededQuota);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test HDFS operations that change disk space consumed by a directory tree.
 * namely create, rename, delete, append, and setReplication.
 * This is based on testNamespaceCommands() above.
 */
@Test public void testSpaceCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,"512");
  conf.setBoolean("dfs.support.append",true);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  try {
    int fileLen=1024;
    short replication=3;
    int fileSpace=fileLen * replication;
    assertTrue(dfs.mkdirs(new Path("/nqdir0/qdir1/qdir20/nqdir30")));
    final Path quotaDir1=new Path("/nqdir0/qdir1");
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,4 * fileSpace);
    ContentSummary c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceQuota(),4 * fileSpace);
    final Path quotaDir20=new Path("/nqdir0/qdir1/qdir20");
    dfs.setQuota(quotaDir20,FSConstants.QUOTA_DONT_SET,6 * fileSpace);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceQuota(),6 * fileSpace);
    final Path quotaDir21=new Path("/nqdir0/qdir1/qdir21");
    assertTrue(dfs.mkdirs(quotaDir21));
    dfs.setQuota(quotaDir21,FSConstants.QUOTA_DONT_SET,2 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceQuota(),2 * fileSpace);
    Path tempPath=new Path(quotaDir21,"nqdir32");
    assertTrue(dfs.mkdirs(tempPath));
    DFSTestUtil.createFile(dfs,new Path(tempPath,"fileDir/file1"),fileLen,replication,0);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    boolean hasException=false;
    try {
      DFSTestUtil.createFile(dfs,new Path(quotaDir21,"nqdir33/file2"),2 * fileLen,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.delete(new Path(quotaDir21,"nqdir33"),true));
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    assertEquals(c.getSpaceQuota(),2 * fileSpace);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),0);
    Path dstPath=new Path(quotaDir20,"nqdir30");
    Path srcPath=new Path(quotaDir21,"nqdir32");
    assertTrue(dfs.rename(srcPath,dstPath));
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    final Path file2=new Path(dstPath,"fileDir/file2");
    int file2Len=2 * fileLen;
    DFSTestUtil.createFile(dfs,file2,file2Len,replication,0);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    hasException=false;
    try {
      assertFalse(dfs.rename(dstPath,srcPath));
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertFalse(dfs.exists(srcPath));
    assertTrue(dfs.exists(dstPath));
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceQuota(),4 * fileSpace);
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    OutputStream out=dfs.append(file2);
    out.write(new byte[fileLen]);
    out.close();
    file2Len+=fileLen;
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),4 * fileSpace);
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,5 * fileSpace);
    out=dfs.append(file2);
    hasException=false;
    try {
      out.write(new byte[fileLen + 1024]);
      out.flush();
      out.close();
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
      IOUtils.closeStream(out);
    }
    assertTrue(hasException);
    file2Len+=fileLen;
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace);
    dfs.setReplication(file2,(short)(replication - 1));
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace - file2Len);
    hasException=false;
    try {
      dfs.setReplication(file2,(short)(replication + 1));
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace - file2Len);
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,10 * fileSpace);
    dfs.setQuota(quotaDir20,FSConstants.QUOTA_DONT_SET,10 * fileSpace);
    dfs.setReplication(file2,(short)(replication + 1));
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace + file2Len);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Violate a space quota using files of size < 1 block. Test that block
 * allocation conservatively assumes that for quota checking the entire
 * space of the block is used.
 */
@Test public void testBlockAllocationAdjustsUsageConservatively() throws Exception {
  Configuration conf=new HdfsConfiguration();
  final int BLOCK_SIZE=6 * 1024;
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  cluster.waitActive();
  FileSystem fs=cluster.getFileSystem();
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    Path dir=new Path("/test");
    Path file1=new Path("/test/test1");
    Path file2=new Path("/test/test2");
    boolean exceededQuota=false;
    final int QUOTA_SIZE=3 * BLOCK_SIZE;
    final int FILE_SIZE=BLOCK_SIZE / 2;
    ContentSummary c;
    assertTrue(fs.mkdirs(dir));
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(QUOTA_SIZE),dir.toString());
    DFSTestUtil.createFile(fs,file1,FILE_SIZE,(short)3,1L);
    DFSTestUtil.waitReplication(fs,file1,(short)3);
    c=fs.getContentSummary(dir);
    assertEquals("Quota is half consumed",QUOTA_SIZE / 2,c.getSpaceConsumed());
    try {
      DFSTestUtil.createFile(fs,file2,FILE_SIZE,(short)3,1L);
    }
 catch (    QuotaExceededException e) {
      exceededQuota=true;
    }
    assertTrue("Quota not exceeded",exceededQuota);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test quota related commands: 
 * setQuota, clrQuota, setSpaceQuota, clrSpaceQuota, and count 
 */
@Test public void testQuotaCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final int DEFAULT_BLOCK_SIZE=512;
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DEFAULT_BLOCK_SIZE);
  conf.setBoolean("dfs.support.append",true);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    final int fileLen=1024;
    final short replication=5;
    final long spaceQuota=fileLen * replication * 15 / 8;
    final Path parent=new Path("/test");
    assertTrue(dfs.mkdirs(parent));
    String[] args=new String[]{"-setQuota","3",parent.toString()};
    runCommand(admin,args,false);
    runCommand(admin,false,"-setSpaceQuota","2t",parent.toString());
    assertEquals(2L << 40,dfs.getContentSummary(parent).getSpaceQuota());
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota),parent.toString());
    final Path childDir0=new Path(parent,"data0");
    assertTrue(dfs.mkdirs(childDir0));
    final Path childFile0=new Path(parent,"datafile0");
    DFSTestUtil.createFile(fs,childFile0,fileLen,replication,0);
    ContentSummary c=dfs.getContentSummary(parent);
    assertEquals(c.getFileCount() + c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),3);
    assertEquals(c.getSpaceConsumed(),fileLen * replication);
    assertEquals(c.getSpaceQuota(),spaceQuota);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getFileCount() + c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),-1);
    c=dfs.getContentSummary(parent);
    assertEquals(c.getSpaceConsumed(),fileLen * replication);
    final Path childDir1=new Path(parent,"data1");
    boolean hasException=false;
    try {
      assertFalse(dfs.mkdirs(childDir1));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    OutputStream fout;
    final Path childFile1=new Path(parent,"datafile1");
    hasException=false;
    try {
      fout=dfs.create(childFile1);
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    runCommand(admin,new String[]{"-clrQuota",parent.toString()},false);
    c=dfs.getContentSummary(parent);
    assertEquals(c.getQuota(),-1);
    assertEquals(c.getSpaceQuota(),spaceQuota);
    runCommand(admin,new String[]{"-clrQuota",childDir0.toString()},false);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getQuota(),-1);
    fout=dfs.create(childFile1,replication);
    hasException=false;
    try {
      fout.write(new byte[fileLen]);
      fout.close();
    }
 catch (    QuotaExceededException e) {
      hasException=true;
      IOUtils.closeStream(fout);
    }
    assertTrue(hasException);
    dfs.delete(childFile1,false);
    runCommand(admin,false,"-clrSpaceQuota",parent.toString());
    c=dfs.getContentSummary(parent);
    assertEquals(c.getQuota(),-1);
    assertEquals(c.getSpaceQuota(),-1);
    DFSTestUtil.createFile(dfs,childFile1,fileLen,replication,0);
    args=new String[]{"-setQuota","1",parent.toString()};
    runCommand(admin,args,false);
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(fileLen),args[2]);
    args=new String[]{"-setQuota","1",childDir0.toString()};
    runCommand(admin,args,false);
    hasException=false;
    try {
      assertFalse(dfs.mkdirs(new Path(childDir0,"in")));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getDirectoryCount() + c.getFileCount(),1);
    assertEquals(c.getQuota(),1);
    Path nonExistentPath=new Path("/test1");
    assertFalse(dfs.exists(nonExistentPath));
    args=new String[]{"-setQuota","1",nonExistentPath.toString()};
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","1g",nonExistentPath.toString());
    assertTrue(dfs.isFile(childFile0));
    args[1]=childFile0.toString();
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","1t",args[1]);
    args[0]="-clrQuota";
    runCommand(admin,args,true);
    runCommand(admin,true,"-clrSpaceQuota",args[1]);
    args[1]=nonExistentPath.toString();
    runCommand(admin,args,true);
    runCommand(admin,true,"-clrSpaceQuota",args[1]);
    args=new String[]{"-setQuota","0",parent.toString()};
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","0",args[2]);
    args[1]="-1";
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    args[1]=String.valueOf(Long.MAX_VALUE + 1L);
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    args[1]="33aa1.5";
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    runCommand(admin,true,"-setSpaceQuota",(Long.MAX_VALUE / 1024 / 1024 + 1024) + "m",args[2]);
    final String username="userxx";
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting(username,new String[]{"groupyy"});
    final String[] args2=args.clone();
    ugi.doAs(new PrivilegedExceptionAction(){
      @Override public Object run() throws Exception {
        assertEquals("Not running as new user",username,UserGroupInformation.getCurrentUser().getShortUserName());
        DFSAdmin userAdmin=new DFSAdmin(conf);
        args2[1]="100";
        runCommand(userAdmin,args2,true);
        runCommand(userAdmin,true,"-setSpaceQuota","1g",args2[2]);
        String[] args3=new String[]{"-clrQuota",parent.toString()};
        runCommand(userAdmin,args3,true);
        runCommand(userAdmin,true,"-clrSpaceQuota",args3[1]);
        return null;
      }
    }
);
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-setQuota","1000000","/");
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    runCommand(admin,new String[]{"-clrQuota",parent.toString()},false);
    runCommand(admin,false,"-clrSpaceQuota",parent.toString());
    final Path childDir2=new Path(parent,"data2");
    assertTrue(dfs.mkdirs(childDir2));
    final Path childFile2=new Path(childDir2,"datafile2");
    final Path childFile3=new Path(childDir2,"datafile3");
    final long spaceQuota2=DEFAULT_BLOCK_SIZE * replication;
    final long fileLen2=DEFAULT_BLOCK_SIZE;
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),childDir2.toString());
    runCommand(admin,false,"-clrSpaceQuota",childDir2.toString());
    DFSTestUtil.createFile(fs,childFile2,fileLen2,replication,0);
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),childDir2.toString());
    hasException=false;
    try {
      DFSTestUtil.createFile(fs,childFile3,fileLen2,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    final Path childFile4=new Path("/","datafile2");
    final Path childFile5=new Path("/","datafile3");
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),"/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    DFSTestUtil.createFile(fs,childFile4,fileLen2,replication,0);
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),"/");
    hasException=false;
    try {
      DFSTestUtil.createFile(fs,childFile5,fileLen2,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestSafeMode </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * This test verifies that if SafeMode is manually entered, name-node does not
 * come out of safe mode even after the startup safe mode conditions are met.
 * <ol>
 * <li>Start cluster with 1 data-node.</li>
 * <li>Create 2 files with replication 1.</li>
 * <li>Re-start cluster with 0 data-nodes. 
 * Name-node should stay in automatic safe-mode.</li>
 * <li>Enter safe mode manually.</li>
 * <li>Start the data-node.</li>
 * <li>Wait longer than <tt>dfs.namenode.safemode.extension</tt> and 
 * verify that the name-node is still in safe mode.</li>
 * </ol>
 * @throws IOException
 */
@Test public void testManualSafeMode() throws IOException {
  fs=(DistributedFileSystem)cluster.getFileSystem();
  Path file1=new Path("/tmp/testManualSafeMode/file1");
  Path file2=new Path("/tmp/testManualSafeMode/file2");
  DFSTestUtil.createFile(fs,file1,1000,(short)1,0);
  DFSTestUtil.createFile(fs,file2,2000,(short)1,0);
  fs.close();
  cluster.shutdown();
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).build();
  cluster.waitActive();
  dfs=(DistributedFileSystem)cluster.getFileSystem();
  assertTrue("No datanode is started. Should be in SafeMode",dfs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
  cluster.startDataNodes(conf,1,true,null,null);
  cluster.waitActive();
  try {
    Thread.sleep(2000);
  }
 catch (  InterruptedException ignored) {
  }
  assertTrue("should still be in SafeMode",dfs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  assertFalse("should not be in SafeMode",dfs.setSafeMode(SafeModeAction.SAFEMODE_LEAVE));
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Run various fs operations while the NN is in safe mode,
 * assert that they are either allowed or fail as expected.
 */
@Test public void testOperationsWhileInSafeMode() throws IOException {
  final Path file1=new Path("/file1");
  assertFalse(dfs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  DFSTestUtil.createFile(fs,file1,1024,(short)1,0);
  assertTrue("Could not enter SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER));
  runFsFun("Set quota while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      ((DistributedFileSystem)fs).setQuota(file1,1,1);
    }
  }
);
  runFsFun("Set perm while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setPermission(file1,FsPermission.getDefault());
    }
  }
);
  runFsFun("Set owner while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setOwner(file1,"user","group");
    }
  }
);
  runFsFun("Set repl while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setReplication(file1,(short)1);
    }
  }
);
  runFsFun("Append file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      DFSTestUtil.appendFile(fs,file1,"new bytes");
    }
  }
);
  runFsFun("Delete file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.delete(file1,false);
    }
  }
);
  runFsFun("Rename file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.rename(file1,new Path("file2"));
    }
  }
);
  try {
    fs.setTimes(file1,0,0);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  try {
    DFSTestUtil.readFile(fs,file1);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  assertFalse("Could not leave SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_LEAVE));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.protocol.TestCorruptFileBlocks </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Test serialization and deserializaton of CorruptFileBlocks.
 */
@Test public void testSerialization() throws IOException {
{
    CorruptFileBlocks cfb=new CorruptFileBlocks();
    assertTrue("cannot serialize empty CFB",checkSerialize(cfb));
  }
{
    String[] files=new String[0];
    CorruptFileBlocks cfb=new CorruptFileBlocks(files,"");
    assertTrue("cannot serialize CFB with empty cookie",checkSerialize(cfb));
  }
{
    String[] files={"a","bb","ccc"};
    CorruptFileBlocks cfb=new CorruptFileBlocks(files,"test");
    assertTrue("cannot serialize CFB",checkSerialize(cfb));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.protocol.TestLayoutVersion </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Test to make sure 0.20.204 supports delegation token
 */
@Test public void testRelease204(){
  assertTrue(LayoutVersion.supports(Feature.DELEGATION_TOKEN,Feature.RESERVED_REL20_204.lv));
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Test to make sure 0.20.203 supports delegation token
 */
@Test public void testRelease203(){
  assertTrue(LayoutVersion.supports(Feature.DELEGATION_TOKEN,Feature.RESERVED_REL20_203.lv));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.TestDelegationToken </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testDelegationTokenDFSApi() throws Exception {
  DelegationTokenSecretManager dtSecretManager=cluster.getNamesystem().getDelegationTokenSecretManager();
  DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
  Token<DelegationTokenIdentifier> token=dfs.getDelegationToken("JobTracker");
  DelegationTokenIdentifier identifier=new DelegationTokenIdentifier();
  byte[] tokenId=token.getIdentifier();
  identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
  LOG.info("A valid token should have non-null password, and should be renewed successfully");
  Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
  dtSecretManager.renewToken(token,"JobTracker");
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDelegationTokenSecretManager() throws Exception {
  DelegationTokenSecretManager dtSecretManager=cluster.getNamesystem().getDelegationTokenSecretManager();
  Token<DelegationTokenIdentifier> token=generateDelegationToken("SomeUser","JobTracker");
  try {
    dtSecretManager.renewToken(token,"FakeRenewer");
    Assert.fail("should have failed");
  }
 catch (  AccessControlException ace) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  DelegationTokenIdentifier identifier=new DelegationTokenIdentifier();
  byte[] tokenId=token.getIdentifier();
  identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
  Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
  LOG.info("Sleep to expire the token");
  Thread.sleep(6000);
  try {
    dtSecretManager.retrievePassword(identifier);
    Assert.fail("Token should have expired");
  }
 catch (  InvalidToken e) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  LOG.info("Sleep beyond the max lifetime");
  Thread.sleep(5000);
  try {
    dtSecretManager.renewToken(token,"JobTracker");
    Assert.fail("should have been expired");
  }
 catch (  InvalidToken it) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * BlockRecovery_02.8.
 * Two replicas are in Finalized state
 * @throws IOException in case of an error
 */
@Test public void testFinalizedReplicas() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  ReplicaRecoveryInfo replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  ReplicaRecoveryInfo replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 2,ReplicaState.FINALIZED);
  InterDatanodeProtocol dn1=mock(InterDatanodeProtocol.class);
  InterDatanodeProtocol dn2=mock(InterDatanodeProtocol.class);
  testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
  verify(dn1).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  verify(dn2).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN2,GEN_STAMP - 2,ReplicaState.FINALIZED);
  try {
    testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
    Assert.fail("Two finalized replicas should not have different lengthes!");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("Inconsistent size of finalized replicas. "));
  }
}

</code></pre>

<br>
<pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of datanode
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (dn != null) {
    try {
      dn.shutdown();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(DATA_DIR);
      if (dir.exists())       Assert.assertTrue("Cannot delete data-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockReport </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test write a file, verifies and closes it. Then a couple of random blocks
 * is removed and BlockReport is forced; the FSNamesystem is pushed to
 * recalculate required DN's activities such as replications and so on.
 * The number of missing and under-replicated blocks should be the same in
 * case of a single-DN cluster.
 * @throws IOException in case of errors
 */
@Test public void blockReport_02() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  LOG.info("Running test " + METHOD_NAME);
  Path filePath=new Path("/" + METHOD_NAME + ".dat");
  DFSTestUtil.createFile(fs,filePath,(long)FILE_SIZE,REPL_FACTOR,rand.nextLong());
  File dataDir=new File(cluster.getDataDirectory());
  assertTrue(dataDir.isDirectory());
  List<ExtendedBlock> blocks2Remove=new ArrayList<ExtendedBlock>();
  List<Integer> removedIndex=new ArrayList<Integer>();
  List<LocatedBlock> lBlocks=cluster.getNameNode().getBlockLocations(filePath.toString(),FILE_START,FILE_SIZE).getLocatedBlocks();
  while (removedIndex.size() != 2) {
    int newRemoveIndex=rand.nextInt(lBlocks.size());
    if (!removedIndex.contains(newRemoveIndex))     removedIndex.add(newRemoveIndex);
  }
  for (  Integer aRemovedIndex : removedIndex) {
    blocks2Remove.add(lBlocks.get(aRemovedIndex).getBlock());
  }
  ArrayList<Block> blocks=locatedToBlocks(lBlocks,removedIndex);
  if (LOG.isDebugEnabled()) {
    LOG.debug("Number of blocks allocated " + lBlocks.size());
  }
  for (  ExtendedBlock b : blocks2Remove) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Removing the block " + b.getBlockName());
    }
    for (    File f : findAllFiles(dataDir,new MyFileFilter(b.getBlockName(),true))) {
      cluster.getDataNodes().get(DN_N0).getFSDataset().unfinalizeBlock(b);
      if (!f.delete())       LOG.warn("Couldn't delete " + b.getBlockName());
    }
  }
  waitTil(DN_RESCAN_EXTRA_WAIT);
  DataNode dn=cluster.getDataNodes().get(DN_N0);
  String poolId=cluster.getNamesystem().getBlockPoolId();
  DatanodeRegistration dnR=dn.getDNRegistrationForBP(poolId);
  cluster.getNameNode().blockReport(dnR,poolId,new BlockListAsLongs(blocks,null).getBlockListAsLongs());
  cluster.getNamesystem().computeDatanodeWork();
  printStats();
  assertEquals("Wrong number of MissingBlocks is found",blocks2Remove.size(),cluster.getNamesystem().getMissingBlocksCount());
  assertEquals("Wrong number of UnderReplicatedBlocks is found",blocks2Remove.size(),cluster.getNamesystem().getUnderReplicatedBlocks());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations </h4><pre class="type-3 type-8 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMiniDFSClusterWithMultipleNN() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(1)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(1)Should be 3 namenodes",3,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).federation(true).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(2)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  try {
    cluster.addNameNode(conf,9929);
    Assert.fail("shouldn't be able to add another NN to non federated cluster");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("cannot add namenode"));
    Assert.assertEquals("(3)Should be 1 namenodes",1,cluster.getNumNameNodes());
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting </h4><pre class="type-8 type-18 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Sets implicit assumptions 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that the NN re-learns of volume failures after restart.
 */
@Test public void testVolFailureStatsPreservedOnNNRestart() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn1Vol1=new File(dataDir,"data" + (2 * 0 + 1));
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(false));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)2,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)2);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  cluster.restartNameNode(0);
  cluster.waitActive();
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
}

</code></pre>

<br>
<pre class="type-8 type-9 type-18 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Sets implicit assumptions 
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that individual volume failures do not cause DNs to fail, that
 * all volumes failed on a single datanode do cause it to fail, and
 * that the capacities and liveliness is adjusted correctly in the NN.
 */
@Test public void testSuccessiveVolumeFailures() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  Thread.sleep(WAIT_FOR_HEARTBEATS);
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn1Vol1=new File(dataDir,"data" + (2 * 0 + 1));
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  File dn3Vol1=new File(dataDir,"data" + (2 * 2 + 1));
  File dn3Vol2=new File(dataDir,"data" + (2 * 2 + 2));
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(false));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)3);
  ArrayList<DataNode> dns=cluster.getDataNodes();
  assertTrue("DN1 should be up",dns.get(0).isDatanodeUp());
  assertTrue("DN2 should be up",dns.get(1).isDatanodeUp());
  assertTrue("DN3 should be up",dns.get(2).isDatanodeUp());
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(0).getMetrics().name()));
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(1).getMetrics().name()));
  assertCounter("VolumeFailures",0L,getMetrics(dns.get(2).getMetrics().name()));
  assert (WAIT_FOR_HEARTBEATS * 10) > WAIT_FOR_DEATH;
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn3Vol1.setExecutable(false));
  Path file2=new Path("/test2");
  DFSTestUtil.createFile(fs,file2,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file2,(short)3);
  assertTrue("DN3 should still be up",dns.get(2).isDatanodeUp());
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(2).getMetrics().name()));
  ArrayList<DatanodeDescriptor> live=new ArrayList<DatanodeDescriptor>();
  ArrayList<DatanodeDescriptor> dead=new ArrayList<DatanodeDescriptor>();
  ns.DFSNodesStatus(live,dead);
  live.clear();
  dead.clear();
  ns.DFSNodesStatus(live,dead);
  assertEquals("DN3 should have 1 failed volume",1,live.get(2).getVolumeFailures());
  dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,3,origCapacity - (3 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn3Vol2.setExecutable(false));
  Path file3=new Path("/test3");
  DFSTestUtil.createFile(fs,file3,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file3,(short)2);
  DFSTestUtil.waitForDatanodeDeath(dns.get(2));
  assertCounter("VolumeFailures",2L,getMetrics(dns.get(2).getMetrics().name()));
  DFSTestUtil.waitForDatanodeStatus(ns,2,1,2,origCapacity - (4 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn3Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn3Vol2.setExecutable(true));
  cluster.restartDataNodes();
  cluster.waitActive();
  Path file4=new Path("/test4");
  DFSTestUtil.createFile(fs,file4,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file4,(short)3);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,0,origCapacity,WAIT_FOR_HEARTBEATS);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration </h4><pre class="type-8 type-18 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Sets implicit assumptions 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY configuration
 * option, ie the DN shuts itself down when the number of failures
 * experienced drops below the tolerated amount.
 */
@Test public void testConfigureMinValidVolumes() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  conf.setInt(DFSConfigKeys.DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY,0);
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)2);
  DFSTestUtil.waitForDatanodeStatus(ns,2,1,0,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(true));
  Path file2=new Path("/test2");
  DFSTestUtil.createFile(fs,file2,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file2,(short)2);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDfsAdminDeleteBlockPool() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1,namesServerId2");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(2).numDataNodes(1).build();
    cluster.waitActive();
    FileSystem fs1=cluster.getFileSystem(0);
    FileSystem fs2=cluster.getFileSystem(1);
    DFSTestUtil.createFile(fs1,new Path("/alpha"),1024,(short)1,54);
    DFSTestUtil.createFile(fs2,new Path("/beta"),1024,(short)1,54);
    DataNode dn1=cluster.getDataNodes().get(0);
    String bpid1=cluster.getNamesystem(0).getBlockPoolId();
    String bpid2=cluster.getNamesystem(1).getBlockPoolId();
    File dn1StorageDir1=MiniDFSCluster.getStorageDir(0,0);
    File dn1StorageDir2=MiniDFSCluster.getStorageDir(0,1);
    Configuration nn1Conf=cluster.getConfiguration(0);
    nn1Conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1");
    dn1.refreshNamenodes(nn1Conf);
    Assert.assertEquals(1,dn1.getAllBpOs().length);
    DFSAdmin admin=new DFSAdmin(nn1Conf);
    String dn1Address=dn1.getSelfAddr().getHostName() + ":" + dn1.getIpcPort();
    String[] args={"-deleteBlockPool",dn1Address,bpid2};
    int ret=admin.run(args);
    Assert.assertFalse(0 == ret);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid2);
    String[] forceArgs={"-deleteBlockPool",dn1Address,bpid2,"force"};
    ret=admin.run(forceArgs);
    Assert.assertEquals(0,ret);
    verifyBlockPoolDirectories(false,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(false,dn1StorageDir2,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid1);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDiskError </h4><pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Test to check that a DN goes down when all its volumes have failed.
 */
@Test public void testShutdown() throws Exception {
  if (System.getProperty("os.name").startsWith("Windows")) {
    return;
  }
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  final int dnIndex=0;
  String bpid=cluster.getNamesystem().getBlockPoolId();
  File storageDir=MiniDFSCluster.getStorageDir(dnIndex,0);
  File dir1=MiniDFSCluster.getRbwDir(storageDir,bpid);
  storageDir=MiniDFSCluster.getStorageDir(dnIndex,1);
  File dir2=MiniDFSCluster.getRbwDir(storageDir,bpid);
  try {
    assertTrue("Couldn't chmod local vol",dir1.setReadOnly());
    assertTrue("Couldn't chmod local vol",dir2.setReadOnly());
    DataNode dn=cluster.getDataNodes().get(dnIndex);
    for (int i=0; dn.isDatanodeUp(); i++) {
      Path fileName=new Path("/test.txt" + i);
      DFSTestUtil.createFile(fs,fileName,1024,(short)2,1L);
      DFSTestUtil.waitReplication(fs,fileName,(short)2);
      fs.delete(fileName,true);
    }
  }
  finally {
    dir1.setWritable(true);
    dir2.setWritable(true);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestInterDatanodeProtocol </h4><pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * The following test first creates a file.
 * It verifies the block information from a datanode.
 * Then, it updates the block with new information and verifies again. 
 */
@Test public void testBlockMetaDataInfo() throws Exception {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
    String filestr="/foo";
    Path filepath=new Path(filestr);
    DFSTestUtil.createFile(dfs,filepath,1024L,(short)3,0L);
    assertTrue(dfs.getClient().exists(filestr));
    LocatedBlock locatedblock=getLastLocatedBlock(dfs.getClient().getNamenode(),filestr);
    DatanodeInfo[] datanodeinfo=locatedblock.getLocations();
    assertTrue(datanodeinfo.length > 0);
    DataNode datanode=cluster.getDataNode(datanodeinfo[0].getIpcPort());
    InterDatanodeProtocol idp=DataNode.createInterDataNodeProtocolProxy(datanodeinfo[0],conf,datanode.socketTimeout);
    assertTrue(datanode != null);
    if (datanode.blockScanner != null) {
      datanode.blockScanner.shutdown();
    }
    ExtendedBlock b=locatedblock.getBlock();
    InterDatanodeProtocol.LOG.info("b=" + b + ", "+ b.getClass());
    checkMetaInfo(b,datanode);
    long recoveryId=b.getGenerationStamp() + 1;
    idp.initReplicaRecovery(new RecoveringBlock(b,locatedblock.getLocations(),recoveryId));
    ExtendedBlock newblock=new ExtendedBlock(b.getBlockPoolId(),b.getBlockId(),b.getNumBytes() / 2,b.getGenerationStamp() + 1);
    idp.updateReplicaUnderRecovery(b,recoveryId,newblock.getNumBytes());
    checkMetaInfo(newblock,datanode);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test  for{@link FSDataset#updateReplicaUnderRecovery(ExtendedBlock,long,long)} 
 */
@Test public void testUpdateReplicaUnderRecovery() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    String bpid=cluster.getNamesystem().getBlockPoolId();
    DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
    String filestr="/foo";
    Path filepath=new Path(filestr);
    DFSTestUtil.createFile(dfs,filepath,1024L,(short)3,0L);
    final LocatedBlock locatedblock=getLastLocatedBlock(dfs.getClient().getNamenode(),filestr);
    final DatanodeInfo[] datanodeinfo=locatedblock.getLocations();
    Assert.assertTrue(datanodeinfo.length > 0);
    final DataNode datanode=cluster.getDataNode(datanodeinfo[0].getIpcPort());
    Assert.assertTrue(datanode != null);
    Assert.assertTrue(datanode.data instanceof FSDataset);
    final FSDataset fsdataset=(FSDataset)datanode.data;
    final ExtendedBlock b=locatedblock.getBlock();
    final long recoveryid=b.getGenerationStamp() + 1;
    final long newlength=b.getNumBytes() - 1;
    final ReplicaRecoveryInfo rri=fsdataset.initReplicaRecovery(new RecoveringBlock(b,null,recoveryid));
    final ReplicaInfo replica=fsdataset.fetchReplicaInfo(bpid,b.getBlockId());
    Assert.assertEquals(ReplicaState.RUR,replica.getState());
    FSDataset.checkReplicaFiles(replica);
{
      final ExtendedBlock tmp=new ExtendedBlock(b.getBlockPoolId(),rri.getBlockId(),rri.getNumBytes() - 1,rri.getGenerationStamp());
      try {
        fsdataset.updateReplicaUnderRecovery(tmp,recoveryid,newlength);
        Assert.fail();
      }
 catch (      IOException ioe) {
        System.out.println("GOOD: getting " + ioe);
      }
    }
    final ReplicaInfo finalized=fsdataset.updateReplicaUnderRecovery(new ExtendedBlock(b.getBlockPoolId(),rri),recoveryid,newlength);
    FSDataset.checkReplicaFiles(finalized);
    Assert.assertEquals(b.getBlockId(),finalized.getBlockId());
    Assert.assertEquals(recoveryid,finalized.getGenerationStamp());
    Assert.assertEquals(newlength,finalized.getNumBytes());
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRefreshNamenodes() throws IOException {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(1).nameNodePort(nnPort1).build();
    DataNode dn=cluster.getDataNodes().get(0);
    assertEquals(1,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort2);
    assertEquals(2,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort3);
    assertEquals(3,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort4);
    BPOfferService[] bpoList=dn.getAllBpOs();
    for (int i=0; i < 4; i++) {
      InetSocketAddress addr=cluster.getNameNode(i).getNameNodeAddress();
      boolean found=false;
      for (int j=0; j < bpoList.length; j++) {
        if (bpoList[j] != null && addr.equals(bpoList[j].nnAddr)) {
          found=true;
          bpoList[j]=null;
          break;
        }
      }
      assertTrue("NameNode address " + addr + " is not found.",found);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestTransferRbw </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testTransferRbw() throws Exception {
  final HdfsConfiguration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION).build();
  try {
    cluster.waitActive();
    final DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
    final Path p=new Path("/foo");
    final int size=(1 << 16) + RAN.nextInt(1 << 16);
    LOG.info("size = " + size);
    final FSDataOutputStream out=fs.create(p,REPLICATION);
    final byte[] bytes=new byte[1024];
    for (int remaining=size; remaining > 0; ) {
      RAN.nextBytes(bytes);
      final int len=bytes.length < remaining ? bytes.length : remaining;
      out.write(bytes,0,len);
      out.hflush();
      remaining-=len;
    }
    final ReplicaBeingWritten oldrbw;
    final DataNode newnode;
    final DatanodeInfo newnodeinfo;
    final String bpid=cluster.getNamesystem().getBlockPoolId();
{
      final DataNode oldnode=cluster.getDataNodes().get(0);
      oldrbw=getRbw(oldnode,bpid);
      LOG.info("oldrbw = " + oldrbw);
      cluster.startDataNodes(conf,1,true,null,null);
      newnode=cluster.getDataNodes().get(REPLICATION);
      final DatanodeInfo oldnodeinfo;
{
        final DatanodeInfo[] datatnodeinfos=cluster.getNameNode().getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertEquals(2,datatnodeinfos.length);
        int i=0;
        for (DatanodeRegistration dnReg=newnode.getDNRegistrationForBP(bpid); i < datatnodeinfos.length && !datatnodeinfos[i].equals(dnReg); i++)         ;
        Assert.assertTrue(i < datatnodeinfos.length);
        newnodeinfo=datatnodeinfos[i];
        oldnodeinfo=datatnodeinfos[1 - i];
      }
      final ExtendedBlock b=new ExtendedBlock(bpid,oldrbw.getBlockId(),oldrbw.getBytesAcked(),oldrbw.getGenerationStamp());
      final BlockOpResponseProto s=DFSTestUtil.transferRbw(b,fs.getClient(),oldnodeinfo,newnodeinfo);
      Assert.assertEquals(Status.SUCCESS,s.getStatus());
    }
    final ReplicaBeingWritten newrbw=getRbw(newnode,bpid);
    LOG.info("newrbw = " + newrbw);
    Assert.assertEquals(oldrbw.getBlockId(),newrbw.getBlockId());
    Assert.assertEquals(oldrbw.getGenerationStamp(),newrbw.getGenerationStamp());
    Assert.assertEquals(oldrbw.getVisibleLength(),newrbw.getVisibleLength());
    LOG.info("DONE");
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestAllowFormat </h4><pre class="type-3 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start MiniDFScluster, try formatting with different settings
 * @throws IOException
 * @throws InterruptedException 
 */
@Test public void testAllowFormat() throws IOException {
  LOG.info("--starting mini cluster");
  NameNode nn;
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  cluster=new MiniDFSCluster.Builder(config).manageDataDfsDirs(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  assertNotNull(cluster);
  nn=cluster.getNameNode();
  assertNotNull(nn);
  LOG.info("Mini cluster created OK");
  LOG.info("Verifying format will fail with allowformat false");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,false);
  try {
    cluster.shutdown();
    NameNode.format(config);
    fail("Format succeeded, when it should have failed");
  }
 catch (  IOException e) {
    assertTrue("Exception was not about formatting Namenode",e.getMessage().startsWith("The option " + DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY));
    LOG.info("Expected failure: " + StringUtils.stringifyException(e));
    LOG.info("Done verifying format will fail with allowformat false");
  }
  LOG.info("Verifying format will succeed with allowformat true");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  NameNode.format(config);
  LOG.info("Done verifying format will succeed with allowformat true");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test NameNode.getBlockLocations(..) on reading un-closed files.
 */
@Test public void testGetBlockLocations() throws IOException {
  final NameNode namenode=cluster.getNameNode();
  final Path p=new Path(BASE_DIR,"file2.dat");
  final String src=p.toString();
  final FSDataOutputStream out=TestFileCreation.createFile(hdfs,p,3);
  int len=BLOCK_SIZE >>> 1;
  writeFile(p,out,len);
  for (int i=1; i < NUM_BLOCKS; ) {
    final LocatedBlocks lb=namenode.getBlockLocations(src,0,len);
    final List<LocatedBlock> blocks=lb.getLocatedBlocks();
    assertEquals(i,blocks.size());
    final Block b=blocks.get(blocks.size() - 1).getBlock().getLocalBlock();
    assertTrue(b instanceof BlockInfoUnderConstruction);
    if (++i < NUM_BLOCKS) {
      writeFile(p,out,BLOCK_SIZE);
      len+=BLOCK_SIZE;
    }
  }
  out.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlocksWithNotEnoughRacks </h4><pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testNodeDecomissionRespectsRackPolicy() throws Exception {
  Configuration conf=getConf();
  short REPLICATION_FACTOR=2;
  final Path filePath=new Path("/testFile");
  FileSystem localFileSys=FileSystem.getLocal(conf);
  Path workingDir=localFileSys.getWorkingDirectory();
  Path dir=new Path(workingDir,"build/test/data/temp/decommission");
  Path excludeFile=new Path(dir,"exclude");
  assertTrue(localFileSys.mkdirs(dir));
  DFSTestUtil.writeFile(localFileSys,excludeFile,"");
  conf.set("dfs.hosts.exclude",excludeFile.toUri().getPath());
  String racks[]={"/rack1","/rack1","/rack2","/rack2"};
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(racks.length).racks(racks).build();
  final FSNamesystem ns=cluster.getNameNode().getNamesystem();
  try {
    final FileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,filePath,1L,REPLICATION_FACTOR,1L);
    ExtendedBlock b=DFSTestUtil.getFirstBlock(fs,filePath);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    BlockLocation locs[]=fs.getFileBlockLocations(fs.getFileStatus(filePath),0,Long.MAX_VALUE);
    String name=locs[0].getNames()[0];
    DFSTestUtil.writeFile(localFileSys,excludeFile,name);
    ns.refreshNodes(conf);
    DFSTestUtil.waitForDecommission(fs,name);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-12 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testCorruptBlockRereplicatedAcrossRacks() throws Exception {
  Configuration conf=getConf();
  short REPLICATION_FACTOR=2;
  int fileLen=512;
  final Path filePath=new Path("/testFile");
  String racks[]={"/rack1","/rack1","/rack2","/rack2"};
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(racks.length).racks(racks).build();
  final FSNamesystem ns=cluster.getNameNode().getNamesystem();
  try {
    final FileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,filePath,fileLen,REPLICATION_FACTOR,1L);
    final String fileContent=DFSTestUtil.readFile(fs,filePath);
    ExtendedBlock b=DFSTestUtil.getFirstBlock(fs,filePath);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    int dnToCorrupt=DFSTestUtil.firstDnWithBlock(cluster,b);
    assertTrue(MiniDFSCluster.corruptReplica(dnToCorrupt,b));
    cluster.restartDataNode(dnToCorrupt);
    DFSTestUtil.waitCorruptReplicas(fs,ns,filePath,b,1);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    for (int i=0; i < racks.length; i++) {
      String blockContent=cluster.readBlockOnDataNode(i,b);
      if (blockContent != null && i != dnToCorrupt) {
        assertEquals("Corrupt replica",fileContent,blockContent);
      }
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testNodeDecomissionWithOverreplicationRespectsRackPolicy() throws Exception {
  Configuration conf=getConf();
  short REPLICATION_FACTOR=5;
  final Path filePath=new Path("/testFile");
  FileSystem localFileSys=FileSystem.getLocal(conf);
  Path workingDir=localFileSys.getWorkingDirectory();
  Path dir=new Path(workingDir,"build/test/data/temp/decommission");
  Path excludeFile=new Path(dir,"exclude");
  assertTrue(localFileSys.mkdirs(dir));
  DFSTestUtil.writeFile(localFileSys,excludeFile,"");
  conf.set("dfs.hosts.exclude",excludeFile.toUri().getPath());
  String racks[]={"/rack1","/rack2","/rack1","/rack1","/rack1"};
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(racks.length).racks(racks).build();
  final FSNamesystem ns=cluster.getNameNode().getNamesystem();
  try {
    final FileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,filePath,1L,REPLICATION_FACTOR,1L);
    ExtendedBlock b=DFSTestUtil.getFirstBlock(fs,filePath);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    REPLICATION_FACTOR=2;
    fs.setReplication(filePath,REPLICATION_FACTOR);
    BlockLocation locs[]=fs.getFileBlockLocations(fs.getFileStatus(filePath),0,Long.MAX_VALUE);
    for (    String top : locs[0].getTopologyPaths()) {
      if (!top.startsWith("/rack2")) {
        String name=top.substring("/rack1".length() + 1);
        DFSTestUtil.writeFile(localFileSys,excludeFile,name);
        ns.refreshNodes(conf);
        DFSTestUtil.waitForDecommission(fs,name);
        break;
      }
    }
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens </h4><pre class="type-10 type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests save namepsace.
 */
@Test public void testSaveNamespace() throws IOException {
  DistributedFileSystem fs=null;
  try {
    Configuration conf=new HdfsConfiguration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    cluster.waitActive();
    fs=(DistributedFileSystem)(cluster.getFileSystem());
    FSNamesystem namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    String renewer=UserGroupInformation.getLoginUser().getUserName();
    Token<DelegationTokenIdentifier> token1=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token2=namesystem.getDelegationToken(new Text(renewer));
    DFSAdmin admin=new DFSAdmin(conf);
    String[] args=new String[]{"-saveNamespace"};
    Collection<URI> editsDirs=cluster.getNameEditsDirs(0);
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() > Integer.SIZE / Byte.SIZE);
    }
    fs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    try {
      admin.run(args);
    }
 catch (    Exception e) {
      throw new IOException(e.getMessage());
    }
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() == Integer.SIZE / Byte.SIZE);
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    try {
      renewToken(token1);
      renewToken(token2);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token3=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token4=namesystem.getDelegationToken(new Text(renewer));
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token5=namesystem.getDelegationToken(new Text(renewer));
    try {
      renewToken(token1);
      renewToken(token2);
      renewToken(token3);
      renewToken(token4);
      renewToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    try {
      renewToken(token1);
      cancelToken(token1);
      renewToken(token2);
      cancelToken(token2);
      renewToken(token3);
      cancelToken(token3);
      renewToken(token4);
      cancelToken(token4);
      renewToken(token5);
      cancelToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
  }
  finally {
    if (fs != null)     fs.close();
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestClusterId </h4><pre class="type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testFormatClusterIdOption() throws IOException {
  Configuration config=new Configuration();
  config.set(DFS_NAMENODE_NAME_DIR_KEY,new File(hdfsDir,"name").getPath());
  NameNode.format(config);
  String cid=getClusterId(config);
  assertTrue("Didn't get new ClusterId",(cid != null && !cid.equals("")));
  StartupOption.FORMAT.setClusterId("mycluster");
  NameNode.format(config);
  cid=getClusterId(config);
  assertTrue("ClusterId didn't match",cid.equals("mycluster"));
  StartupOption.FORMAT.setClusterId("");
  NameNode.format(config);
  String newCid=getClusterId(config);
  assertFalse("ClusterId should not be the same",newCid.equals(cid));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestCorruptFilesJsp </h4><pre class="type-16 type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testCorruptFilesJsp() throws Exception {
  MiniDFSCluster cluster=null;
  try {
    final int FILE_SIZE=512;
    Path[] filepaths={new Path("/audiobook"),new Path("/audio/audio1"),new Path("/audio/audio2"),new Path("/audio/audio")};
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    cluster=new MiniDFSCluster.Builder(conf).build();
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    for (    Path filepath : filepaths) {
      DFSTestUtil.createFile(fs,filepath,FILE_SIZE,(short)1,0L);
      DFSTestUtil.waitReplication(fs,filepath,(short)1);
    }
    final NameNode namenode=cluster.getNameNode();
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("There are " + badFiles.size() + " corrupt files, but expecting none",badFiles.size() == 0);
    URL url=new URL("http://" + conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY) + "/corrupt_files.jsp");
    String corruptFilesPage=DFSTestUtil.urlGet(url);
    assertTrue("Corrupt files page is not showing a healthy filesystem",corruptFilesPage.contains("No missing blocks found at the moment."));
    for (int idx=0; idx < filepaths.length - 1; idx++) {
      ExtendedBlock blk=DFSTestUtil.getFirstBlock(fs,filepaths[idx]);
      assertTrue(TestDatanodeBlockScanner.corruptReplica(blk,0));
      FSDataInputStream in=fs.open(filepaths[idx]);
      try {
        in.readFully(new byte[FILE_SIZE]);
      }
 catch (      ChecksumException ignored) {
      }
      in.close();
    }
    badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Expecting 3 corrupt files, but got " + badFiles.size(),badFiles.size() == 3);
    url=new URL("http://" + conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY) + "/corrupt_files.jsp");
    corruptFilesPage=DFSTestUtil.urlGet(url);
    assertTrue("'/audiobook' should be corrupt",corruptFilesPage.contains("/audiobook"));
    assertTrue("'/audio/audio1' should be corrupt",corruptFilesPage.contains("/audio/audio1"));
    assertTrue("'/audio/audio2' should be corrupt",corruptFilesPage.contains("/audio/audio2"));
    assertTrue("Summary message shall report 3 corrupt files",corruptFilesPage.contains("At least 3 corrupt file(s)"));
    for (    Path filepath : filepaths) {
      fs.delete(filepath,false);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testPreallocation() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
  File editLog=cluster.getNameNode().getFSImage().getEditLog().getFsEditName();
  assertEquals("Edit log should only be 4 bytes long",4,editLog.length());
  assertEquals("Edit log disk space used should be one block",4096,new DU(editLog,conf).getUsed());
  cluster.getFileSystem().mkdirs(new Path("/tmp"),new FsPermission((short)777));
  assertEquals("Edit log should be 1MB + 4 bytes long",(1024 * 1024) + 4,editLog.length());
  assertTrue("Edit log disk space used should be at least 257 blocks",257 * 4096 <= new DU(editLog,conf).getUsed());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestEditLogRace </h4><pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Most of the FSNamesystem methods have a synchronized section where they
 * update the name system itself and write to the edit log, and then
 * unsynchronized, they call logSync. This test verifies that, if an
 * operation has written to the edit log but not yet synced it,
 * we wait for that sync before entering safe mode.
 */
@Test public void testSaveRightBeforeSync() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=spy(fsimage.getEditLog());
    fsimage.editLog=editLog;
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterSync=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterSync.countDown();
        }
      }
    }
;
    Answer<Void> blockingSync=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("logSync called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it just before logSync...");
          waitToEnterSync.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to logSync. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("logSync complete");
        return null;
      }
    }
;
    doAnswer(blockingSync).when(editLog).logSync();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to just before logSync...");
    waitToEnterSync.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync about to be called.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since we have pending edits");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * The logSync() method in FSEditLog is unsynchronized whiel syncing
 * so that other threads can concurrently enqueue edits while the prior
 * sync is ongoing. This test checks that the log is saved correctly
 * if the saveImage occurs while the syncing thread is in the unsynchronized middle section.
 * This replicates the following manual test proposed by Konstantin:
 * I start the name-node in debugger.
 * I do -mkdir and stop the debugger in logSync() just before it does flush.
 * Then I enter safe mode with another client
 * I start saveNamepsace and stop the debugger in
 * FSImage.saveFSImage() -> FSEditLog.createEditLogFile()
 * -> EditLogFileOutputStream.create() ->
 * after truncating the file but before writing LAYOUT_VERSION into it.
 * Then I let logSync() run.
 * Then I terminate the name-node.
 * After that the name-node wont start, since the edits file is broken.
 */
@Test public void testSaveImageWhileSyncInProgress() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=fsimage.getEditLog();
    ArrayList<EditLogOutputStream> streams=editLog.getEditStreams();
    EditLogOutputStream spyElos=spy(streams.get(0));
    streams.set(0,spyElos);
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterFlush=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterFlush.countDown();
        }
      }
    }
;
    Answer<Void> blockingFlush=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("Flush called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it to flush section...");
          waitToEnterFlush.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to flush. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("Flush complete");
        return null;
      }
    }
;
    doAnswer(blockingFlush).when(spyElos).flush();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to enter flush...");
    waitToEnterFlush.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync is in unsynchronized section.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since flush will sleep that long");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDisplayRecentEditLogOpCodes() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  FileSystem fileSys=null;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  final FSEditLog editLog=fsimage.getEditLog();
  for (int i=0; i < 20; i++) {
    fileSys.mkdirs(new Path("/tmp/tmp" + i));
  }
  File editFile=editLog.getFsEditName();
  editLog.close();
  cluster.shutdown();
  long fileLen=editFile.length();
  RandomAccessFile rwf=new RandomAccessFile(editFile,"rw");
  rwf.seek(fileLen - 40);
  for (int i=0; i < 20; i++) {
    rwf.write(FSEditLogOpCodes.OP_DELETE.getOpCode());
  }
  rwf.close();
  String expectedErrorMessage="^Error replaying edit log at offset \\d+\n";
  expectedErrorMessage+="Recent opcode offsets: (\\d+\\s*){4}$";
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).build();
    fail("should not be able to start");
  }
 catch (  IOException e) {
    assertTrue("error message contains opcodes message",e.getMessage().matches(expectedErrorMessage));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestGetImageServlet </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void IsValidRequestorRejectsCorrectly() throws IOException {
  GetImageServlet gim=new GetImageServlet();
  assertFalse("isValidRequestor allowed a requestor despite no values being set",gim.isValidRequestor("not set",getConf()));
  verifyIsValidReqBehavior(gim,false,"isValidRequestor has allowed an invalid requestor: ");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat </h4><pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * test illegal args cases
 */
@Test public void testIllegalArg() throws IOException {
  long fileLen=blockSize * 3;
  Path parentDir=new Path("/parentTrg");
  assertTrue(dfs.mkdirs(parentDir));
  Path trg=new Path(parentDir,"trg");
  DFSTestUtil.createFile(dfs,trg,fileLen,REPL_FACTOR,1);
{
    Path dir1=new Path("/dir1");
    assertTrue(dfs.mkdirs(dir1));
    Path src=new Path(dir1,"src");
    DFSTestUtil.createFile(dfs,src,fileLen,REPL_FACTOR,1);
    try {
      dfs.concat(trg,new Path[]{src});
      fail("didn't fail for src and trg in different directories");
    }
 catch (    Exception e) {
    }
  }
  try {
    dfs.concat(trg,new Path[]{new Path("test1/a")});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
  try {
    dfs.concat(trg,new Path[]{});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that the concat operation is properly persisted in the
 * edit log, and properly replayed on restart.
 */
@Test public void testConcatInEditLog() throws Exception {
  final Path TEST_DIR=new Path("/testConcatInEditLog");
  final long FILE_LEN=blockSize;
  Path[] srcFiles=new Path[3];
  for (int i=0; i < srcFiles.length; i++) {
    Path path=new Path(TEST_DIR,"src-" + i);
    DFSTestUtil.createFile(dfs,path,FILE_LEN,REPL_FACTOR,1);
    srcFiles[i]=path;
  }
  Path targetFile=new Path(TEST_DIR,"target");
  DFSTestUtil.createFile(dfs,targetFile,FILE_LEN,REPL_FACTOR,1);
  dfs.concat(targetFile,srcFiles);
  assertTrue(dfs.exists(targetFile));
  FileStatus origStatus=dfs.getFileStatus(targetFile);
  cluster.restartNameNode(true);
  assertTrue(dfs.exists(targetFile));
  assertFalse(dfs.exists(srcFiles[0]));
  FileStatus statusAfterRestart=dfs.getFileStatus(targetFile);
  assertEquals(origStatus.getModificationTime(),statusAfterRestart.getModificationTime());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks </h4><pre class="type-16 type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testlistCorruptFileBlocks() throws Exception {
  Configuration conf=new Configuration();
  conf.setLong(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,1000);
  conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
  FileSystem fs=null;
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).build();
    cluster.waitActive();
    fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil("testGetCorruptFiles",3,1,1024);
    util.createFiles(fs,"/corruptData");
    final NameNode namenode=cluster.getNameNode();
    Collection<FSNamesystem.CorruptFileBlockInfo> corruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/corruptData",null);
    int numCorrupt=corruptFileBlocks.size();
    assertTrue(numCorrupt == 0);
    String bpid=cluster.getNamesystem().getBlockPoolId();
    for (int i=0; i < 4; i++) {
      for (int j=0; j <= 1; j++) {
        File storageDir=MiniDFSCluster.getStorageDir(i,j);
        File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
        File[] blocks=data_dir.listFiles();
        if (blocks == null)         continue;
        for (int idx=0; idx < blocks.length; idx++) {
          if (!blocks[idx].getName().startsWith("blk_")) {
            continue;
          }
          LOG.info("Deliberately removing file " + blocks[idx].getName());
          assertTrue("Cannot remove file.",blocks[idx].delete());
        }
      }
    }
    int count=0;
    corruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/corruptData",null);
    numCorrupt=corruptFileBlocks.size();
    while (numCorrupt < 3) {
      Thread.sleep(1000);
      corruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/corruptData",null);
      numCorrupt=corruptFileBlocks.size();
      count++;
      if (count > 30)       break;
    }
    LOG.info("Namenode has bad files. " + numCorrupt);
    assertTrue(numCorrupt == 3);
    FSNamesystem.CorruptFileBlockInfo[] cfb=corruptFileBlocks.toArray(new FSNamesystem.CorruptFileBlockInfo[0]);
    Collection<FSNamesystem.CorruptFileBlockInfo> nextCorruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/corruptData",cfb[0].block.getBlockName());
    FSNamesystem.CorruptFileBlockInfo[] ncfb=nextCorruptFileBlocks.toArray(new FSNamesystem.CorruptFileBlockInfo[0]);
    numCorrupt=nextCorruptFileBlocks.size();
    assertTrue(numCorrupt == 2);
    assertTrue(ncfb[0].block.getBlockName().equalsIgnoreCase(cfb[1].block.getBlockName()));
    corruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/corruptData",ncfb[1].block.getBlockName());
    numCorrupt=corruptFileBlocks.size();
    assertTrue(numCorrupt == 0);
    util.createFiles(fs,"/goodData");
    corruptFileBlocks=namenode.getNamesystem().listCorruptFileBlocks("/goodData",null);
    numCorrupt=corruptFileBlocks.size();
    assertTrue(numCorrupt == 0);
    util.cleanup(fs,"/corruptData");
    util.cleanup(fs,"/goodData");
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Test if NN.listCorruptFiles() returns the right number of results.
 * Also, test that DFS.listCorruptFileBlocks can make multiple successive
 * calls.
 */
@Test public void testMaxCorruptFiles() throws Exception {
  MiniDFSCluster cluster=null;
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,15);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    final int maxCorruptFileBlocks=FSNamesystem.DEFAULT_MAX_CORRUPT_FILEBLOCKS_RETURNED;
    DFSTestUtil util=new DFSTestUtil("testMaxCorruptFiles",maxCorruptFileBlocks * 3,1,512);
    util.createFiles(fs,"/srcdat2",(short)1);
    util.waitReplication(fs,"/srcdat2",(short)1);
    final NameNode namenode=cluster.getNameNode();
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=namenode.getNamesystem().listCorruptFileBlocks("/srcdat2",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting none.",badFiles.size() == 0);
    final String bpid=cluster.getNamesystem().getBlockPoolId();
    for (int i=0; i < 4; i++) {
      for (int j=0; j <= 1; j++) {
        File storageDir=MiniDFSCluster.getStorageDir(i,j);
        File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
        LOG.info("Removing files from " + data_dir);
        File[] blocks=data_dir.listFiles();
        if (blocks == null)         continue;
        for (int idx=0; idx < blocks.length; idx++) {
          if (!blocks[idx].getName().startsWith("blk_")) {
            continue;
          }
          assertTrue("Cannot remove file.",blocks[idx].delete());
        }
      }
    }
    badFiles=namenode.getNamesystem().listCorruptFileBlocks("/srcdat2",null);
    while (badFiles.size() < maxCorruptFileBlocks) {
      LOG.info("# of corrupt files is: " + badFiles.size());
      Thread.sleep(10000);
      badFiles=namenode.getNamesystem().listCorruptFileBlocks("/srcdat2",null);
    }
    badFiles=namenode.getNamesystem().listCorruptFileBlocks("/srcdat2",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting "+ maxCorruptFileBlocks+ ".",badFiles.size() == maxCorruptFileBlocks);
    CorruptFileBlockIterator iter=(CorruptFileBlockIterator)fs.listCorruptFileBlocks(new Path("/srcdat2"));
    int corruptPaths=countPaths(iter);
    assertTrue("Expected more than " + maxCorruptFileBlocks + " corrupt file blocks but got "+ corruptPaths,corruptPaths > maxCorruptFileBlocks);
    assertTrue("Iterator should have made more than 1 call but made " + iter.getCallsMade(),iter.getCallsMade() > 1);
    util.cleanup(fs,"/srcdat2");
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * test listCorruptFileBlocks in DistributedFileSystem
 */
@Test public void testlistCorruptFileBlocksDFS() throws Exception {
  Configuration conf=new Configuration();
  conf.setLong(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,1000);
  conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
  FileSystem fs=null;
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).build();
    cluster.waitActive();
    fs=cluster.getFileSystem();
    DistributedFileSystem dfs=(DistributedFileSystem)fs;
    DFSTestUtil util=new DFSTestUtil("testGetCorruptFiles",3,1,1024);
    util.createFiles(fs,"/corruptData");
    RemoteIterator<Path> corruptFileBlocks=dfs.listCorruptFileBlocks(new Path("/corruptData"));
    int numCorrupt=countPaths(corruptFileBlocks);
    assertTrue(numCorrupt == 0);
    String bpid=cluster.getNamesystem().getBlockPoolId();
    for (int i=0; i < 2; i++) {
      File storageDir=MiniDFSCluster.getStorageDir(0,i);
      File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
      File[] blocks=data_dir.listFiles();
      if (blocks == null)       continue;
      for (int idx=0; idx < blocks.length; idx++) {
        if (!blocks[idx].getName().startsWith("blk_")) {
          continue;
        }
        LOG.info("Deliberately removing file " + blocks[idx].getName());
        assertTrue("Cannot remove file.",blocks[idx].delete());
      }
    }
    int count=0;
    corruptFileBlocks=dfs.listCorruptFileBlocks(new Path("/corruptData"));
    numCorrupt=countPaths(corruptFileBlocks);
    while (numCorrupt < 3) {
      Thread.sleep(1000);
      corruptFileBlocks=dfs.listCorruptFileBlocks(new Path("/corruptData"));
      numCorrupt=countPaths(corruptFileBlocks);
      count++;
      if (count > 30)       break;
    }
    LOG.info("Namenode has bad files. " + numCorrupt);
    assertTrue(numCorrupt == 3);
    util.cleanup(fs,"/corruptData");
    util.cleanup(fs,"/goodData");
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-12 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * check if nn.getCorruptFiles() returns a file that has corrupted blocks 
 */
@Test public void testListCorruptFilesCorruptedBlock() throws Exception {
  MiniDFSCluster cluster=null;
  Random random=new Random();
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil("testCorruptFilesCorruptedBlock",2,1,512);
    util.createFiles(fs,"/srcdat10");
    final NameNode namenode=cluster.getNameNode();
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting None.",badFiles.size() == 0);
    String bpid=cluster.getNamesystem().getBlockPoolId();
    File storageDir=MiniDFSCluster.getStorageDir(0,1);
    File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
    assertTrue("data directory does not exist",data_dir.exists());
    File[] blocks=data_dir.listFiles();
    assertTrue("Blocks do not exist in data-dir",(blocks != null) && (blocks.length > 0));
    for (int idx=0; idx < blocks.length; idx++) {
      if (blocks[idx].getName().startsWith("blk_") && blocks[idx].getName().endsWith(".meta")) {
        RandomAccessFile file=new RandomAccessFile(blocks[idx],"rw");
        FileChannel channel=file.getChannel();
        long position=channel.size() - 2;
        int length=2;
        byte[] buffer=new byte[length];
        random.nextBytes(buffer);
        channel.write(ByteBuffer.wrap(buffer),position);
        file.close();
        LOG.info("Deliberately corrupting file " + blocks[idx].getName() + " at offset "+ position+ " length "+ length);
        try {
          util.checkFiles(fs,"/srcdat10");
        }
 catch (        BlockMissingException e) {
          System.out.println("Received BlockMissingException as expected.");
        }
catch (        IOException e) {
          assertTrue("Corrupted replicas not handled properly. Expecting BlockMissingException " + " but received IOException " + e,false);
        }
        break;
      }
    }
    badFiles=namenode.getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    util.cleanup(fs,"/srcdat10");
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-10 type-12 type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Check that listCorruptFileBlocks works while the namenode is still in safemode.
 */
@Test public void testListCorruptFileBlocksInSafeMode() throws Exception {
  MiniDFSCluster cluster=null;
  Random random=new Random();
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY,1.5f);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_REPL_QUEUE_THRESHOLD_PCT_KEY,0f);
    cluster=new MiniDFSCluster.Builder(conf).waitSafeMode(false).build();
    cluster.getNameNode().setSafeMode(FSConstants.SafeModeAction.SAFEMODE_LEAVE);
    FileSystem fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil("testListCorruptFileBlocksInSafeMode",2,1,512);
    util.createFiles(fs,"/srcdat10");
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting None.",badFiles.size() == 0);
    File storageDir=MiniDFSCluster.getStorageDir(0,0);
    File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,cluster.getNamesystem().getBlockPoolId());
    assertTrue("data directory does not exist",data_dir.exists());
    File[] blocks=data_dir.listFiles();
    assertTrue("Blocks do not exist in data-dir",(blocks != null) && (blocks.length > 0));
    for (int idx=0; idx < blocks.length; idx++) {
      if (blocks[idx].getName().startsWith("blk_") && blocks[idx].getName().endsWith(".meta")) {
        RandomAccessFile file=new RandomAccessFile(blocks[idx],"rw");
        FileChannel channel=file.getChannel();
        long position=channel.size() - 2;
        int length=2;
        byte[] buffer=new byte[length];
        random.nextBytes(buffer);
        channel.write(ByteBuffer.wrap(buffer),position);
        file.close();
        LOG.info("Deliberately corrupting file " + blocks[idx].getName() + " at offset "+ position+ " length "+ length);
        try {
          util.checkFiles(fs,"/srcdat10");
        }
 catch (        BlockMissingException e) {
          System.out.println("Received BlockMissingException as expected.");
        }
catch (        IOException e) {
          assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
        }
        break;
      }
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    cluster.restartNameNode(0);
    fs=cluster.getFileSystem();
    while (!cluster.getNameNode().namesystem.isPopulatingReplQueues()) {
      try {
        LOG.info("waiting for replication queues");
        Thread.sleep(1000);
      }
 catch (      InterruptedException ignore) {
      }
    }
    try {
      util.checkFiles(fs,"/srcdat10");
    }
 catch (    BlockMissingException e) {
      System.out.println("Received BlockMissingException as expected.");
    }
catch (    IOException e) {
      assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    assertTrue("Namenode is not in safe mode",cluster.getNameNode().isInSafeMode());
    cluster.getNameNode().setSafeMode(FSConstants.SafeModeAction.SAFEMODE_LEAVE);
    util.cleanup(fs,"/srcdat10");
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestMetaSave </h4><pre class="type-10 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Tests metasave
 */
@Test public void testMetaSave() throws IOException, InterruptedException {
  final FSNamesystem namesystem=cluster.getNamesystem();
  for (int i=0; i < 2; i++) {
    Path file=new Path("/filestatus" + i);
    createFile(fileSys,file);
  }
  cluster.stopDataNode(1);
  Thread.sleep(15000);
  namesystem.setReplication("/filestatus0",(short)4);
  namesystem.metaSave("metasave.out.txt");
  String logFile=System.getProperty("hadoop.log.dir") + "/" + "metasave.out.txt";
  FileInputStream fstream=new FileInputStream(logFile);
  DataInputStream in=new DataInputStream(fstream);
  BufferedReader reader=new BufferedReader(new InputStreamReader(in));
  String line=reader.readLine();
  assertTrue(line.equals("3 files and directories, 2 blocks = 5 total"));
  line=reader.readLine();
  assertTrue(line.equals("Live Datanodes: 1"));
  line=reader.readLine();
  assertTrue(line.equals("Dead Datanodes: 1"));
  line=reader.readLine();
  line=reader.readLine();
  assertTrue(line.matches("^/filestatus[01]:.*"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNNLeaseRecovery </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCommitBlockSynchronization_EqualRecoveryID() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  long recoveryId=2002;
  long newSize=273487234;
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,true);
  BlockInfo lastBlock=fsn.dir.getFileINode(anyString()).getLastBlock();
  when(((BlockInfoUnderConstruction)lastBlock).getBlockRecoveryId()).thenReturn(recoveryId);
  boolean recoveryChecked=false;
  try {
    fsn.commitBlockSynchronization(fsn.getExtendedBlock(lastBlock),recoveryId,newSize,true,false,new DatanodeID[1]);
  }
 catch (  NullPointerException ioe) {
    LOG.info("Exception ",ioe);
    recoveryChecked=true;
  }
  assertTrue("commitBlockSynchronization had to throw NPE here",recoveryChecked);
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCommitBlockSynchronization_notUR() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  long recoveryId=2002;
  long newSize=273487234;
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.COMPLETE,file,dnd,ps,true);
  BlockInfo lastBlock=fsn.dir.getFileINode(anyString()).getLastBlock();
  when(lastBlock.isComplete()).thenReturn(true);
  try {
    fsn.commitBlockSynchronization(fsn.getExtendedBlock(lastBlock),recoveryId,newSize,true,false,new DatanodeID[1]);
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().startsWith("Unexpected block (="));
  }
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file with 0 blocks
 * and invokes lease recovery method. 
 */
@Test public void testInternalReleaseLease_0blocks() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(0,null,null,file,dnd,ps,false);
  assertTrue("True has to be returned in this case",releaseLease(fsn,lm,file));
}

</code></pre>

<br>
<pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of FSNamesystem
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (fsn != null) {
    try {
      fsn.close();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(NAME_DIR);
      if (dir != null)       assertTrue("Cannot delete name-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file, sets status of last two
 * blocks to COMMITTED and UNDER_CONSTRUCTION and invokes lease recovery
 * method. <code>false</code> is expected as the result
 * @throws IOException in case of an error
 */
@Test public void testInternalReleaseLease_COMM_CONSTRUCTION() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,false);
  assertFalse("False is expected in return in this case",releaseLease(fsn,lm,file));
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCommitBlockSynchronization_WrongGreaterRecoveryID() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  long recoveryId=2002;
  long newSize=273487234;
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,true);
  BlockInfo lastBlock=fsn.dir.getFileINode(anyString()).getLastBlock();
  when(((BlockInfoUnderConstruction)lastBlock).getBlockRecoveryId()).thenReturn(recoveryId - 100);
  try {
    fsn.commitBlockSynchronization(fsn.getExtendedBlock(lastBlock),recoveryId,newSize,true,false,new DatanodeID[1]);
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().startsWith("The recovery id " + recoveryId + " does not match current recovery id "+ (recoveryId - 100)));
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file and invokes lease recovery
 * method. 
 * @throws IOException in case of an error
 */
@Test public void testInternalReleaseLease_allCOMPLETE() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  fsn.dir.addFile(file.toString(),ps,(short)3,1l,"test","test-machine",dnd,1001l);
  assertTrue("True has to be returned in this case",releaseLease(fsn,lm,file));
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCommitBlockSynchronization_BlockNotFound() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  long recoveryId=2002;
  long newSize=273487234;
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,false);
  BlockInfo lastBlock=fsn.dir.getFileINode(anyString()).getLastBlock();
  try {
    fsn.commitBlockSynchronization(fsn.getExtendedBlock(lastBlock),recoveryId,newSize,true,false,new DatanodeID[1]);
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().startsWith("Block (="));
  }
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testCommitBlockSynchronization_WrongLesserRecoveryID() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  long recoveryId=2002;
  long newSize=273487234;
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,true);
  BlockInfo lastBlock=fsn.dir.getFileINode(anyString()).getLastBlock();
  when(((BlockInfoUnderConstruction)lastBlock).getBlockRecoveryId()).thenReturn(recoveryId + 100);
  try {
    fsn.commitBlockSynchronization(fsn.getExtendedBlock(lastBlock),recoveryId,newSize,true,false,new DatanodeID[1]);
  }
 catch (  IOException ioe) {
    assertTrue(ioe.getMessage().startsWith("The recovery id " + recoveryId + " does not match current recovery id "+ (recoveryId + 100)));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNameCache </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDictionary() throws Exception {
  NameCache<String> cache=new NameCache<String>(2);
  String[] matching={"part1","part10000000","fileabc","abc","filepart"};
  String[] notMatching={"spart1","apart","abcd","def"};
  for (  String s : matching) {
    cache.put(s);
    assertTrue(s == cache.put(s));
  }
  for (  String s : notMatching) {
    cache.put(s);
  }
  cache.initialized();
  for (  String s : matching) {
    verifyNameReuse(cache,s,true);
  }
  assertEquals(matching.length,cache.size());
  for (  String s : notMatching) {
    verifyNameReuse(cache,s,false);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNameNodeJspHelper </h4><pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void tesSecurityModeText(){
  conf.set(DFSConfigKeys.HADOOP_SECURITY_AUTHENTICATION,"kerberos");
  UserGroupInformation.setConfiguration(conf);
  String securityOnOff=NamenodeJspHelper.getSecurityModeText();
  Assert.assertTrue("security mode doesn't match. Should be ON",securityOnOff.contains("ON"));
  conf.set(DFSConfigKeys.HADOOP_SECURITY_AUTHENTICATION,"simple");
  UserGroupInformation.setConfiguration(conf);
  securityOnOff=NamenodeJspHelper.getSecurityModeText();
  Assert.assertTrue("security mode doesn't match. Should be OFF",securityOnOff.contains("OFF"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Tests that hasAvailableDiskSpace returns true if disk usage is below
 * threshold.
 * @throws IOException in case of errors
 */
@Test public void testCheckAvailability() throws IOException {
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_DU_RESERVED_KEY,0);
  NameNodeResourceChecker nb=new NameNodeResourceChecker(conf);
  assertTrue("isResourceAvailable must return true if " + "disk usage is lower than threshold",nb.hasAvailableDiskSpace());
}

</code></pre>

<br>
<pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Tests that NameNode resource monitor causes the NN to enter safe mode when
 * resources are low.
 * @throws IOException in case of errors
 * @throws InterruptedException 
 */
@Test public void testCheckThatNameNodeResourceMonitorIsRunning() throws IOException, InterruptedException {
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameDir.getAbsolutePath());
    conf.setLong(DFSConfigKeys.DFS_NAMENODE_RESOURCE_CHECK_INTERVAL_KEY,1);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    NameNodeResourceChecker mockResourceChecker=Mockito.mock(NameNodeResourceChecker.class);
    Mockito.when(mockResourceChecker.hasAvailableDiskSpace()).thenReturn(true);
    cluster.getNameNode().getNamesystem().nnResourceChecker=mockResourceChecker;
    cluster.waitActive();
    String name=NameNodeResourceMonitor.class.getName();
    boolean isNameNodeMonitorRunning=false;
    Set<Thread> runningThreads=Thread.getAllStackTraces().keySet();
    for (    Thread runningThread : runningThreads) {
      if (runningThread.toString().startsWith("Thread[" + name)) {
        isNameNodeMonitorRunning=true;
        break;
      }
    }
    assertTrue("NN resource monitor should be running",isNameNodeMonitorRunning);
    assertFalse("NN should not presently be in safe mode",cluster.getNameNode().isInSafeMode());
    Mockito.when(mockResourceChecker.hasAvailableDiskSpace()).thenReturn(false);
    long startMillis=System.currentTimeMillis();
    while (!cluster.getNameNode().isInSafeMode() && System.currentTimeMillis() < startMillis + (60 * 1000)) {
      Thread.sleep(1000);
    }
    assertTrue("NN should be in safe mode after resources crossed threshold",cluster.getNameNode().isInSafeMode());
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Tests that hasAvailableDiskSpace returns false if disk usage is above
 * threshold.
 * @throws IOException in case of errors
 */
@Test public void testCheckAvailabilityNeg() throws IOException {
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_DU_RESERVED_KEY,Long.MAX_VALUE);
  NameNodeResourceChecker nb=new NameNodeResourceChecker(conf);
  assertFalse("isResourceAvailable must return false if " + "disk usage is higher than threshold",nb.hasAvailableDiskSpace());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestSafeMode </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Verify that the NameNode stays in safemode when dfs.safemode.datanode.min
 * is set to a number greater than the number of live datanodes.
 */
@Test public void testDatanodeThreshold() throws IOException {
  MiniDFSCluster cluster=null;
  DistributedFileSystem fs=null;
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_EXTENSION_KEY,0);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_MIN_DATANODES_KEY,1);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).format(true).build();
    cluster.waitActive();
    fs=(DistributedFileSystem)cluster.getFileSystem();
    assertTrue("No datanode started, but we require one - safemode expected",fs.setSafeMode(SafeModeAction.SAFEMODE_GET));
    String tipMsg=cluster.getNamesystem().getSafeModeTip();
    assertTrue("Safemode tip message looks right",tipMsg.contains("The number of live datanodes 0 needs an " + "additional 1 live"));
    cluster.startDataNodes(conf,1,true,null,null);
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException ignored) {
    }
    assertFalse("Out of safe mode after starting datanode.",fs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  }
  finally {
    if (fs != null)     fs.close();
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace </h4><pre class="type-10 type-8 type-9 type-17 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies values related to public fields.
"></span><br>
/** 
 * Verify that a saveNamespace command brings faulty directories
 * in fs.name.dir and fs.edit.dir back online.
 */
@Test public void testReinsertnamedirsInSavenamespace() throws Exception {
  Configuration conf=getConf();
  conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_RESTORE_KEY,true);
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  FSNamesystem fsn=new FSNamesystem(conf);
  FSImage originalImage=fsn.dir.fsImage;
  NNStorage storage=originalImage.getStorage();
  storage.close();
  NNStorage spyStorage=spy(storage);
  originalImage.storage=spyStorage;
  FSImage spyImage=spy(originalImage);
  fsn.dir.fsImage=spyImage;
  spyImage.getStorage().setStorageDirectories(FSNamesystem.getNamespaceDirs(conf),FSNamesystem.getNamespaceEditsDirs(conf));
  doAnswer(new FaultySaveImage(false)).when(spyImage).saveFSImage((File)anyObject());
  try {
    doAnEdit(fsn,1);
    fsn.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    LOG.info("Doing the first savenamespace.");
    fsn.saveNamespace();
    LOG.warn("First savenamespace sucessful.");
    assertTrue("Savenamespace should have marked one directory as bad." + " But found " + spyStorage.getRemovedStorageDirs().size() + " bad directories.",spyStorage.getRemovedStorageDirs().size() == 1);
    LOG.info("Doing the second savenamespace.");
    fsn.saveNamespace();
    LOG.warn("Second savenamespace sucessful.");
    assertTrue("Savenamespace should have been successful in removing " + " bad directories from Image." + " But found " + storage.getRemovedStorageDirs().size() + " bad directories.",storage.getRemovedStorageDirs().size() == 0);
    LOG.info("Shutting down fsimage.");
    originalImage.close();
    fsn.close();
    fsn=null;
    LOG.info("Loading new FSmage from disk.");
    fsn=new FSNamesystem(conf);
    LOG.info("Checking reloaded image.");
    checkEditExists(fsn,1);
    LOG.info("Reloaded image is good.");
  }
  finally {
    if (fsn != null) {
      fsn.close();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestStartupOptionUpgrade </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Tests the upgrade from version 0.20.204 to Federation version Test without
 * clusterid the case: -upgrade 
 * Expected to generate clusterid
 * @throws Exception
 */
@Test public void testStartupOptUpgradeFrom204() throws Exception {
  layoutVersion=Feature.RESERVED_REL20_204.getLayoutVersion();
  storage.processStartupOptionsForUpgrade(startOpt,layoutVersion);
  Assert.assertTrue("Clusterid should start with CID",storage.getClusterID().startsWith("CID"));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Regression test for HDFS-1997. Test that, if an exception
 * occurs on the client side, it is properly reported as such
 */
@Test public void testClientSideException() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
  try {
    String fsName=NameNode.getHostPortString(cluster.getNameNode().getHttpAddress());
    String id="getimage=1";
    File[] localPath=new File[]{new File("/xxxxx-does-not-exist/blah")};
    TransferFsImage.getFileClient(fsName,id,localPath,false);
    fail("Didn't get an exception!");
  }
 catch (  IOException ioe) {
    assertTrue("Expected FNFE, got: " + StringUtils.stringifyException(ioe),ioe instanceof FileNotFoundException);
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.tools.TestGetConf </h4><pre class="type-10 type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
"></span><br>
/** 
 * Test invalid argument to the tool
 */
@Test public void testInvalidArgument() throws Exception {
  HdfsConfiguration conf=new HdfsConfiguration();
  String[] args={"-invalidArgument"};
  String ret=runTool(conf,args,false);
  assertTrue(ret.contains(GetConf.USAGE));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer </h4><pre class="type-8 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
"></span><br>
/** 
 * Test the OfflineEditsViewer
 */
@Test public void testGenerated() throws IOException {
  LOG.info("START - testing with generated edits");
  nnHelper.startCluster(buildDir + "/dfs/");
  String edits=nnHelper.generateEdits();
  String editsParsedXml=cacheDir + "/editsParsed.xml";
  String editsReparsed=cacheDir + "/editsReparsed";
  runOev(edits,editsParsedXml,"xml");
  runOev(editsParsedXml,editsReparsed,"binary");
  assertTrue("Edits " + edits + " should have all op codes",hasAllOpCodes(edits));
  assertTrue("Generated edits and reparsed (bin to XML to bin) should be same",filesEqualIgnoreTrailingZeros(edits,editsReparsed));
  nnHelper.shutdownCluster();
  LOG.info("END");
}

</code></pre>

<br>
<pre class="type-8 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
"></span><br>
@Test public void testStored() throws IOException {
  LOG.info("START - testing with stored reference edits");
  String editsStored=cacheDir + "/editsStored";
  String editsStoredParsedXml=cacheDir + "/editsStoredParsed.xml";
  String editsStoredReparsed=cacheDir + "/editsStoredReparsed";
  String editsStoredXml=cacheDir + "/editsStored.xml";
  runOev(editsStored,editsStoredParsedXml,"xml");
  runOev(editsStoredParsedXml,editsStoredReparsed,"binary");
  assertTrue("Edits " + editsStored + " should have all op codes",hasAllOpCodes(editsStored));
  assertTrue("Reference XML edits and parsed to XML should be same",filesEqual(editsStoredXml,editsStoredParsedXml));
  assertTrue("Reference edits and reparsed (bin to XML to bin) should be same",filesEqualIgnoreTrailingZeros(editsStored,editsStoredReparsed));
  LOG.info("END");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.util.TestExactSizeInputStream </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMark() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertFalse(s.markSupported());
  try {
    s.mark(1);
    fail("Mark should not succeed");
  }
 catch (  UnsupportedOperationException uoe) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.security.TestRefreshUserMappings </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGroupMappingRefresh() throws Exception {
  DFSAdmin admin=new DFSAdmin(config);
  String[] args=new String[]{"-refreshUserToGroupsMappings"};
  Groups groups=Groups.getUserToGroupsMappingService(config);
  String user=UserGroupInformation.getCurrentUser().getUserName();
  System.out.println("first attempt:");
  List<String> g1=groups.getGroups(user);
  String[] str_groups=new String[g1.size()];
  g1.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  System.out.println("second attempt, should be same:");
  List<String> g2=groups.getGroups(user);
  g2.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g2.size(); i++) {
    assertEquals("Should be same group ",g1.get(i),g2.get(i));
  }
  admin.run(args);
  System.out.println("third attempt(after refresh command), should be different:");
  List<String> g3=groups.getGroups(user);
  g3.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g3.size(); i++) {
    assertFalse("Should be different group: " + g1.get(i) + " and "+ g3.get(i),g1.get(i).equals(g3.get(i)));
  }
  Thread.sleep(groupRefreshTimeoutSec * 1100);
  System.out.println("fourth attempt(after timeout), should be different:");
  List<String> g4=groups.getGroups(user);
  g4.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g4.size(); i++) {
    assertFalse("Should be different group ",g3.get(i).equals(g4.get(i)));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.TestDelegationTokenFetcher </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Verify that when the DelegationTokenFetcher runs, it talks to the Namenode,
 * pulls out the correct user's token and successfully serializes it to disk.
 */
@Test public void expectedTokenIsRetrievedFromDFS() throws Exception {
  final byte[] ident=new DelegationTokenIdentifier(new Text("owner"),new Text("renewer"),new Text("realuser")).getBytes();
  final byte[] pw=new byte[]{42};
  final Text kind=new Text("MY-KIND");
  final Text service=new Text(uri.toString());
  Token<DelegationTokenIdentifier> t=new Token<DelegationTokenIdentifier>(ident,pw,kind,service);
  when(dfs.getDelegationToken((String)null)).thenReturn(t);
  when(dfs.renewDelegationToken(eq(t))).thenReturn(1000L);
  when(dfs.getUri()).thenReturn(uri);
  FileSystem fileSys=FileSystem.getLocal(conf);
  try {
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),tokenFile});
    Path p=new Path(fileSys.getWorkingDirectory(),tokenFile);
    Credentials creds=Credentials.readTokenStorageFile(p,conf);
    Iterator<Token<?>> itr=creds.getAllTokens().iterator();
    assertTrue(itr.hasNext());
    assertEquals(t,itr.next());
    assertTrue(!itr.hasNext());
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--print",tokenFile});
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--renew",tokenFile});
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--cancel",tokenFile});
    verify(dfs).renewDelegationToken(eq(t));
    verify(dfs).cancelDelegationToken(eq(t));
  }
  finally {
    fileSys.delete(new Path(tokenFile),true);
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

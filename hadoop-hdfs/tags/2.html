<h3><span class=" glyphicon glyphicon-tag"/>&nbspHybridVerifier</h3><kbd>Contains more than 2 JUnit-based stereotypes</kbd><br><br><br><h4 style="margin:0px">Class: TestFuseDFS </h4><pre class="type-3 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test concurrent creation and access of the mount 
 */
@Test public void testMultipleThreads() throws IOException {
  ArrayList<Thread> threads=new ArrayList<Thread>();
  final AtomicReference<String> errorMessage=new AtomicReference<String>();
  for (int i=0; i < 10; i++) {
    Thread t=new Thread(){
      public void run(){
        try {
          File d=new File(mountPoint,"dir" + getId());
          execWaitRet("mkdir " + d.getAbsolutePath());
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            final String contents="thread " + getId() + " "+ j;
            createFile(f,contents);
          }
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            execWaitRet("cat " + f.getAbsolutePath());
            execWaitRet("rm " + f.getAbsolutePath());
          }
          execWaitRet("rmdir " + d.getAbsolutePath());
        }
 catch (        IOException ie) {
          errorMessage.set(String.format("Exception %s",StringUtils.stringifyException(ie)));
        }
      }
    }
;
    t.start();
    threads.add(t);
  }
  for (  Thread t : threads) {
    try {
      t.join();
    }
 catch (    InterruptedException ie) {
      fail("Thread interrupted: " + ie.getMessage());
    }
  }
  assertNull(errorMessage.get(),errorMessage.get());
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test random access to a file 
 */
@Test public void testRandomAccess() throws IOException {
  final String contents="hello world";
  File f=new File(mountPoint,"file1");
  createFile(f,contents);
  RandomAccessFile raf=new RandomAccessFile(f,"rw");
  raf.seek(f.length());
  try {
    raf.write('b');
  }
 catch (  IOException e) {
    assertEquals("Operation not supported",e.getMessage());
  }
 finally {
    raf.close();
  }
  raf=new RandomAccessFile(f,"rw");
  raf.seek(0);
  try {
    raf.write('b');
    fail("Over-wrote existing bytes");
  }
 catch (  IOException e) {
    assertEquals("Invalid argument",e.getMessage());
  }
 finally {
    raf.close();
  }
  execAssertSucceeds("rm " + f.getAbsolutePath());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.cli.TestHDFSCLI </h4><pre class="type-10 type-7 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Allocates resources before the execution of the test cases
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before @Override public void setUp() throws Exception {
  super.setUp();
  conf.setClass(PolicyProvider.POLICY_PROVIDER_CONFIG,HDFSPolicyProvider.class,PolicyProvider.class);
  conf.setInt(DFSConfigKeys.DFS_REPLICATION_KEY,1);
  String[] racks={"/rack1","/rack1","/rack2","/rack2","/rack2","/rack3","/rack4","/rack4"};
  String[] hosts={"host1","host2","host3","host4","host5","host6","host7","host8"};
  dfsCluster=new MiniDFSCluster.Builder(conf).numDataNodes(8).racks(racks).hosts(hosts).build();
  dfsCluster.waitClusterUp();
  namenode=conf.get(DFSConfigKeys.FS_DEFAULT_NAME_KEY,"file:///");
  username=System.getProperty("user.name");
  fs=dfsCluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFcHdfsSymlink </h4><pre class="type-10 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testCreateLinkMaxPathLink() throws IOException {
  Path dir=new Path(testBaseDir1());
  Path file=new Path(testBaseDir1(),"file");
  final int maxPathLen=FSConstants.MAX_PATH_LENGTH;
  final int dirLen=dir.toString().length() + 1;
  int len=maxPathLen - dirLen;
  StringBuilder sb=new StringBuilder("");
  for (int i=0; i < (len / 10); i++) {
    sb.append("0123456789");
  }
  for (int i=0; i < (len % 10); i++) {
    sb.append("x");
  }
  Path link=new Path(sb.toString());
  assertEquals(maxPathLen,dirLen + link.toString().length());
  createAndWriteFile(file);
  fc.setWorkingDirectory(dir);
  fc.createSymlink(file,link,false);
  readFile(link);
  link=new Path(sb.toString() + "x");
  try {
    fc.createSymlink(file,link,false);
    fail("Path name should be too long");
  }
 catch (  IOException x) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFiListPath </h4><pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Remove the target directory after the getListing RPC 
 */
@Test public void testTargetDeletionForListStatus() throws Exception {
  LOG.info("Test Target Delete For listStatus");
  try {
    fs.listStatus(TEST_PATH);
    fail("Test should fail with FileNotFoundException");
  }
 catch (  FileNotFoundException e) {
    assertEquals("File " + TEST_PATH + " does not exist.",e.getMessage());
    LOG.info(StringUtils.stringifyException(e));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFiRename </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Rename test where both src and dst are files 
 */
@Test public void testDeletionOfDstFile() throws Exception {
  Path src=getTestPath("testDeletionOfDstFile/dir/src");
  Path dst=getTestPath("testDeletionOfDstFile/newdir/dst");
  createFile(src);
  createFile(dst);
  final FSNamesystem namesystem=cluster.getNamesystem();
  final long blocks=namesystem.getBlocksTotal();
  final long fileCount=namesystem.getFilesTotal();
  rename(src,dst,false,false,true,Rename.OVERWRITE);
  Assert.assertEquals(blocks - 1,namesystem.getBlocksTotal());
  Assert.assertEquals(fileCount - 1,namesystem.getFilesTotal());
  restartCluster(false);
  int count=0;
  boolean exception=true;
  src=getTestPath("testDeletionOfDstFile/dir/src");
  dst=getTestPath("testDeletionOfDstFile/newdir/dst");
  while (exception && count < 5) {
    try {
      exists(fc,src);
      exception=false;
    }
 catch (    Exception e) {
      LOG.warn("Exception " + " count " + count + " "+ e.getMessage());
      Thread.sleep(1000);
      count++;
    }
  }
  Assert.assertFalse(exists(fc,src));
  Assert.assertTrue(exists(fc,dst));
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Rename test where both src and dst are directories 
 */
@Test public void testDeletionOfDstDirectory() throws Exception {
  Path src=getTestPath("testDeletionOfDstDirectory/dir/src");
  Path dst=getTestPath("testDeletionOfDstDirectory/newdir/dst");
  fc.mkdir(src,FileContext.DEFAULT_PERM,true);
  fc.mkdir(dst,FileContext.DEFAULT_PERM,true);
  FSNamesystem namesystem=cluster.getNamesystem();
  long fileCount=namesystem.getFilesTotal();
  rename(src,dst,false,false,true,Rename.OVERWRITE);
  Assert.assertEquals(fileCount - 1,namesystem.getFilesTotal());
  restartCluster(false);
  src=getTestPath("testDeletionOfDstDirectory/dir/src");
  dst=getTestPath("testDeletionOfDstDirectory/newdir/dst");
  int count=0;
  boolean exception=true;
  while (exception && count < 5) {
    try {
      exists(fc,src);
      exception=false;
    }
 catch (    Exception e) {
      LOG.warn("Exception " + " count " + count + " "+ e.getMessage());
      Thread.sleep(1000);
      count++;
    }
  }
  Assert.assertFalse(exists(fc,src));
  Assert.assertTrue(exists(fc,dst));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestResolveHdfsSymlink </h4><pre class="type-12 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests resolution of an hdfs symlink to the local file system.
 * @throws IOException
 * @throws InterruptedException
 */
@Test public void testFcResolveAfs() throws IOException, InterruptedException {
  Configuration conf=new Configuration();
  FileContext fcLocal=FileContext.getLocalFSFileContext();
  FileContext fcHdfs=FileContext.getFileContext(cluster.getFileSystem().getUri());
  Path alphaLocalPath=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp/alpha");
  DFSTestUtil.createFile(FileSystem.getLocal(conf),alphaLocalPath,16,(short)1,2);
  Path linkTarget=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp");
  Path hdfsLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString(),"/tmp/link");
  fcHdfs.createSymlink(linkTarget,hdfsLink,true);
  Path alphaHdfsPathViaLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString() + "/tmp/link/alpha");
  Set<AbstractFileSystem> afsList=fcHdfs.resolveAbstractFileSystems(alphaHdfsPathViaLink);
  Assert.assertEquals(2,afsList.size());
  for (  AbstractFileSystem afs : afsList) {
    if ((!afs.equals(fcHdfs.getDefaultFileSystem())) && (!afs.equals(fcLocal.getDefaultFileSystem()))) {
      Assert.fail("Failed to resolve AFS correctly");
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGetNewStamp() throws IOException {
  int numDataNodes=1;
  Configuration conf=new HdfsConfiguration();
  conf.setBoolean("dfs.support.append",true);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
  try {
    cluster.waitActive();
    FileSystem fileSys=cluster.getFileSystem();
    NameNode namenode=cluster.getNameNode();
    Path file=new Path("dataprotocol.dat");
    DFSTestUtil.createFile(fileSys,file,1L,(short)numDataNodes,0L);
    ExtendedBlock firstBlock=DFSTestUtil.getFirstBlock(fileSys,file);
    try {
      namenode.updateBlockForPipeline(firstBlock,"");
      Assert.fail("Can not get a new GS from a finalized block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("is not under Construction"));
    }
    try {
      long newBlockId=firstBlock.getBlockId() + 1;
      ExtendedBlock newBlock=new ExtendedBlock(firstBlock.getBlockPoolId(),newBlockId,0,firstBlock.getGenerationStamp());
      namenode.updateBlockForPipeline(newBlock,"");
      Assert.fail("Cannot get a new GS from a non-existent block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("does not exist"));
    }
    DFSOutputStream out=null;
    try {
      out=(DFSOutputStream)(fileSys.append(file).getWrappedStream());
      out.write(1);
      out.hflush();
      FSDataInputStream in=null;
      try {
        in=fileSys.open(file);
        firstBlock=DFSTestUtil.getAllBlocks(in).get(0).getBlock();
      }
  finally {
        IOUtils.closeStream(in);
      }
      DFSClient dfs=((DistributedFileSystem)fileSys).dfs;
      try {
        namenode.updateBlockForPipeline(firstBlock,"test" + dfs.clientName);
        Assert.fail("Cannot get a new GS for a non lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      try {
        namenode.updateBlockForPipeline(firstBlock,null);
        Assert.fail("Cannot get a new GS for a null lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      namenode.updateBlockForPipeline(firstBlock,dfs.clientName);
    }
  finally {
      IOUtils.closeStream(out);
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestConnCache </h4><pre class="type-10 type-8 type-9 type-13 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether two objects/variables are the same">IdentityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether two objects/variables are the same
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the SocketCache itself.
 */
@Test public void testSocketCache() throws IOException {
  final int CACHE_SIZE=4;
  SocketCache cache=new SocketCache(CACHE_SIZE);
  InetSocketAddress nnAddr=new InetSocketAddress("localhost",cluster.getNameNodePort());
  DFSClient client=new DFSClient(nnAddr,conf);
  LocatedBlock block=client.getNamenode().getBlockLocations(testFile.toString(),0,FILE_SIZE).getLocatedBlocks().get(0);
  DataNode dn=util.getDataNode(block);
  InetSocketAddress dnAddr=dn.getSelfAddr();
  Socket[] dnSockets=new Socket[CACHE_SIZE];
  for (int i=0; i < dnSockets.length; ++i) {
    dnSockets[i]=client.socketFactory.createSocket(dnAddr.getAddress(),dnAddr.getPort());
  }
  Socket nnSock=new Socket(nnAddr.getAddress(),nnAddr.getPort());
  cache.put(nnSock);
  assertSame("Read the write",nnSock,cache.get(nnAddr));
  cache.put(nnSock);
  for (  Socket dnSock : dnSockets) {
    cache.put(dnSock);
  }
  assertEquals("NN socket evicted",null,cache.get(nnAddr));
  assertTrue("Evicted socket closed",nnSock.isClosed());
  for (  Socket dnSock : dnSockets) {
    assertEquals("Retrieve cached sockets",dnSock,cache.get(dnAddr));
    dnSock.close();
  }
  assertEquals("Cache is empty",0,cache.size());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUpgrade </h4><pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test(expected=IOException.class) public void testUpgradeFromPreUpgradeLVFails() throws IOException {
  Storage.checkVersionUpgradable(Storage.LAST_PRE_UPGRADE_LAYOUT_VERSION + 1);
  fail("Expected IOException is not thrown");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUtil </h4><pre class="type-10 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test conversion of LocatedBlock to BlockLocation
 */
@Test public void testLocatedBlocks2Locations(){
  DatanodeInfo d=new DatanodeInfo();
  DatanodeInfo[] ds=new DatanodeInfo[1];
  ds[0]=d;
  ExtendedBlock b1=new ExtendedBlock("bpid",1,1,1);
  LocatedBlock l1=new LocatedBlock(b1,ds,0,false);
  ExtendedBlock b2=new ExtendedBlock("bpid",2,1,1);
  LocatedBlock l2=new LocatedBlock(b2,ds,0,true);
  List<LocatedBlock> ls=Arrays.asList(l1,l2);
  LocatedBlocks lbs=new LocatedBlocks(10,false,ls,l2,true);
  BlockLocation[] bs=DFSUtil.locatedBlocks2Locations(lbs);
  assertTrue("expected 2 blocks but got " + bs.length,bs.length == 2);
  int corruptCount=0;
  for (  BlockLocation b : bs) {
    if (b.isCorrupt()) {
      corruptCount++;
    }
  }
  assertTrue("expected 1 corrupt files but got " + corruptCount,corruptCount == 1);
  bs=DFSUtil.locatedBlocks2Locations(new LocatedBlocks());
  assertEquals(0,bs.length);
}

</code></pre>

<br>
<pre class="type-10 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test for{@link DFSUtil#getNameServiceIds(Configuration)}{@link DFSUtil#getNameServiceId(Configuration)}{@link DFSUtil#getNNServiceRpcAddresses(Configuration)}
 */
@Test public void testMultipleNamenodes() throws IOException {
  HdfsConfiguration conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"nn1,nn2");
  Collection<String> nameserviceIds=DFSUtil.getNameServiceIds(conf);
  Iterator<String> it=nameserviceIds.iterator();
  assertEquals(2,nameserviceIds.size());
  assertEquals("nn1",it.next().toString());
  assertEquals("nn2",it.next().toString());
  conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICE_ID,"nn1");
  assertEquals("nn1",DFSUtil.getNameServiceId(conf));
  final String NN1_ADDRESS="localhost:9000";
  final String NN2_ADDRESS="localhost:9001";
  final String NN3_ADDRESS="localhost:9002";
  conf.set(DFSUtil.getNameServiceIdKey(DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY,"nn1"),NN1_ADDRESS);
  conf.set(DFSUtil.getNameServiceIdKey(DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY,"nn2"),NN2_ADDRESS);
  Collection<InetSocketAddress> nnAddresses=DFSUtil.getNNServiceRpcAddresses(conf);
  assertEquals(2,nnAddresses.size());
  Iterator<InetSocketAddress> iterator=nnAddresses.iterator();
  assertEquals(2,nameserviceIds.size());
  InetSocketAddress addr=iterator.next();
  assertEquals("localhost",addr.getHostName());
  assertEquals(9000,addr.getPort());
  addr=iterator.next();
  assertEquals("localhost",addr.getHostName());
  assertEquals(9001,addr.getPort());
  InetSocketAddress testAddress1=NetUtils.createSocketAddr(NN1_ADDRESS);
  String nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress1,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertEquals("nn1",nameserviceId);
  InetSocketAddress testAddress2=NetUtils.createSocketAddr(NN2_ADDRESS);
  nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress2,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertEquals("nn2",nameserviceId);
  InetSocketAddress testAddress3=NetUtils.createSocketAddr(NN3_ADDRESS);
  nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress3,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertNull(nameserviceId);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDataTransferProtocol </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testPacketHeader() throws IOException {
  PacketHeader hdr=new PacketHeader(4,1024,100,false,4096);
  ByteArrayOutputStream baos=new ByteArrayOutputStream();
  hdr.write(new DataOutputStream(baos));
  PacketHeader readBack=new PacketHeader();
  ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray());
  readBack.readFields(new DataInputStream(bais));
  assertEquals(hdr,readBack);
  readBack=new PacketHeader();
  readBack.readFields(ByteBuffer.wrap(baos.toByteArray()));
  assertEquals(hdr,readBack);
  assertTrue(hdr.sanityCheck(99));
  assertFalse(hdr.sanityCheck(100));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDatanodeConfig </h4><pre class="type-10 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that a data-node does not start if configuration specifies
 * incorrect URI scheme in data directory.
 * Test that a data-node starts if data directory is specified as
 * URI = "file:///path" or as a non URI path.
 */
@Test public void testDataDirectories() throws IOException {
  File dataDir=new File(BASE_DIR,"data").getCanonicalFile();
  Configuration conf=cluster.getConfiguration(0);
  String dnDir=makeURI("shv",null,fileAsURI(dataDir).getPath());
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir);
  DataNode dn=null;
  try {
    dn=DataNode.createDataNode(new String[]{},conf);
  }
 catch (  IOException e) {
  }
  if (dn != null)   dn.shutdown();
  assertNull("Data-node startup should have failed.",dn);
  String dnDir1=fileAsURI(dataDir).toString() + "1";
  String dnDir2=makeURI("file","localhost",fileAsURI(dataDir).getPath() + "2");
  String dnDir3=dataDir.getAbsolutePath() + "3";
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir1 + "," + dnDir2+ ","+ dnDir3);
  cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
  assertTrue("Data-node should startup.",cluster.isDataNodeUp());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDistributedFileSystem </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDFSClient() throws Exception {
  Configuration conf=getTestConfiguration();
  final long grace=1000L;
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
    final String filepathstring="/test/LeaseChecker/foo";
    final Path[] filepaths=new Path[4];
    for (int i=0; i < filepaths.length; i++) {
      filepaths[i]=new Path(filepathstring + i);
    }
    final long millis=System.currentTimeMillis();
{
      DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      dfs.dfs.leaserenewer.setGraceSleepPeriod(grace);
      assertFalse(dfs.dfs.leaserenewer.isRunning());
{
        final FSDataOutputStream out=dfs.create(filepaths[0]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out.close();
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        for (int i=0; i < 3; i++) {
          if (dfs.dfs.leaserenewer.isRunning()) {
            Thread.sleep(grace / 2);
          }
        }
        assertFalse(dfs.dfs.leaserenewer.isRunning());
      }
{
        final FSDataOutputStream out1=dfs.create(filepaths[1]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        final FSDataOutputStream out2=dfs.create(filepaths[2]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out1.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out1.close();
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out2.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out2.close();
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
      }
{
        final FSDataOutputStream out3=dfs.create(filepaths[3]);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out3.writeLong(millis);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        out3.close();
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        Thread.sleep(grace / 4 * 3);
        assertTrue(dfs.dfs.leaserenewer.isRunning());
        for (int i=0; i < 3; i++) {
          if (dfs.dfs.leaserenewer.isRunning()) {
            Thread.sleep(grace / 2);
          }
        }
        assertFalse(dfs.dfs.leaserenewer.isRunning());
      }
      dfs.close();
    }
{
      FileSystem fs=cluster.getFileSystem();
      Path dir=new Path("/wrwelkj");
      assertFalse("File should not exist for test.",fs.exists(dir));
      try {
        FSDataInputStream in=fs.open(dir);
        try {
          in.close();
          fs.close();
        }
  finally {
          assertTrue("Did not get a FileNotFoundException for non-existing" + " file.",false);
        }
      }
 catch (      FileNotFoundException fnf) {
      }
    }
{
      DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      FSDataInputStream in=dfs.open(filepaths[0]);
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      assertEquals(millis,in.readLong());
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      in.close();
      assertFalse(dfs.dfs.leaserenewer.isRunning());
      dfs.close();
    }
{
      String uri="hdfs://127.0.0.1:" + cluster.getNameNodePort() + "/test/ipAddress/file";
      Path path=new Path(uri);
      FileSystem fs=FileSystem.get(path.toUri(),conf);
      FSDataOutputStream out=fs.create(path);
      byte[] buf=new byte[1024];
      out.write(buf);
      out.close();
      FSDataInputStream in=fs.open(path);
      in.readFully(buf);
      in.close();
      fs.close();
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-16 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFileChecksum() throws Exception {
  ((Log4JLogger)HftpFileSystem.LOG).getLogger().setLevel(Level.ALL);
  final long seed=RAN.nextLong();
  System.out.println("seed=" + seed);
  RAN.setSeed(seed);
  final Configuration conf=getTestConfiguration();
  conf.set(DFSConfigKeys.DFS_DATANODE_HOST_NAME_KEY,"localhost");
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem hdfs=cluster.getFileSystem();
  final String hftpuri="hftp://" + conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY);
  System.out.println("hftpuri=" + hftpuri);
  final FileSystem hftp=new Path(hftpuri).getFileSystem(conf);
  final String dir="/filechecksum";
  final int block_size=1024;
  final int buffer_size=conf.getInt("io.file.buffer.size",4096);
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,512);
  for (int n=0; n < 5; n++) {
    final byte[] data=new byte[RAN.nextInt(block_size / 2 - 1) + n * block_size + 1];
    RAN.nextBytes(data);
    System.out.println("data.length=" + data.length);
    final Path foo=new Path(dir,"foo" + n);
{
      final FSDataOutputStream out=hdfs.create(foo,false,buffer_size,(short)2,block_size);
      out.write(data);
      out.close();
    }
    final FileChecksum hdfsfoocs=hdfs.getFileChecksum(foo);
    System.out.println("hdfsfoocs=" + hdfsfoocs);
    final FileChecksum hftpfoocs=hftp.getFileChecksum(foo);
    System.out.println("hftpfoocs=" + hftpfoocs);
    final Path qualified=new Path(hftpuri + dir,"foo" + n);
    final FileChecksum qfoocs=hftp.getFileChecksum(qualified);
    System.out.println("qfoocs=" + qfoocs);
    final Path bar=new Path(dir,"bar" + n);
{
      final FSDataOutputStream out=hdfs.create(bar,false,buffer_size,(short)2,block_size);
      out.write(data);
      out.close();
    }
{
      final FileChecksum barcs=hdfs.getFileChecksum(bar);
      final int barhashcode=barcs.hashCode();
      assertEquals(hdfsfoocs.hashCode(),barhashcode);
      assertEquals(hdfsfoocs,barcs);
      assertEquals(hftpfoocs.hashCode(),barhashcode);
      assertEquals(hftpfoocs,barcs);
      assertEquals(qfoocs.hashCode(),barhashcode);
      assertEquals(qfoocs,barcs);
    }
{
      hdfs.setPermission(new Path(dir),new FsPermission((short)0));
      try {
        final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
        final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,conf,0,"somegroup");
        hftp2.getFileChecksum(qualified);
        fail();
      }
 catch (      IOException ioe) {
        FileSystem.LOG.info("GOOD: getting an exception",ioe);
      }
    }
  }
  cluster.shutdown();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend4 </h4><pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, recovers a file from another writer,
 * starts writing from that writer, and then has the old lease holder
 * call completeFile
 */
@Test(timeout=60000) public void testCompleteOtherLeaseHoldersFile() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testCompleteOtherLease");
    final OutputStream stm=client.create("/testCompleteOtherLease",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Opening file for append from new fs");
    FSDataOutputStream appenderStream=fs2.append(file1);
    LOG.info("Writing some data from new appender");
    AppendTestUtil.write(appenderStream,0,4096);
    LOG.info("Telling old close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("Lease mismatch"))     throw thrownByClose;
    appenderStream.close();
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, and then tries to recover
 * the lease from another thread.
 */
@Test(timeout=60000) public void testRecoverFinalizedBlock() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testRecoverFinalized");
    final OutputStream stm=client.create("/testRecoverFinalized",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Telling close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("No lease on /testRecoverFinalized"))     throw thrownByClose;
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileStatus </h4><pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test FileStatus objects obtained from a directory 
 */
@Test public void testGetFileStatusOnDir() throws Exception {
  Path dir=new Path("/test/mkdirs");
  assertTrue("mkdir failed",fs.mkdirs(dir));
  assertTrue("mkdir failed",fs.exists(dir));
  FileStatus status=fs.getFileStatus(dir);
  assertTrue(dir + " should be a directory",status.isDirectory());
  assertTrue(dir + " should be zero size ",status.getLen() == 0);
  assertEquals(dir.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
  FileStatus[] stats=fs.listStatus(dir);
  assertEquals(dir + " should be empty",0,stats.length);
  assertEquals(dir + " should be zero size ",0,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " should be zero size using hftp",0,hftpfs.getContentSummary(dir).getLength());
  RemoteIterator<FileStatus> itor=fc.listStatus(dir);
  assertFalse(dir + " should be empty",itor.hasNext());
  Path file2=new Path(dir,"filestatus2.dat");
  writeFile(fs,file2,1,blockSize / 4,blockSize);
  checkFile(fs,file2,1);
  status=fs.getFileStatus(file2);
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  file2=fs.makeQualified(file2);
  assertEquals(file2.toString(),status.getPath().toString());
  Path file3=new Path(dir,"filestatus3.dat");
  writeFile(fs,file3,1,blockSize / 4,blockSize);
  checkFile(fs,file3,1);
  file3=fs.makeQualified(file3);
  final int expected=blockSize / 2;
  assertEquals(dir + " size should be " + expected,expected,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " size should be " + expected+ " using hftp",expected,hftpfs.getContentSummary(dir).getLength());
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have two entries",2,stats.length);
  assertEquals(file2.toString(),stats[0].getPath().toString());
  assertEquals(file3.toString(),stats[1].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir3=fs.makeQualified(new Path(dir,"dir3"));
  fs.mkdirs(dir3);
  dir3=fs.makeQualified(dir3);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have three entries",3,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(file2.toString(),stats[1].getPath().toString());
  assertEquals(file3.toString(),stats[2].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir4=fs.makeQualified(new Path(dir,"dir4"));
  fs.mkdirs(dir4);
  dir4=fs.makeQualified(dir4);
  Path dir5=fs.makeQualified(new Path(dir,"dir5"));
  fs.mkdirs(dir5);
  dir5=fs.makeQualified(dir5);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have five entries",5,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(dir4.toString(),stats[1].getPath().toString());
  assertEquals(dir5.toString(),stats[2].getPath().toString());
  assertEquals(file2.toString(),stats[3].getPath().toString());
  assertEquals(file3.toString(),stats[4].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(dir4.toString(),itor.next().getPath().toString());
  assertEquals(dir5.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse(itor.hasNext());
{
    fs.setPermission(dir,new FsPermission((short)0));
    try {
      final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
      final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,conf,0,"somegroup");
      hftp2.getContentSummary(dir);
      fail();
    }
 catch (    IOException ioe) {
      FileSystem.LOG.info("GOOD: getting an exception",ioe);
    }
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the FileStatus obtained calling getFileStatus on a file 
 */
@Test public void testGetFileStatusOnFile() throws IOException {
  checkFile(fs,file1,1);
  FileStatus status=fs.getFileStatus(file1);
  assertFalse(file1 + " should be a file",status.isDirectory());
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  assertEquals(fileSize,status.getLen());
  assertEquals(file1.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
}

</code></pre>

<br>
<pre class="type-3 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test getting a FileStatus object using a non-existant path 
 */
@Test public void testGetFileStatusOnNonExistantFileDir() throws IOException {
  Path dir=new Path("/test/mkdirs");
  try {
    fs.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fc.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fs.getFileStatus(dir);
    fail("getFileStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertTrue("Exception doesn't indicate non-existant path",fe.getMessage().startsWith("File does not exist"));
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the FileStatus obtained calling listStatus on a file 
 */
@Test public void testListStatusOnFile() throws IOException {
  FileStatus[] stats=fs.listStatus(file1);
  assertEquals(1,stats.length);
  FileStatus status=stats[0];
  assertFalse(file1 + " should be a file",status.isDirectory());
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  assertEquals(fileSize,status.getLen());
  assertEquals(file1.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
  RemoteIterator<FileStatus> itor=fc.listStatus(file1);
  status=itor.next();
  assertEquals(stats[0],status);
  assertFalse(file1 + " should be a file",status.isDirectory());
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test calling getFileInfo directly on the client 
 */
@Test public void testGetFileInfo() throws IOException {
  Path path=new Path("/");
  assertTrue("/ should be a directory",fs.getFileStatus(path).isDirectory());
  HdfsFileStatus fileInfo=dfsClient.getFileInfo("/noSuchFile");
  assertEquals("Non-existant file should result in null",null,fileInfo);
  try {
    dfsClient.getFileInfo("non-absolute");
    fail("getFileInfo for a non-absolute path did not throw IOException");
  }
 catch (  RemoteException re) {
    assertTrue("Wrong exception for invalid file name",re.toString().contains("Invalid file name"));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLease </h4><pre class="type-10 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFactory() throws Exception {
  final String[] groups=new String[]{"supergroup"};
  final UserGroupInformation[] ugi=new UserGroupInformation[3];
  for (int i=0; i < ugi.length; i++) {
    ugi[i]=UserGroupInformation.createUserForTesting("user" + i,groups);
  }
  final Configuration conf=new Configuration();
  final DFSClient c1=createDFSClientAs(ugi[0],conf);
  final DFSClient c2=createDFSClientAs(ugi[0],conf);
  Assert.assertEquals(c1.leaserenewer,c2.leaserenewer);
  final DFSClient c3=createDFSClientAs(ugi[1],conf);
  Assert.assertTrue(c1.leaserenewer != c3.leaserenewer);
  final DFSClient c4=createDFSClientAs(ugi[1],conf);
  Assert.assertEquals(c3.leaserenewer,c4.leaserenewer);
  final DFSClient c5=createDFSClientAs(ugi[2],conf);
  Assert.assertTrue(c1.leaserenewer != c5.leaserenewer);
  Assert.assertTrue(c3.leaserenewer != c5.leaserenewer);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRecovery2 </h4><pre class="type-16 type-10 type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the soft lease expiration period to be short 1s. Thus triggering
 * soft lease expiration to happen immediately by having another client
 * trying to create the same file.
 * The test makes sure that the lease recovery completes.
 * @throws Exception
 */
@Test public void testSoftLeaseRecovery() throws Exception {
  Map<String,String[]> u2g_map=new HashMap<String,String[]>(1);
  u2g_map.put(fakeUsername,new String[]{fakeGroup});
  DFSTestUtil.updateConfWithFakeGroupMapping(conf,u2g_map);
  String filestr="/foo" + AppendTestUtil.nextInt();
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
{
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting(fakeUsername,new String[]{fakeGroup});
    FileSystem dfs2=DFSTestUtil.getFileSystemAs(ugi,conf);
    boolean done=false;
    for (int i=0; i < 10 && !done; i++) {
      AppendTestUtil.LOG.info("i=" + i);
      try {
        dfs2.create(filepath,false,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
        fail("Creation of an existing file should never succeed.");
      }
 catch (      FileAlreadyExistsException ex) {
        done=true;
      }
catch (      AlreadyBeingCreatedException ex) {
        AppendTestUtil.LOG.info("GOOD! got " + ex.getMessage());
      }
catch (      IOException ioe) {
        AppendTestUtil.LOG.warn("UNEXPECTED IOException",ioe);
      }
      if (!done) {
        AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
        try {
          Thread.sleep(5000);
        }
 catch (        InterruptedException e) {
        }
      }
    }
    assertTrue(done);
  }
  AppendTestUtil.LOG.info("Lease for file " + filepath + " is recovered. "+ "Validating its contents now...");
  long fileSize=dfs.getFileStatus(filepath).getLen();
  assertTrue("File should be " + size + " bytes, but is actually "+ " found to be "+ fileSize+ " bytes",fileSize == size);
  AppendTestUtil.LOG.info("File size is good. " + "Now validating data and sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the hard lease expiration period to be short 1s. Thus triggering
 * lease expiration to happen while the client is still alive.
 * The test makes sure that the lease recovery completes and the client
 * fails if it continues to write to the file.
 * @throws Exception
 */
@Test public void testHardLeaseRecovery() throws Exception {
  String filestr="/hardLeaseRecovery";
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
  LocatedBlocks locatedBlocks;
  do {
    Thread.sleep(SHORT_LEASE_PERIOD);
    locatedBlocks=DFSClient.callGetBlockLocations(dfs.dfs.namenode,filestr,0L,size);
  }
 while (locatedBlocks.isUnderConstruction());
  assertEquals(size,locatedBlocks.getFileLength());
  try {
    stm.write('b');
    stm.close();
    fail("Writer thread should have been killed");
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
  AppendTestUtil.LOG.info("File size is good. Now validating sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRenewer </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testThreadName() throws Exception {
  DFSOutputStream mockStream=Mockito.mock(DFSOutputStream.class);
  String filePath="/foo";
  Assert.assertFalse("Renewer not initially running",renewer.isRunning());
  Mockito.doReturn(false).when(MOCK_DFSCLIENT).isFilesBeingWrittenEmpty();
  renewer.put(filePath,mockStream,MOCK_DFSCLIENT);
  Assert.assertTrue("Renewer should have started running",renewer.isRunning());
  String threadName=renewer.getDaemonName();
  Assert.assertEquals("LeaseRenewer:myuser@hdfs://nn1/",threadName);
  Mockito.doReturn(true).when(MOCK_DFSCLIENT).isFilesBeingWrittenEmpty();
  renewer.closeFile(filePath,MOCK_DFSCLIENT);
  long failTime=System.currentTimeMillis() + 5000;
  while (renewer.isRunning() && System.currentTimeMillis() < failTime) {
    Thread.sleep(50);
  }
  Assert.assertFalse(renewer.isRunning());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestListFilesInFileContext </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input patch has a symbolic links as its children 
 */
@Test public void testSymbolicLinks() throws IOException {
  writeFile(fc,FILE1,FILE_LEN);
  writeFile(fc,FILE2,FILE_LEN);
  writeFile(fc,FILE3,FILE_LEN);
  Path dir4=new Path(TEST_DIR,"dir4");
  Path dir5=new Path(dir4,"dir5");
  Path file4=new Path(dir4,"file4");
  fc.createSymlink(DIR1,dir5,true);
  fc.createSymlink(FILE1,file4,true);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(dir4,true);
  LocatedFileStatus stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE3),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(dir4,false);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
}

</code></pre>

<br>
<pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input path is a file 
 */
@Test public void testFile() throws IOException {
  fc.mkdir(TEST_DIR,FsPermission.getDefault(),true);
  writeFile(fc,FILE1,FILE_LEN);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(FILE1,true);
  LocatedFileStatus stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  itor=fc.util().listFiles(FILE1,false);
  stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
}

</code></pre>

<br>
<pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test when input path is a directory 
 */
@Test public void testDirectory() throws IOException {
  fc.mkdir(DIR1,FsPermission.getDefault(),true);
  RemoteIterator<LocatedFileStatus> itor=fc.util().listFiles(DIR1,true);
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(DIR1,false);
  assertFalse(itor.hasNext());
  writeFile(fc,FILE2,FILE_LEN);
  itor=fc.util().listFiles(DIR1,true);
  LocatedFileStatus stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  itor=fc.util().listFiles(DIR1,false);
  stat=itor.next();
  assertFalse(itor.hasNext());
  assertTrue(stat.isFile());
  assertEquals(FILE_LEN,stat.getLen());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  assertEquals(1,stat.getBlockLocations().length);
  writeFile(fc,FILE1,FILE_LEN);
  writeFile(fc,FILE3,FILE_LEN);
  itor=fc.util().listFiles(TEST_DIR,true);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE2),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE3),stat.getPath());
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
  itor=fc.util().listFiles(TEST_DIR,false);
  stat=itor.next();
  assertTrue(stat.isFile());
  assertEquals(fc.makeQualified(FILE1),stat.getPath());
  assertFalse(itor.hasNext());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestPipelines </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Creates and closes a file of certain length.
 * Calls append to allow next write() operation to add to the end of it
 * After write() invocation, calls hflush() to make sure that data sunk through
 * the pipeline and check the state of the last block's replica.
 * It supposes to be in RBW state
 * @throws IOException in case of an error
 */
@Test public void pipeline_01() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + METHOD_NAME);
  }
  Path filePath=new Path("/" + METHOD_NAME + ".dat");
  DFSTestUtil.createFile(fs,filePath,FILE_SIZE,REPL_FACTOR,rand.nextLong());
  if (LOG.isDebugEnabled()) {
    LOG.debug("Invoking append but doing nothing otherwise...");
  }
  FSDataOutputStream ofs=fs.append(filePath);
  ofs.writeBytes("Some more stuff to write");
  ((DFSOutputStream)ofs.getWrappedStream()).hflush();
  List<LocatedBlock> lb=cluster.getNameNode().getBlockLocations(filePath.toString(),FILE_SIZE - 1,FILE_SIZE).getLocatedBlocks();
  String bpid=cluster.getNamesystem().getBlockPoolId();
  for (  DataNode dn : cluster.getDataNodes()) {
    Replica r=DataNodeAdapter.fetchReplicaInfo(dn,bpid,lb.get(0).getBlock().getBlockId());
    assertTrue("Replica on DN " + dn + " shouldn't be null",r != null);
    assertEquals("Should be RBW replica on " + dn + " after sequence of calls append()/write()/hflush()",HdfsConstants.ReplicaState.RBW,r.getState());
  }
  ofs.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestQuota </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test commands that change the size of the name space:
 * mkdirs, rename, and delete 
 */
@Test public void testNamespaceCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  try {
    assertTrue(dfs.mkdirs(new Path("/nqdir0/qdir1/qdir20/nqdir30")));
    final Path quotaDir1=new Path("/nqdir0/qdir1");
    dfs.setQuota(quotaDir1,6,FSConstants.QUOTA_DONT_SET);
    ContentSummary c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),6);
    final Path quotaDir2=new Path("/nqdir0/qdir1/qdir20");
    dfs.setQuota(quotaDir2,7,FSConstants.QUOTA_DONT_SET);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    final Path quotaDir3=new Path("/nqdir0/qdir1/qdir21");
    assertTrue(dfs.mkdirs(quotaDir3));
    dfs.setQuota(quotaDir3,2,FSConstants.QUOTA_DONT_SET);
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),2);
    Path tempPath=new Path(quotaDir3,"nqdir32");
    assertTrue(dfs.mkdirs(tempPath));
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),2);
    tempPath=new Path(quotaDir3,"nqdir33");
    boolean hasException=false;
    try {
      assertFalse(dfs.mkdirs(tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(quotaDir3);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),2);
    tempPath=new Path(quotaDir2,"nqdir31");
    assertTrue(dfs.mkdirs(tempPath));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
    tempPath=new Path(quotaDir2,"nqdir33");
    hasException=false;
    try {
      assertFalse(dfs.mkdirs(tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    tempPath=new Path(quotaDir2,"nqdir30");
    dfs.rename(new Path(quotaDir3,"nqdir32"),tempPath);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
    hasException=false;
    try {
      assertFalse(dfs.rename(tempPath,quotaDir3));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.exists(tempPath));
    assertFalse(dfs.exists(new Path(quotaDir3,"nqdir30")));
    hasException=false;
    try {
      assertFalse(dfs.rename(tempPath,new Path(quotaDir3,"nqdir32")));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.exists(tempPath));
    assertFalse(dfs.exists(new Path(quotaDir3,"nqdir32")));
    assertTrue(dfs.rename(tempPath,new Path("/nqdir0")));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),6);
    assertTrue(dfs.mkdirs(new Path("/nqdir0/nqdir30/nqdir33")));
    hasException=false;
    try {
      assertFalse(dfs.rename(new Path("/nqdir0/nqdir30"),tempPath));
    }
 catch (    NSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.rename(quotaDir3,quotaDir2));
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),4);
    assertEquals(c.getQuota(),6);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),7);
    tempPath=new Path(quotaDir2,"qdir21");
    c=dfs.getContentSummary(tempPath);
    assertEquals(c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),2);
    dfs.delete(tempPath,true);
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),2);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),6);
    assertTrue(dfs.rename(new Path("/nqdir0/nqdir30"),quotaDir2));
    c=dfs.getContentSummary(quotaDir2);
    assertEquals(c.getDirectoryCount(),5);
    assertEquals(c.getQuota(),7);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getDirectoryCount(),6);
    assertEquals(c.getQuota(),6);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Like the previous test but create many files. This covers bugs where
 * the quota adjustment is incorrect but it takes many files to accrue 
 * a big enough accounting error to violate the quota.
 */
@Test public void testMultipleFilesSmallerThanOneBlock() throws Exception {
  Configuration conf=new HdfsConfiguration();
  final int BLOCK_SIZE=6 * 1024;
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  cluster.waitActive();
  FileSystem fs=cluster.getFileSystem();
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    Path dir=new Path("/test");
    boolean exceededQuota=false;
    ContentSummary c;
    final int FILE_SIZE=1024;
    final int QUOTA_SIZE=32 * (int)fs.getDefaultBlockSize();
    assertEquals(6 * 1024,fs.getDefaultBlockSize());
    assertEquals(192 * 1024,QUOTA_SIZE);
    assertTrue(fs.mkdirs(dir));
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(QUOTA_SIZE),dir.toString());
    for (int i=0; i < 59; i++) {
      Path file=new Path("/test/test" + i);
      DFSTestUtil.createFile(fs,file,FILE_SIZE,(short)3,1L);
      DFSTestUtil.waitReplication(fs,file,(short)3);
    }
    c=fs.getContentSummary(dir);
    assertEquals("Invalid space consumed",59 * FILE_SIZE * 3,c.getSpaceConsumed());
    assertEquals("Invalid space consumed",QUOTA_SIZE - (59 * FILE_SIZE * 3),3 * (fs.getDefaultBlockSize() - FILE_SIZE));
    try {
      Path file=new Path("/test/test59");
      DFSTestUtil.createFile(fs,file,FILE_SIZE,(short)3,1L);
      DFSTestUtil.waitReplication(fs,file,(short)3);
    }
 catch (    QuotaExceededException e) {
      exceededQuota=true;
    }
    assertTrue("Quota not exceeded",exceededQuota);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test HDFS operations that change disk space consumed by a directory tree.
 * namely create, rename, delete, append, and setReplication.
 * This is based on testNamespaceCommands() above.
 */
@Test public void testSpaceCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,"512");
  conf.setBoolean("dfs.support.append",true);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  try {
    int fileLen=1024;
    short replication=3;
    int fileSpace=fileLen * replication;
    assertTrue(dfs.mkdirs(new Path("/nqdir0/qdir1/qdir20/nqdir30")));
    final Path quotaDir1=new Path("/nqdir0/qdir1");
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,4 * fileSpace);
    ContentSummary c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceQuota(),4 * fileSpace);
    final Path quotaDir20=new Path("/nqdir0/qdir1/qdir20");
    dfs.setQuota(quotaDir20,FSConstants.QUOTA_DONT_SET,6 * fileSpace);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceQuota(),6 * fileSpace);
    final Path quotaDir21=new Path("/nqdir0/qdir1/qdir21");
    assertTrue(dfs.mkdirs(quotaDir21));
    dfs.setQuota(quotaDir21,FSConstants.QUOTA_DONT_SET,2 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceQuota(),2 * fileSpace);
    Path tempPath=new Path(quotaDir21,"nqdir32");
    assertTrue(dfs.mkdirs(tempPath));
    DFSTestUtil.createFile(dfs,new Path(tempPath,"fileDir/file1"),fileLen,replication,0);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    boolean hasException=false;
    try {
      DFSTestUtil.createFile(dfs,new Path(quotaDir21,"nqdir33/file2"),2 * fileLen,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertTrue(dfs.delete(new Path(quotaDir21,"nqdir33"),true));
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    assertEquals(c.getSpaceQuota(),2 * fileSpace);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),0);
    Path dstPath=new Path(quotaDir20,"nqdir30");
    Path srcPath=new Path(quotaDir21,"nqdir32");
    assertTrue(dfs.rename(srcPath,dstPath));
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceConsumed(),fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    final Path file2=new Path(dstPath,"fileDir/file2");
    int file2Len=2 * fileLen;
    DFSTestUtil.createFile(dfs,file2,file2Len,replication,0);
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    hasException=false;
    try {
      assertFalse(dfs.rename(dstPath,srcPath));
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    assertFalse(dfs.exists(srcPath));
    assertTrue(dfs.exists(dstPath));
    c=dfs.getContentSummary(quotaDir20);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    c=dfs.getContentSummary(quotaDir21);
    assertEquals(c.getSpaceConsumed(),0);
    c=dfs.getContentSummary(quotaDir1);
    assertEquals(c.getSpaceQuota(),4 * fileSpace);
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),3 * fileSpace);
    OutputStream out=dfs.append(file2);
    out.write(new byte[fileLen]);
    out.close();
    file2Len+=fileLen;
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),4 * fileSpace);
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,5 * fileSpace);
    out=dfs.append(file2);
    hasException=false;
    try {
      out.write(new byte[fileLen + 1024]);
      out.flush();
      out.close();
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
      IOUtils.closeStream(out);
    }
    assertTrue(hasException);
    file2Len+=fileLen;
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace);
    dfs.setReplication(file2,(short)(replication - 1));
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace - file2Len);
    hasException=false;
    try {
      dfs.setReplication(file2,(short)(replication + 1));
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace - file2Len);
    dfs.setQuota(quotaDir1,FSConstants.QUOTA_DONT_SET,10 * fileSpace);
    dfs.setQuota(quotaDir20,FSConstants.QUOTA_DONT_SET,10 * fileSpace);
    dfs.setReplication(file2,(short)(replication + 1));
    c=dfs.getContentSummary(dstPath);
    assertEquals(c.getSpaceConsumed(),5 * fileSpace + file2Len);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Violate a space quota using files of size < 1 block. Test that block
 * allocation conservatively assumes that for quota checking the entire
 * space of the block is used.
 */
@Test public void testBlockAllocationAdjustsUsageConservatively() throws Exception {
  Configuration conf=new HdfsConfiguration();
  final int BLOCK_SIZE=6 * 1024;
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  cluster.waitActive();
  FileSystem fs=cluster.getFileSystem();
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    Path dir=new Path("/test");
    Path file1=new Path("/test/test1");
    Path file2=new Path("/test/test2");
    boolean exceededQuota=false;
    final int QUOTA_SIZE=3 * BLOCK_SIZE;
    final int FILE_SIZE=BLOCK_SIZE / 2;
    ContentSummary c;
    assertTrue(fs.mkdirs(dir));
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(QUOTA_SIZE),dir.toString());
    DFSTestUtil.createFile(fs,file1,FILE_SIZE,(short)3,1L);
    DFSTestUtil.waitReplication(fs,file1,(short)3);
    c=fs.getContentSummary(dir);
    assertEquals("Quota is half consumed",QUOTA_SIZE / 2,c.getSpaceConsumed());
    try {
      DFSTestUtil.createFile(fs,file2,FILE_SIZE,(short)3,1L);
    }
 catch (    QuotaExceededException e) {
      exceededQuota=true;
    }
    assertTrue("Quota not exceeded",exceededQuota);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test quota related commands: 
 * setQuota, clrQuota, setSpaceQuota, clrSpaceQuota, and count 
 */
@Test public void testQuotaCommands() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  final int DEFAULT_BLOCK_SIZE=512;
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DEFAULT_BLOCK_SIZE);
  conf.setBoolean("dfs.support.append",true);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  DFSAdmin admin=new DFSAdmin(conf);
  try {
    final int fileLen=1024;
    final short replication=5;
    final long spaceQuota=fileLen * replication * 15 / 8;
    final Path parent=new Path("/test");
    assertTrue(dfs.mkdirs(parent));
    String[] args=new String[]{"-setQuota","3",parent.toString()};
    runCommand(admin,args,false);
    runCommand(admin,false,"-setSpaceQuota","2t",parent.toString());
    assertEquals(2L << 40,dfs.getContentSummary(parent).getSpaceQuota());
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota),parent.toString());
    final Path childDir0=new Path(parent,"data0");
    assertTrue(dfs.mkdirs(childDir0));
    final Path childFile0=new Path(parent,"datafile0");
    DFSTestUtil.createFile(fs,childFile0,fileLen,replication,0);
    ContentSummary c=dfs.getContentSummary(parent);
    assertEquals(c.getFileCount() + c.getDirectoryCount(),3);
    assertEquals(c.getQuota(),3);
    assertEquals(c.getSpaceConsumed(),fileLen * replication);
    assertEquals(c.getSpaceQuota(),spaceQuota);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getFileCount() + c.getDirectoryCount(),1);
    assertEquals(c.getQuota(),-1);
    c=dfs.getContentSummary(parent);
    assertEquals(c.getSpaceConsumed(),fileLen * replication);
    final Path childDir1=new Path(parent,"data1");
    boolean hasException=false;
    try {
      assertFalse(dfs.mkdirs(childDir1));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    OutputStream fout;
    final Path childFile1=new Path(parent,"datafile1");
    hasException=false;
    try {
      fout=dfs.create(childFile1);
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    runCommand(admin,new String[]{"-clrQuota",parent.toString()},false);
    c=dfs.getContentSummary(parent);
    assertEquals(c.getQuota(),-1);
    assertEquals(c.getSpaceQuota(),spaceQuota);
    runCommand(admin,new String[]{"-clrQuota",childDir0.toString()},false);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getQuota(),-1);
    fout=dfs.create(childFile1,replication);
    hasException=false;
    try {
      fout.write(new byte[fileLen]);
      fout.close();
    }
 catch (    QuotaExceededException e) {
      hasException=true;
      IOUtils.closeStream(fout);
    }
    assertTrue(hasException);
    dfs.delete(childFile1,false);
    runCommand(admin,false,"-clrSpaceQuota",parent.toString());
    c=dfs.getContentSummary(parent);
    assertEquals(c.getQuota(),-1);
    assertEquals(c.getSpaceQuota(),-1);
    DFSTestUtil.createFile(dfs,childFile1,fileLen,replication,0);
    args=new String[]{"-setQuota","1",parent.toString()};
    runCommand(admin,args,false);
    runCommand(admin,false,"-setSpaceQuota",Integer.toString(fileLen),args[2]);
    args=new String[]{"-setQuota","1",childDir0.toString()};
    runCommand(admin,args,false);
    hasException=false;
    try {
      assertFalse(dfs.mkdirs(new Path(childDir0,"in")));
    }
 catch (    QuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    c=dfs.getContentSummary(childDir0);
    assertEquals(c.getDirectoryCount() + c.getFileCount(),1);
    assertEquals(c.getQuota(),1);
    Path nonExistentPath=new Path("/test1");
    assertFalse(dfs.exists(nonExistentPath));
    args=new String[]{"-setQuota","1",nonExistentPath.toString()};
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","1g",nonExistentPath.toString());
    assertTrue(dfs.isFile(childFile0));
    args[1]=childFile0.toString();
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","1t",args[1]);
    args[0]="-clrQuota";
    runCommand(admin,args,true);
    runCommand(admin,true,"-clrSpaceQuota",args[1]);
    args[1]=nonExistentPath.toString();
    runCommand(admin,args,true);
    runCommand(admin,true,"-clrSpaceQuota",args[1]);
    args=new String[]{"-setQuota","0",parent.toString()};
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota","0",args[2]);
    args[1]="-1";
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    args[1]=String.valueOf(Long.MAX_VALUE + 1L);
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    args[1]="33aa1.5";
    runCommand(admin,args,true);
    runCommand(admin,true,"-setSpaceQuota",args[1],args[2]);
    runCommand(admin,true,"-setSpaceQuota",(Long.MAX_VALUE / 1024 / 1024 + 1024) + "m",args[2]);
    final String username="userxx";
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting(username,new String[]{"groupyy"});
    final String[] args2=args.clone();
    ugi.doAs(new PrivilegedExceptionAction(){
      @Override public Object run() throws Exception {
        assertEquals("Not running as new user",username,UserGroupInformation.getCurrentUser().getShortUserName());
        DFSAdmin userAdmin=new DFSAdmin(conf);
        args2[1]="100";
        runCommand(userAdmin,args2,true);
        runCommand(userAdmin,true,"-setSpaceQuota","1g",args2[2]);
        String[] args3=new String[]{"-clrQuota",parent.toString()};
        runCommand(userAdmin,args3,true);
        runCommand(userAdmin,true,"-clrSpaceQuota",args3[1]);
        return null;
      }
    }
);
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-setQuota","1000000","/");
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    runCommand(admin,new String[]{"-clrQuota",parent.toString()},false);
    runCommand(admin,false,"-clrSpaceQuota",parent.toString());
    final Path childDir2=new Path(parent,"data2");
    assertTrue(dfs.mkdirs(childDir2));
    final Path childFile2=new Path(childDir2,"datafile2");
    final Path childFile3=new Path(childDir2,"datafile3");
    final long spaceQuota2=DEFAULT_BLOCK_SIZE * replication;
    final long fileLen2=DEFAULT_BLOCK_SIZE;
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),childDir2.toString());
    runCommand(admin,false,"-clrSpaceQuota",childDir2.toString());
    DFSTestUtil.createFile(fs,childFile2,fileLen2,replication,0);
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),childDir2.toString());
    hasException=false;
    try {
      DFSTestUtil.createFile(fs,childFile3,fileLen2,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    final Path childFile4=new Path("/","datafile2");
    final Path childFile5=new Path("/","datafile3");
    runCommand(admin,true,"-clrQuota","/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),"/");
    runCommand(admin,false,"-clrSpaceQuota","/");
    DFSTestUtil.createFile(fs,childFile4,fileLen2,replication,0);
    runCommand(admin,false,"-setSpaceQuota",Long.toString(spaceQuota2),"/");
    hasException=false;
    try {
      DFSTestUtil.createFile(fs,childFile5,fileLen2,replication,0);
    }
 catch (    DSQuotaExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestSafeMode </h4><pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Run various fs operations while the NN is in safe mode,
 * assert that they are either allowed or fail as expected.
 */
@Test public void testOperationsWhileInSafeMode() throws IOException {
  final Path file1=new Path("/file1");
  assertFalse(dfs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  DFSTestUtil.createFile(fs,file1,1024,(short)1,0);
  assertTrue("Could not enter SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER));
  runFsFun("Set quota while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      ((DistributedFileSystem)fs).setQuota(file1,1,1);
    }
  }
);
  runFsFun("Set perm while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setPermission(file1,FsPermission.getDefault());
    }
  }
);
  runFsFun("Set owner while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setOwner(file1,"user","group");
    }
  }
);
  runFsFun("Set repl while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setReplication(file1,(short)1);
    }
  }
);
  runFsFun("Append file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      DFSTestUtil.appendFile(fs,file1,"new bytes");
    }
  }
);
  runFsFun("Delete file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.delete(file1,false);
    }
  }
);
  runFsFun("Rename file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.rename(file1,new Path("file2"));
    }
  }
);
  try {
    fs.setTimes(file1,0,0);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  try {
    DFSTestUtil.readFile(fs,file1);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  assertFalse("Could not leave SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_LEAVE));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.TestDelegationToken </h4><pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDelegationTokenSecretManager() throws Exception {
  DelegationTokenSecretManager dtSecretManager=cluster.getNamesystem().getDelegationTokenSecretManager();
  Token<DelegationTokenIdentifier> token=generateDelegationToken("SomeUser","JobTracker");
  try {
    dtSecretManager.renewToken(token,"FakeRenewer");
    Assert.fail("should have failed");
  }
 catch (  AccessControlException ace) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  DelegationTokenIdentifier identifier=new DelegationTokenIdentifier();
  byte[] tokenId=token.getIdentifier();
  identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
  Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
  LOG.info("Sleep to expire the token");
  Thread.sleep(6000);
  try {
    dtSecretManager.retrievePassword(identifier);
    Assert.fail("Token should have expired");
  }
 catch (  InvalidToken e) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  LOG.info("Sleep beyond the max lifetime");
  Thread.sleep(5000);
  try {
    dtSecretManager.renewToken(token,"JobTracker");
    Assert.fail("should have been expired");
  }
 catch (  InvalidToken it) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.token.block.TestBlockToken </h4><pre class="type-16 type-10 type-12 type-3 type-9 type-18 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Sets implicit assumptions 
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that fast repeated invocations of createClientDatanodeProtocolProxy
 * will not end up using up thousands of sockets. This is a regression test for
 * HDFS-1965.
 */
@Test public void testBlockTokenRpcLeak() throws Exception {
  Assume.assumeTrue(FD_DIR.exists());
  BlockTokenSecretManager sm=new BlockTokenSecretManager(true,blockKeyUpdateInterval,blockTokenLifetime);
  Token<BlockTokenIdentifier> token=sm.generateToken(block3,EnumSet.allOf(BlockTokenSecretManager.AccessMode.class));
  final Server server=createMockDatanode(sm,token);
  server.start();
  final InetSocketAddress addr=NetUtils.getConnectAddress(server);
  DatanodeID fakeDnId=new DatanodeID("localhost:" + addr.getPort(),"fake-storage",0,addr.getPort());
  ExtendedBlock b=new ExtendedBlock("fake-pool",new Block(12345L));
  LocatedBlock fakeBlock=new LocatedBlock(b,new DatanodeInfo[0]);
  fakeBlock.setBlockToken(token);
  ClientDatanodeProtocol proxyToNoWhere=RPC.getProxy(ClientDatanodeProtocol.class,ClientDatanodeProtocol.versionID,new InetSocketAddress("1.1.1.1",1),UserGroupInformation.createRemoteUser("junk"),conf,NetUtils.getDefaultSocketFactory(conf));
  ClientDatanodeProtocol proxy=null;
  int fdsAtStart=countOpenFileDescriptors();
  try {
    long endTime=System.currentTimeMillis() + 3000;
    while (System.currentTimeMillis() < endTime) {
      proxy=DFSTestUtil.createClientDatanodeProtocolProxy(fakeDnId,conf,1000,fakeBlock);
      assertEquals(block3.getBlockId(),proxy.getReplicaVisibleLength(block3));
      if (proxy != null) {
        RPC.stopProxy(proxy);
      }
      LOG.info("Num open fds:" + countOpenFileDescriptors());
    }
    int fdsAtEnd=countOpenFileDescriptors();
    if (fdsAtEnd - fdsAtStart > 50) {
      fail("Leaked " + (fdsAtEnd - fdsAtStart) + " fds!");
    }
  }
  finally {
    server.stop();
  }
  RPC.stopProxy(proxyToNoWhere);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * BlockRecovery_02.8.
 * Two replicas are in Finalized state
 * @throws IOException in case of an error
 */
@Test public void testFinalizedReplicas() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  ReplicaRecoveryInfo replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  ReplicaRecoveryInfo replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 2,ReplicaState.FINALIZED);
  InterDatanodeProtocol dn1=mock(InterDatanodeProtocol.class);
  InterDatanodeProtocol dn2=mock(InterDatanodeProtocol.class);
  testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
  verify(dn1).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  verify(dn2).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN2,GEN_STAMP - 2,ReplicaState.FINALIZED);
  try {
    testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
    Assert.fail("Two finalized replicas should not have different lengthes!");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("Inconsistent size of finalized replicas. "));
  }
}

</code></pre>

<br>
<pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of datanode
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (dn != null) {
    try {
      dn.shutdown();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(DATA_DIR);
      if (dir.exists())       Assert.assertTrue("Cannot delete data-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockReport </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test write a file, verifies and closes it. Then a couple of random blocks
 * is removed and BlockReport is forced; the FSNamesystem is pushed to
 * recalculate required DN's activities such as replications and so on.
 * The number of missing and under-replicated blocks should be the same in
 * case of a single-DN cluster.
 * @throws IOException in case of errors
 */
@Test public void blockReport_02() throws IOException {
  final String METHOD_NAME=GenericTestUtils.getMethodName();
  LOG.info("Running test " + METHOD_NAME);
  Path filePath=new Path("/" + METHOD_NAME + ".dat");
  DFSTestUtil.createFile(fs,filePath,(long)FILE_SIZE,REPL_FACTOR,rand.nextLong());
  File dataDir=new File(cluster.getDataDirectory());
  assertTrue(dataDir.isDirectory());
  List<ExtendedBlock> blocks2Remove=new ArrayList<ExtendedBlock>();
  List<Integer> removedIndex=new ArrayList<Integer>();
  List<LocatedBlock> lBlocks=cluster.getNameNode().getBlockLocations(filePath.toString(),FILE_START,FILE_SIZE).getLocatedBlocks();
  while (removedIndex.size() != 2) {
    int newRemoveIndex=rand.nextInt(lBlocks.size());
    if (!removedIndex.contains(newRemoveIndex))     removedIndex.add(newRemoveIndex);
  }
  for (  Integer aRemovedIndex : removedIndex) {
    blocks2Remove.add(lBlocks.get(aRemovedIndex).getBlock());
  }
  ArrayList<Block> blocks=locatedToBlocks(lBlocks,removedIndex);
  if (LOG.isDebugEnabled()) {
    LOG.debug("Number of blocks allocated " + lBlocks.size());
  }
  for (  ExtendedBlock b : blocks2Remove) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Removing the block " + b.getBlockName());
    }
    for (    File f : findAllFiles(dataDir,new MyFileFilter(b.getBlockName(),true))) {
      cluster.getDataNodes().get(DN_N0).getFSDataset().unfinalizeBlock(b);
      if (!f.delete())       LOG.warn("Couldn't delete " + b.getBlockName());
    }
  }
  waitTil(DN_RESCAN_EXTRA_WAIT);
  DataNode dn=cluster.getDataNodes().get(DN_N0);
  String poolId=cluster.getNamesystem().getBlockPoolId();
  DatanodeRegistration dnR=dn.getDNRegistrationForBP(poolId);
  cluster.getNameNode().blockReport(dnR,poolId,new BlockListAsLongs(blocks,null).getBlockListAsLongs());
  cluster.getNamesystem().computeDatanodeWork();
  printStats();
  assertEquals("Wrong number of MissingBlocks is found",blocks2Remove.size(),cluster.getNamesystem().getMissingBlocksCount());
  assertEquals("Wrong number of UnderReplicatedBlocks is found",blocks2Remove.size(),cluster.getNamesystem().getUnderReplicatedBlocks());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations </h4><pre class="type-9 type-13 type-6 type-4 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether two objects/variables are the same">IdentityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether two objects/variables are the same
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start multiple NNs and single DN and verifies per BP registrations and
 * handshakes.
 * @throws IOException
 */
@Test public void test2NNRegistration() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  try {
    cluster.waitActive();
    NameNode nn1=cluster.getNameNode(0);
    NameNode nn2=cluster.getNameNode(1);
    assertNotNull("cannot create nn1",nn1);
    assertNotNull("cannot create nn2",nn2);
    String bpid1=nn1.getFSImage().getBlockPoolID();
    String bpid2=nn2.getFSImage().getBlockPoolID();
    String cid1=nn1.getFSImage().getClusterID();
    String cid2=nn2.getFSImage().getClusterID();
    int lv1=nn1.getFSImage().getLayoutVersion();
    int lv2=nn2.getFSImage().getLayoutVersion();
    int ns1=nn1.getFSImage().getNamespaceID();
    int ns2=nn2.getFSImage().getNamespaceID();
    assertNotSame("namespace ids should be different",ns1,ns2);
    LOG.info("nn1: lv=" + lv1 + ";cid="+ cid1+ ";bpid="+ bpid1+ ";uri="+ nn1.getNameNodeAddress());
    LOG.info("nn2: lv=" + lv2 + ";cid="+ cid2+ ";bpid="+ bpid2+ ";uri="+ nn2.getNameNodeAddress());
    DataNode dn=cluster.getDataNodes().get(0);
    Collection<VolumeInfo> volInfos=((FSDataset)dn.data).getVolumeInfo();
    assertNotNull("No volumes in the fsdataset",volInfos);
    int i=0;
    for (    VolumeInfo vi : volInfos) {
      LOG.info("vol " + i++ + ";dir="+ vi.directory+ ";fs= "+ vi.freeSpace);
    }
    assertEquals("number of volumes is wrong",2,volInfos.size());
    for (    BPOfferService bpos : dn.getAllBpOs()) {
      LOG.info("reg: bpid=" + "; name=" + bpos.bpRegistration.name + "; sid="+ bpos.bpRegistration.storageID+ "; nna="+ bpos.nnAddr);
    }
    BPOfferService bpos1=dn.getAllBpOs()[0];
    BPOfferService bpos2=dn.getAllBpOs()[1];
    if (bpos1.nnAddr.equals(nn2.getNameNodeAddress())) {
      BPOfferService tmp=bpos1;
      bpos1=bpos2;
      bpos2=tmp;
    }
    assertEquals("wrong nn address",bpos1.nnAddr,nn1.getNameNodeAddress());
    assertEquals("wrong nn address",bpos2.nnAddr,nn2.getNameNodeAddress());
    assertEquals("wrong bpid",bpos1.getBlockPoolId(),bpid1);
    assertEquals("wrong bpid",bpos2.getBlockPoolId(),bpid2);
    assertEquals("wrong cid",dn.getClusterId(),cid1);
    assertEquals("cid should be same",cid2,cid1);
    assertEquals("namespace should be same",bpos1.bpNSInfo.namespaceID,ns1);
    assertEquals("namespace should be same",bpos2.bpNSInfo.namespaceID,ns2);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-9 type-6 type-4 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * starts single nn and single dn and verifies registration and handshake
 * @throws IOException
 */
@Test public void testFedSingleNN() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nameNodePort(9927).build();
  try {
    NameNode nn1=cluster.getNameNode();
    assertNotNull("cannot create nn1",nn1);
    String bpid1=nn1.getFSImage().getBlockPoolID();
    String cid1=nn1.getFSImage().getClusterID();
    int lv1=nn1.getFSImage().getLayoutVersion();
    LOG.info("nn1: lv=" + lv1 + ";cid="+ cid1+ ";bpid="+ bpid1+ ";uri="+ nn1.getNameNodeAddress());
    DataNode dn=cluster.getDataNodes().get(0);
    Collection<VolumeInfo> volInfos=((FSDataset)dn.data).getVolumeInfo();
    assertNotNull("No volumes in the fsdataset",volInfos);
    int i=0;
    for (    VolumeInfo vi : volInfos) {
      LOG.info("vol " + i++ + ";dir="+ vi.directory+ ";fs= "+ vi.freeSpace);
    }
    assertEquals("number of volumes is wrong",2,volInfos.size());
    for (    BPOfferService bpos : dn.getAllBpOs()) {
      LOG.info("reg: bpid=" + "; name=" + bpos.bpRegistration.name + "; sid="+ bpos.bpRegistration.storageID+ "; nna="+ bpos.nnAddr);
    }
    BPOfferService bpos1=dn.getAllBpOs()[0];
    bpos1.lastBlockReport=0;
    bpos1.blockReport();
    assertEquals("wrong nn address",bpos1.nnAddr,nn1.getNameNodeAddress());
    assertEquals("wrong bpid",bpos1.getBlockPoolId(),bpid1);
    assertEquals("wrong cid",dn.getClusterId(),cid1);
    cluster.shutdown();
    assertEquals(0,dn.getAllBpOs().length);
    cluster=null;
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testClusterIdMismatch() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  try {
    cluster.waitActive();
    DataNode dn=cluster.getDataNodes().get(0);
    BPOfferService[] bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (should be 2):" + bposs.length);
    Assert.assertEquals("should've registered with two namenodes",bposs.length,2);
    cluster.addNameNode(conf,9938);
    bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (should be 3):" + bposs.length);
    Assert.assertEquals("should've registered with three namenodes",bposs.length,3);
    StartupOption.FORMAT.setClusterId("DifferentCID");
    cluster.addNameNode(conf,9948);
    NameNode nn4=cluster.getNameNode(3);
    assertNotNull("cannot create nn4",nn4);
    bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (still should be 3):" + bposs.length);
    Assert.assertEquals("should've registered with three namenodes",3,bposs.length);
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMiniDFSClusterWithMultipleNN() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(1)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(1)Should be 3 namenodes",3,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).federation(true).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(2)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  try {
    cluster.addNameNode(conf,9929);
    Assert.fail("shouldn't be able to add another NN to non federated cluster");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("cannot add namenode"));
    Assert.assertEquals("(3)Should be 1 namenodes",1,cluster.getNumNameNodes());
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting </h4><pre class="type-8 type-18 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Sets implicit assumptions 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that the NN re-learns of volume failures after restart.
 */
@Test public void testVolFailureStatsPreservedOnNNRestart() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn1Vol1=new File(dataDir,"data" + (2 * 0 + 1));
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(false));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)2,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)2);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  cluster.restartNameNode(0);
  cluster.waitActive();
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
}

</code></pre>

<br>
<pre class="type-8 type-9 type-18 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Sets implicit assumptions 
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that individual volume failures do not cause DNs to fail, that
 * all volumes failed on a single datanode do cause it to fail, and
 * that the capacities and liveliness is adjusted correctly in the NN.
 */
@Test public void testSuccessiveVolumeFailures() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  Thread.sleep(WAIT_FOR_HEARTBEATS);
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn1Vol1=new File(dataDir,"data" + (2 * 0 + 1));
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  File dn3Vol1=new File(dataDir,"data" + (2 * 2 + 1));
  File dn3Vol2=new File(dataDir,"data" + (2 * 2 + 2));
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(false));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)3);
  ArrayList<DataNode> dns=cluster.getDataNodes();
  assertTrue("DN1 should be up",dns.get(0).isDatanodeUp());
  assertTrue("DN2 should be up",dns.get(1).isDatanodeUp());
  assertTrue("DN3 should be up",dns.get(2).isDatanodeUp());
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(0).getMetrics().name()));
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(1).getMetrics().name()));
  assertCounter("VolumeFailures",0L,getMetrics(dns.get(2).getMetrics().name()));
  assert (WAIT_FOR_HEARTBEATS * 10) > WAIT_FOR_DEATH;
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,2,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn3Vol1.setExecutable(false));
  Path file2=new Path("/test2");
  DFSTestUtil.createFile(fs,file2,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file2,(short)3);
  assertTrue("DN3 should still be up",dns.get(2).isDatanodeUp());
  assertCounter("VolumeFailures",1L,getMetrics(dns.get(2).getMetrics().name()));
  ArrayList<DatanodeDescriptor> live=new ArrayList<DatanodeDescriptor>();
  ArrayList<DatanodeDescriptor> dead=new ArrayList<DatanodeDescriptor>();
  ns.DFSNodesStatus(live,dead);
  live.clear();
  dead.clear();
  ns.DFSNodesStatus(live,dead);
  assertEquals("DN3 should have 1 failed volume",1,live.get(2).getVolumeFailures());
  dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,3,origCapacity - (3 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn3Vol2.setExecutable(false));
  Path file3=new Path("/test3");
  DFSTestUtil.createFile(fs,file3,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file3,(short)2);
  DFSTestUtil.waitForDatanodeDeath(dns.get(2));
  assertCounter("VolumeFailures",2L,getMetrics(dns.get(2).getMetrics().name()));
  DFSTestUtil.waitForDatanodeStatus(ns,2,1,2,origCapacity - (4 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn1Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn3Vol1.setExecutable(true));
  assertTrue("Couldn't chmod local vol",dn3Vol2.setExecutable(true));
  cluster.restartDataNodes();
  cluster.waitActive();
  Path file4=new Path("/test4");
  DFSTestUtil.createFile(fs,file4,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file4,(short)3);
  DFSTestUtil.waitForDatanodeStatus(ns,3,0,0,origCapacity,WAIT_FOR_HEARTBEATS);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration </h4><pre class="type-8 type-18 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Sets implicit assumptions 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test the DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY configuration
 * option, ie the DN shuts itself down when the number of failures
 * experienced drops below the tolerated amount.
 */
@Test public void testConfigureMinValidVolumes() throws Exception {
  assumeTrue(!System.getProperty("os.name").startsWith("Windows"));
  conf.setInt(DFSConfigKeys.DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY,0);
  cluster.startDataNodes(conf,2,true,null,null);
  cluster.waitActive();
  FSNamesystem ns=cluster.getNamesystem();
  long origCapacity=DFSTestUtil.getLiveDatanodeCapacity(ns);
  long dnCapacity=DFSTestUtil.getDatanodeCapacity(ns,0);
  File dn2Vol1=new File(dataDir,"data" + (2 * 1 + 1));
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(false));
  Path file1=new Path("/test1");
  DFSTestUtil.createFile(fs,file1,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file1,(short)2);
  DFSTestUtil.waitForDatanodeStatus(ns,2,1,0,origCapacity - (1 * dnCapacity),WAIT_FOR_HEARTBEATS);
  assertTrue("Couldn't chmod local vol",dn2Vol1.setExecutable(true));
  Path file2=new Path("/test2");
  DFSTestUtil.createFile(fs,file2,1024,(short)3,1L);
  DFSTestUtil.waitReplication(fs,file2,(short)2);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDfsAdminDeleteBlockPool() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1,namesServerId2");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(2).numDataNodes(1).build();
    cluster.waitActive();
    FileSystem fs1=cluster.getFileSystem(0);
    FileSystem fs2=cluster.getFileSystem(1);
    DFSTestUtil.createFile(fs1,new Path("/alpha"),1024,(short)1,54);
    DFSTestUtil.createFile(fs2,new Path("/beta"),1024,(short)1,54);
    DataNode dn1=cluster.getDataNodes().get(0);
    String bpid1=cluster.getNamesystem(0).getBlockPoolId();
    String bpid2=cluster.getNamesystem(1).getBlockPoolId();
    File dn1StorageDir1=MiniDFSCluster.getStorageDir(0,0);
    File dn1StorageDir2=MiniDFSCluster.getStorageDir(0,1);
    Configuration nn1Conf=cluster.getConfiguration(0);
    nn1Conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1");
    dn1.refreshNamenodes(nn1Conf);
    Assert.assertEquals(1,dn1.getAllBpOs().length);
    DFSAdmin admin=new DFSAdmin(nn1Conf);
    String dn1Address=dn1.getSelfAddr().getHostName() + ":" + dn1.getIpcPort();
    String[] args={"-deleteBlockPool",dn1Address,bpid2};
    int ret=admin.run(args);
    Assert.assertFalse(0 == ret);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid2);
    String[] forceArgs={"-deleteBlockPool",dn1Address,bpid2,"force"};
    ret=admin.run(forceArgs);
    Assert.assertEquals(0,ret);
    verifyBlockPoolDirectories(false,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(false,dn1StorageDir2,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid1);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDeleteBlockPool() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1,namesServerId2");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(2).numDataNodes(2).build();
    cluster.waitActive();
    FileSystem fs1=cluster.getFileSystem(0);
    FileSystem fs2=cluster.getFileSystem(1);
    DFSTestUtil.createFile(fs1,new Path("/alpha"),1024,(short)2,54);
    DFSTestUtil.createFile(fs2,new Path("/beta"),1024,(short)2,54);
    DataNode dn1=cluster.getDataNodes().get(0);
    DataNode dn2=cluster.getDataNodes().get(1);
    String bpid1=cluster.getNamesystem(0).getBlockPoolId();
    String bpid2=cluster.getNamesystem(1).getBlockPoolId();
    File dn1StorageDir1=MiniDFSCluster.getStorageDir(0,0);
    File dn1StorageDir2=MiniDFSCluster.getStorageDir(0,1);
    File dn2StorageDir1=MiniDFSCluster.getStorageDir(1,0);
    File dn2StorageDir2=MiniDFSCluster.getStorageDir(1,1);
    try {
      dn1.deleteBlockPool(bpid1,true);
      Assert.fail("Must not delete a running block pool");
    }
 catch (    IOException expected) {
    }
    Configuration nn1Conf=cluster.getConfiguration(1);
    nn1Conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId2");
    dn1.refreshNamenodes(nn1Conf);
    assertEquals(1,dn1.getAllBpOs().length);
    try {
      dn1.deleteBlockPool(bpid1,false);
      Assert.fail("Must not delete if any block files exist unless " + "force is true");
    }
 catch (    IOException expected) {
    }
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid1);
    dn1.deleteBlockPool(bpid1,true);
    verifyBlockPoolDirectories(false,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(false,dn1StorageDir2,bpid1);
    fs1.delete(new Path("/alpha"),true);
    while ((MiniDFSCluster.getFinalizedDir(dn2StorageDir1,bpid1).list().length != 0) || (MiniDFSCluster.getFinalizedDir(dn2StorageDir2,bpid1).list().length != 0)) {
      try {
        Thread.sleep(3000);
      }
 catch (      Exception ignored) {
      }
    }
    cluster.shutdownNameNode(0);
    try {
      dn2.deleteBlockPool(bpid1,true);
      Assert.fail("Must not delete a running block pool");
    }
 catch (    IOException expected) {
    }
    dn2.refreshNamenodes(nn1Conf);
    assertEquals(1,dn2.getAllBpOs().length);
    verifyBlockPoolDirectories(true,dn2StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn2StorageDir2,bpid1);
    dn2.deleteBlockPool(bpid1,false);
    verifyBlockPoolDirectories(false,dn2StorageDir1,bpid1);
    verifyBlockPoolDirectories(false,dn2StorageDir2,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid2);
    verifyBlockPoolDirectories(true,dn2StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn2StorageDir2,bpid2);
    Path gammaFile=new Path("/gamma");
    DFSTestUtil.createFile(fs2,gammaFile,1024,(short)1,55);
    fs2.setReplication(gammaFile,(short)2);
    DFSTestUtil.waitReplication(fs2,gammaFile,(short)2);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestInterDatanodeProtocol </h4><pre class="type-10 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test {@link FSDataset#initReplicaRecovery(String,ReplicasMap,Block,long)}
 */
@Test public void testInitReplicaRecovery() throws IOException {
  final long firstblockid=10000L;
  final long gs=7777L;
  final long length=22L;
  final ReplicasMap map=new ReplicasMap(this);
  String bpid="BP-TEST";
  final Block[] blocks=new Block[5];
  for (int i=0; i < blocks.length; i++) {
    blocks[i]=new Block(firstblockid + i,length,gs);
    map.add(bpid,createReplicaInfo(blocks[i]));
  }
{
    final Block b=blocks[0];
    final ReplicaInfo originalInfo=map.get(bpid,b);
    final long recoveryid=gs + 1;
    final ReplicaRecoveryInfo recoveryInfo=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid);
    assertEquals(originalInfo,recoveryInfo);
    final ReplicaUnderRecovery updatedInfo=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo.getBlockId());
    Assert.assertEquals(recoveryid,updatedInfo.getRecoveryID());
    final long recoveryid2=gs + 2;
    final ReplicaRecoveryInfo recoveryInfo2=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid2);
    assertEquals(originalInfo,recoveryInfo2);
    final ReplicaUnderRecovery updatedInfo2=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo2.getBlockId());
    Assert.assertEquals(recoveryid2,updatedInfo2.getRecoveryID());
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    RecoveryInProgressException ripe) {
      System.out.println("GOOD: getting " + ripe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid - 1,length,gs);
    ReplicaRecoveryInfo r=FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
    Assert.assertNull("Data-node should not have this replica.",r);
  }
{
    final long recoveryid=gs - 1;
    final Block b=new Block(firstblockid + 1,length,gs);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    IOException ioe) {
      System.out.println("GOOD: getting " + ioe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid,length,gs + 1);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      fail("InitReplicaRecovery should fail because replica's " + "gs is less than the block's gs");
    }
 catch (    IOException e) {
      e.getMessage().startsWith("replica.getGenerationStamp() < block.getGenerationStamp(), block=");
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test  for{@link FSDataset#updateReplicaUnderRecovery(ExtendedBlock,long,long)} 
 */
@Test public void testUpdateReplicaUnderRecovery() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    String bpid=cluster.getNamesystem().getBlockPoolId();
    DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
    String filestr="/foo";
    Path filepath=new Path(filestr);
    DFSTestUtil.createFile(dfs,filepath,1024L,(short)3,0L);
    final LocatedBlock locatedblock=getLastLocatedBlock(dfs.getClient().getNamenode(),filestr);
    final DatanodeInfo[] datanodeinfo=locatedblock.getLocations();
    Assert.assertTrue(datanodeinfo.length > 0);
    final DataNode datanode=cluster.getDataNode(datanodeinfo[0].getIpcPort());
    Assert.assertTrue(datanode != null);
    Assert.assertTrue(datanode.data instanceof FSDataset);
    final FSDataset fsdataset=(FSDataset)datanode.data;
    final ExtendedBlock b=locatedblock.getBlock();
    final long recoveryid=b.getGenerationStamp() + 1;
    final long newlength=b.getNumBytes() - 1;
    final ReplicaRecoveryInfo rri=fsdataset.initReplicaRecovery(new RecoveringBlock(b,null,recoveryid));
    final ReplicaInfo replica=fsdataset.fetchReplicaInfo(bpid,b.getBlockId());
    Assert.assertEquals(ReplicaState.RUR,replica.getState());
    FSDataset.checkReplicaFiles(replica);
{
      final ExtendedBlock tmp=new ExtendedBlock(b.getBlockPoolId(),rri.getBlockId(),rri.getNumBytes() - 1,rri.getGenerationStamp());
      try {
        fsdataset.updateReplicaUnderRecovery(tmp,recoveryid,newlength);
        Assert.fail();
      }
 catch (      IOException ioe) {
        System.out.println("GOOD: getting " + ioe);
      }
    }
    final ReplicaInfo finalized=fsdataset.updateReplicaUnderRecovery(new ExtendedBlock(b.getBlockPoolId(),rri),recoveryid,newlength);
    FSDataset.checkReplicaFiles(finalized);
    Assert.assertEquals(b.getBlockId(),finalized.getBlockId());
    Assert.assertEquals(recoveryid,finalized.getGenerationStamp());
    Assert.assertEquals(newlength,finalized.getNumBytes());
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRefreshNamenodes() throws IOException {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(1).nameNodePort(nnPort1).build();
    DataNode dn=cluster.getDataNodes().get(0);
    assertEquals(1,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort2);
    assertEquals(2,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort3);
    assertEquals(3,dn.getAllBpOs().length);
    cluster.addNameNode(conf,nnPort4);
    BPOfferService[] bpoList=dn.getAllBpOs();
    for (int i=0; i < 4; i++) {
      InetSocketAddress addr=cluster.getNameNode(i).getNameNodeAddress();
      boolean found=false;
      for (int j=0; j < bpoList.length; j++) {
        if (bpoList[j] != null && addr.equals(bpoList[j].nnAddr)) {
          found=true;
          bpoList[j]=null;
          break;
        }
      }
      assertTrue("NameNode address " + addr + " is not found.",found);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestReplicasMap </h4><pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test for ReplicasMap.get(Block) and ReplicasMap.get(long) tests
 */
@Test public void testGet(){
  try {
    map.get(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  assertNotNull(map.get(bpid,block));
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.get(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.get(bpid,b));
  assertNotNull(map.get(bpid,block.getBlockId()));
  assertNull(map.get(bpid,0));
}

</code></pre>

<br>
<pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRemove(){
  try {
    map.remove(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.remove(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.remove(bpid,b));
  assertNotNull(map.remove(bpid,block));
  assertNull(map.remove(bpid,0));
  map.add(bpid,new FinalizedReplica(block,null,null));
  assertNotNull(map.remove(bpid,block.getBlockId()));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestRoundRobinVolumesPolicy </h4><pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRR() throws Exception {
  final List<FSVolume> volumes=new ArrayList<FSVolume>();
  volumes.add(Mockito.mock(FSVolume.class));
  Mockito.when(volumes.get(0).getAvailable()).thenReturn(100L);
  volumes.add(Mockito.mock(FSVolume.class));
  Mockito.when(volumes.get(1).getAvailable()).thenReturn(200L);
  RoundRobinVolumesPolicy policy=ReflectionUtils.newInstance(RoundRobinVolumesPolicy.class,null);
  Assert.assertEquals(volumes.get(0),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(0),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,150));
  try {
    policy.chooseVolume(volumes,Long.MAX_VALUE);
    Assert.fail();
  }
 catch (  IOException e) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestTransferRbw </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testTransferRbw() throws Exception {
  final HdfsConfiguration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION).build();
  try {
    cluster.waitActive();
    final DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
    final Path p=new Path("/foo");
    final int size=(1 << 16) + RAN.nextInt(1 << 16);
    LOG.info("size = " + size);
    final FSDataOutputStream out=fs.create(p,REPLICATION);
    final byte[] bytes=new byte[1024];
    for (int remaining=size; remaining > 0; ) {
      RAN.nextBytes(bytes);
      final int len=bytes.length < remaining ? bytes.length : remaining;
      out.write(bytes,0,len);
      out.hflush();
      remaining-=len;
    }
    final ReplicaBeingWritten oldrbw;
    final DataNode newnode;
    final DatanodeInfo newnodeinfo;
    final String bpid=cluster.getNamesystem().getBlockPoolId();
{
      final DataNode oldnode=cluster.getDataNodes().get(0);
      oldrbw=getRbw(oldnode,bpid);
      LOG.info("oldrbw = " + oldrbw);
      cluster.startDataNodes(conf,1,true,null,null);
      newnode=cluster.getDataNodes().get(REPLICATION);
      final DatanodeInfo oldnodeinfo;
{
        final DatanodeInfo[] datatnodeinfos=cluster.getNameNode().getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertEquals(2,datatnodeinfos.length);
        int i=0;
        for (DatanodeRegistration dnReg=newnode.getDNRegistrationForBP(bpid); i < datatnodeinfos.length && !datatnodeinfos[i].equals(dnReg); i++)         ;
        Assert.assertTrue(i < datatnodeinfos.length);
        newnodeinfo=datatnodeinfos[i];
        oldnodeinfo=datatnodeinfos[1 - i];
      }
      final ExtendedBlock b=new ExtendedBlock(bpid,oldrbw.getBlockId(),oldrbw.getBytesAcked(),oldrbw.getGenerationStamp());
      final BlockOpResponseProto s=DFSTestUtil.transferRbw(b,fs.getClient(),oldnodeinfo,newnodeinfo);
      Assert.assertEquals(Status.SUCCESS,s.getStatus());
    }
    final ReplicaBeingWritten newrbw=getRbw(newnode,bpid);
    LOG.info("newrbw = " + newrbw);
    Assert.assertEquals(oldrbw.getBlockId(),newrbw.getBlockId());
    Assert.assertEquals(oldrbw.getGenerationStamp(),newrbw.getGenerationStamp());
    Assert.assertEquals(oldrbw.getVisibleLength(),newrbw.getVisibleLength());
    LOG.info("DONE");
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestAllowFormat </h4><pre class="type-3 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start MiniDFScluster, try formatting with different settings
 * @throws IOException
 * @throws InterruptedException 
 */
@Test public void testAllowFormat() throws IOException {
  LOG.info("--starting mini cluster");
  NameNode nn;
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  cluster=new MiniDFSCluster.Builder(config).manageDataDfsDirs(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  assertNotNull(cluster);
  nn=cluster.getNameNode();
  assertNotNull(nn);
  LOG.info("Mini cluster created OK");
  LOG.info("Verifying format will fail with allowformat false");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,false);
  try {
    cluster.shutdown();
    NameNode.format(config);
    fail("Format succeeded, when it should have failed");
  }
 catch (  IOException e) {
    assertTrue("Exception was not about formatting Namenode",e.getMessage().startsWith("The option " + DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY));
    LOG.info("Expected failure: " + StringUtils.stringifyException(e));
    LOG.info("Done verifying format will fail with allowformat false");
  }
  LOG.info("Verifying format will succeed with allowformat true");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  NameNode.format(config);
  LOG.info("Done verifying format will succeed with allowformat true");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test NameNode.getBlockLocations(..) on reading un-closed files.
 */
@Test public void testGetBlockLocations() throws IOException {
  final NameNode namenode=cluster.getNameNode();
  final Path p=new Path(BASE_DIR,"file2.dat");
  final String src=p.toString();
  final FSDataOutputStream out=TestFileCreation.createFile(hdfs,p,3);
  int len=BLOCK_SIZE >>> 1;
  writeFile(p,out,len);
  for (int i=1; i < NUM_BLOCKS; ) {
    final LocatedBlocks lb=namenode.getBlockLocations(src,0,len);
    final List<LocatedBlock> blocks=lb.getLocatedBlocks();
    assertEquals(i,blocks.size());
    final Block b=blocks.get(blocks.size() - 1).getBlock().getLocalBlock();
    assertTrue(b instanceof BlockInfoUnderConstruction);
    if (++i < NUM_BLOCKS) {
      writeFile(p,out,BLOCK_SIZE);
      len+=BLOCK_SIZE;
    }
  }
  out.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestBlocksWithNotEnoughRacks </h4><pre class="type-16 type-10 type-12 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testCorruptBlockRereplicatedAcrossRacks() throws Exception {
  Configuration conf=getConf();
  short REPLICATION_FACTOR=2;
  int fileLen=512;
  final Path filePath=new Path("/testFile");
  String racks[]={"/rack1","/rack1","/rack2","/rack2"};
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(racks.length).racks(racks).build();
  final FSNamesystem ns=cluster.getNameNode().getNamesystem();
  try {
    final FileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,filePath,fileLen,REPLICATION_FACTOR,1L);
    final String fileContent=DFSTestUtil.readFile(fs,filePath);
    ExtendedBlock b=DFSTestUtil.getFirstBlock(fs,filePath);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    int dnToCorrupt=DFSTestUtil.firstDnWithBlock(cluster,b);
    assertTrue(MiniDFSCluster.corruptReplica(dnToCorrupt,b));
    cluster.restartDataNode(dnToCorrupt);
    DFSTestUtil.waitCorruptReplicas(fs,ns,filePath,b,1);
    DFSTestUtil.waitForReplication(cluster,b,2,REPLICATION_FACTOR,0);
    for (int i=0; i < racks.length; i++) {
      String blockContent=cluster.readBlockOnDataNode(i,b);
      if (blockContent != null && i != dnToCorrupt) {
        assertEquals("Corrupt replica",fileContent,blockContent);
      }
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens </h4><pre class="type-10 type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests save namepsace.
 */
@Test public void testSaveNamespace() throws IOException {
  DistributedFileSystem fs=null;
  try {
    Configuration conf=new HdfsConfiguration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    cluster.waitActive();
    fs=(DistributedFileSystem)(cluster.getFileSystem());
    FSNamesystem namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    String renewer=UserGroupInformation.getLoginUser().getUserName();
    Token<DelegationTokenIdentifier> token1=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token2=namesystem.getDelegationToken(new Text(renewer));
    DFSAdmin admin=new DFSAdmin(conf);
    String[] args=new String[]{"-saveNamespace"};
    Collection<URI> editsDirs=cluster.getNameEditsDirs(0);
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() > Integer.SIZE / Byte.SIZE);
    }
    fs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    try {
      admin.run(args);
    }
 catch (    Exception e) {
      throw new IOException(e.getMessage());
    }
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() == Integer.SIZE / Byte.SIZE);
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    try {
      renewToken(token1);
      renewToken(token2);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token3=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token4=namesystem.getDelegationToken(new Text(renewer));
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token5=namesystem.getDelegationToken(new Text(renewer));
    try {
      renewToken(token1);
      renewToken(token2);
      renewToken(token3);
      renewToken(token4);
      renewToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    try {
      renewToken(token1);
      cancelToken(token1);
      renewToken(token2);
      cancelToken(token2);
      renewToken(token3);
      cancelToken(token3);
      renewToken(token4);
      cancelToken(token4);
      renewToken(token5);
      cancelToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
  }
  finally {
    if (fs != null)     fs.close();
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestDeadDatanode </h4><pre class="type-10 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test to ensure namenode rejects request from dead datanode
 * - Start a cluster
 * - Shutdown the datanode and wait for it to be marked dead at the namenode
 * - Send datanode requests to Namenode and make sure it is rejected 
 * appropriately.
 */
@Test public void testDeadDatanode() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,500);
  conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1L);
  cluster=new MiniDFSCluster.Builder(conf).build();
  cluster.waitActive();
  String poolId=cluster.getNamesystem().getBlockPoolId();
  DataNode dn=cluster.getDataNodes().get(0);
  DatanodeRegistration reg=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(0),poolId);
  waitForDatanodeState(reg.getStorageID(),true,20000);
  dn.shutdown();
  waitForDatanodeState(reg.getStorageID(),false,20000);
  DatanodeProtocol dnp=cluster.getNameNode();
  Block[] blocks=new Block[]{new Block(0)};
  String[] delHints=new String[]{""};
  try {
    dnp.blockReceived(reg,poolId,blocks,delHints);
    Assert.fail("Expected IOException is not thrown");
  }
 catch (  IOException ex) {
  }
  long[] blockReport=new long[]{0L,0L,0L};
  try {
    dnp.blockReport(reg,poolId,blockReport);
    Assert.fail("Expected IOException is not thrown");
  }
 catch (  IOException ex) {
  }
  DatanodeCommand[] cmd=dnp.sendHeartbeat(reg,0,0,0,0,0,0,0);
  Assert.assertEquals(1,cmd.length);
  Assert.assertEquals(cmd[0].getAction(),DatanodeCommand.REGISTER.getAction());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testPreallocation() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
  File editLog=cluster.getNameNode().getFSImage().getEditLog().getFsEditName();
  assertEquals("Edit log should only be 4 bytes long",4,editLog.length());
  assertEquals("Edit log disk space used should be one block",4096,new DU(editLog,conf).getUsed());
  cluster.getFileSystem().mkdirs(new Path("/tmp"),new FsPermission((short)777));
  assertEquals("Edit log should be 1MB + 4 bytes long",(1024 * 1024) + 4,editLog.length());
  assertTrue("Edit log disk space used should be at least 257 blocks",257 * 4096 <= new DU(editLog,conf).getUsed());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestEditLogRace </h4><pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Most of the FSNamesystem methods have a synchronized section where they
 * update the name system itself and write to the edit log, and then
 * unsynchronized, they call logSync. This test verifies that, if an
 * operation has written to the edit log but not yet synced it,
 * we wait for that sync before entering safe mode.
 */
@Test public void testSaveRightBeforeSync() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=spy(fsimage.getEditLog());
    fsimage.editLog=editLog;
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterSync=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterSync.countDown();
        }
      }
    }
;
    Answer<Void> blockingSync=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("logSync called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it just before logSync...");
          waitToEnterSync.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to logSync. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("logSync complete");
        return null;
      }
    }
;
    doAnswer(blockingSync).when(editLog).logSync();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to just before logSync...");
    waitToEnterSync.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync about to be called.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since we have pending edits");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * The logSync() method in FSEditLog is unsynchronized whiel syncing
 * so that other threads can concurrently enqueue edits while the prior
 * sync is ongoing. This test checks that the log is saved correctly
 * if the saveImage occurs while the syncing thread is in the unsynchronized middle section.
 * This replicates the following manual test proposed by Konstantin:
 * I start the name-node in debugger.
 * I do -mkdir and stop the debugger in logSync() just before it does flush.
 * Then I enter safe mode with another client
 * I start saveNamepsace and stop the debugger in
 * FSImage.saveFSImage() -> FSEditLog.createEditLogFile()
 * -> EditLogFileOutputStream.create() ->
 * after truncating the file but before writing LAYOUT_VERSION into it.
 * Then I let logSync() run.
 * Then I terminate the name-node.
 * After that the name-node wont start, since the edits file is broken.
 */
@Test public void testSaveImageWhileSyncInProgress() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=fsimage.getEditLog();
    ArrayList<EditLogOutputStream> streams=editLog.getEditStreams();
    EditLogOutputStream spyElos=spy(streams.get(0));
    streams.set(0,spyElos);
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterFlush=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterFlush.countDown();
        }
      }
    }
;
    Answer<Void> blockingFlush=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("Flush called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it to flush section...");
          waitToEnterFlush.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to flush. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("Flush complete");
        return null;
      }
    }
;
    doAnswer(blockingFlush).when(spyElos).flush();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to enter flush...");
    waitToEnterFlush.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync is in unsynchronized section.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since flush will sleep that long");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDisplayRecentEditLogOpCodes() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  FileSystem fileSys=null;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  final FSEditLog editLog=fsimage.getEditLog();
  for (int i=0; i < 20; i++) {
    fileSys.mkdirs(new Path("/tmp/tmp" + i));
  }
  File editFile=editLog.getFsEditName();
  editLog.close();
  cluster.shutdown();
  long fileLen=editFile.length();
  RandomAccessFile rwf=new RandomAccessFile(editFile,"rw");
  rwf.seek(fileLen - 40);
  for (int i=0; i < 20; i++) {
    rwf.write(FSEditLogOpCodes.OP_DELETE.getOpCode());
  }
  rwf.close();
  String expectedErrorMessage="^Error replaying edit log at offset \\d+\n";
  expectedErrorMessage+="Recent opcode offsets: (\\d+\\s*){4}$";
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).build();
    fail("should not be able to start");
  }
 catch (  IOException e) {
    assertTrue("error message contains opcodes message",e.getMessage().matches(expectedErrorMessage));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat </h4><pre class="type-7 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void startUpCluster() throws IOException {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPL_FACTOR).build();
  assertNotNull("Failed Cluster Creation",cluster);
  cluster.waitClusterUp();
  dfs=(DistributedFileSystem)cluster.getFileSystem();
  assertNotNull("Failed to get FileSystem",dfs);
  nn=cluster.getNameNode();
  assertNotNull("Failed to get NameNode",nn);
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * test illegal args cases
 */
@Test public void testIllegalArg() throws IOException {
  long fileLen=blockSize * 3;
  Path parentDir=new Path("/parentTrg");
  assertTrue(dfs.mkdirs(parentDir));
  Path trg=new Path(parentDir,"trg");
  DFSTestUtil.createFile(dfs,trg,fileLen,REPL_FACTOR,1);
{
    Path dir1=new Path("/dir1");
    assertTrue(dfs.mkdirs(dir1));
    Path src=new Path(dir1,"src");
    DFSTestUtil.createFile(dfs,src,fileLen,REPL_FACTOR,1);
    try {
      dfs.concat(trg,new Path[]{src});
      fail("didn't fail for src and trg in different directories");
    }
 catch (    Exception e) {
    }
  }
  try {
    dfs.concat(trg,new Path[]{new Path("test1/a")});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
  try {
    dfs.concat(trg,new Path[]{});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
}

</code></pre>

<br>
<pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that the concat operation is properly persisted in the
 * edit log, and properly replayed on restart.
 */
@Test public void testConcatInEditLog() throws Exception {
  final Path TEST_DIR=new Path("/testConcatInEditLog");
  final long FILE_LEN=blockSize;
  Path[] srcFiles=new Path[3];
  for (int i=0; i < srcFiles.length; i++) {
    Path path=new Path(TEST_DIR,"src-" + i);
    DFSTestUtil.createFile(dfs,path,FILE_LEN,REPL_FACTOR,1);
    srcFiles[i]=path;
  }
  Path targetFile=new Path(TEST_DIR,"target");
  DFSTestUtil.createFile(dfs,targetFile,FILE_LEN,REPL_FACTOR,1);
  dfs.concat(targetFile,srcFiles);
  assertTrue(dfs.exists(targetFile));
  FileStatus origStatus=dfs.getFileStatus(targetFile);
  cluster.restartNameNode(true);
  assertTrue(dfs.exists(targetFile));
  assertFalse(dfs.exists(srcFiles[0]));
  FileStatus statusAfterRestart=dfs.getFileStatus(targetFile);
  assertEquals(origStatus.getModificationTime(),statusAfterRestart.getModificationTime());
}

</code></pre>

<br>
<pre class="type-10 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testConcatNotCompleteBlock() throws IOException {
  long trgFileLen=blockSize * 3;
  long srcFileLen=blockSize * 3 + 20;
  String name1="/trg", name2="/src";
  Path filePath1=new Path(name1);
  DFSTestUtil.createFile(dfs,filePath1,trgFileLen,REPL_FACTOR,1);
  HdfsFileStatus fStatus=cluster.getNameNode().getFileInfo(name1);
  long fileLen=fStatus.getLen();
  assertEquals(fileLen,trgFileLen);
  FSDataInputStream stm=dfs.open(filePath1);
  byte[] byteFile1=new byte[(int)trgFileLen];
  stm.readFully(0,byteFile1);
  stm.close();
  LocatedBlocks lb1=cluster.getNameNode().getBlockLocations(name1,0,trgFileLen);
  Path filePath2=new Path(name2);
  DFSTestUtil.createFile(dfs,filePath2,srcFileLen,REPL_FACTOR,1);
  fStatus=cluster.getNameNode().getFileInfo(name2);
  fileLen=fStatus.getLen();
  assertEquals(srcFileLen,fileLen);
  stm=dfs.open(filePath2);
  byte[] byteFile2=new byte[(int)srcFileLen];
  stm.readFully(0,byteFile2);
  stm.close();
  LocatedBlocks lb2=cluster.getNameNode().getBlockLocations(name2,0,srcFileLen);
  System.out.println("trg len=" + trgFileLen + "; src len="+ srcFileLen);
  dfs.concat(filePath1,new Path[]{filePath2});
  long totalLen=trgFileLen + srcFileLen;
  fStatus=cluster.getNameNode().getFileInfo(name1);
  fileLen=fStatus.getLen();
  stm=dfs.open(filePath1);
  byte[] byteFileConcat=new byte[(int)fileLen];
  stm.readFully(0,byteFileConcat);
  stm.close();
  LocatedBlocks lbConcat=cluster.getNameNode().getBlockLocations(name1,0,fileLen);
  assertEquals(lbConcat.locatedBlockCount(),lb1.locatedBlockCount() + lb2.locatedBlockCount());
  System.out.println("file1 len=" + fileLen + "; total len="+ totalLen);
  assertEquals(fileLen,totalLen);
  fStatus=cluster.getNameNode().getFileInfo(name2);
  assertNull("File " + name2 + "still exists",fStatus);
  checkFileContent(byteFileConcat,new byte[][]{byteFile1,byteFile2});
}

</code></pre>

<br>
<pre class="type-16 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Concatenates 10 files into one
 * Verifies the final size, deletion of the file, number of blocks
 * @throws IOException
 */
@Test public void testConcat() throws IOException, InterruptedException {
  final int numFiles=10;
  long fileLen=blockSize * 3;
  HdfsFileStatus fStatus;
  FSDataInputStream stm;
  String trg=new String("/trg");
  Path trgPath=new Path(trg);
  DFSTestUtil.createFile(dfs,trgPath,fileLen,REPL_FACTOR,1);
  fStatus=nn.getFileInfo(trg);
  long trgLen=fStatus.getLen();
  long trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  Path[] files=new Path[numFiles];
  byte[][] bytes=new byte[numFiles][(int)fileLen];
  LocatedBlocks[] lblocks=new LocatedBlocks[numFiles];
  long[] lens=new long[numFiles];
  int i=0;
  for (i=0; i < files.length; i++) {
    files[i]=new Path("/file" + i);
    Path path=files[i];
    System.out.println("Creating file " + path);
    DFSTestUtil.createFile(dfs,path,fileLen,REPL_FACTOR,1);
    fStatus=nn.getFileInfo(path.toUri().getPath());
    lens[i]=fStatus.getLen();
    assertEquals(trgLen,lens[i]);
    lblocks[i]=nn.getBlockLocations(path.toUri().getPath(),0,lens[i]);
    stm=dfs.open(path);
    stm.readFully(0,bytes[i]);
    stm.close();
  }
  final UserGroupInformation user1=UserGroupInformation.createUserForTesting("theDoctor",new String[]{"tardis"});
  DistributedFileSystem hdfs=(DistributedFileSystem)DFSTestUtil.getFileSystemAs(user1,conf);
  try {
    hdfs.concat(trgPath,files);
    fail("Permission exception expected");
  }
 catch (  IOException ie) {
    System.out.println("Got expected exception for permissions:" + ie.getLocalizedMessage());
  }
  ContentSummary cBefore=dfs.getContentSummary(trgPath.getParent());
  dfs.concat(trgPath,files);
  ContentSummary cAfter=dfs.getContentSummary(trgPath.getParent());
  assertEquals(cBefore.getFileCount(),cAfter.getFileCount() + files.length);
  long totalLen=trgLen;
  long totalBlocks=trgBlocks;
  for (i=0; i < files.length; i++) {
    totalLen+=lens[i];
    totalBlocks+=lblocks[i].locatedBlockCount();
  }
  System.out.println("total len=" + totalLen + "; totalBlocks="+ totalBlocks);
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  stm=dfs.open(trgPath);
  byte[] byteFileConcat=new byte[(int)trgLen];
  stm.readFully(0,byteFileConcat);
  stm.close();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks);
  assertEquals(trgLen,totalLen);
  for (  Path p : files) {
    fStatus=nn.getFileInfo(p.toUri().getPath());
    assertNull("File " + p + " still exists",fStatus);
    DFSTestUtil.createFile(dfs,p,fileLen,REPL_FACTOR,1);
  }
  checkFileContent(byteFileConcat,bytes);
  Path smallFile=new Path("/sfile");
  int sFileLen=10;
  DFSTestUtil.createFile(dfs,smallFile,sFileLen,REPL_FACTOR,1);
  dfs.concat(trgPath,new Path[]{smallFile});
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks + 1);
  assertEquals(trgLen,totalLen + sFileLen);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete </h4><pre class="type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void largeDelete() throws Throwable {
  mc=new MiniDFSCluster.Builder(CONF).build();
  try {
    mc.waitActive();
    Assert.assertNotNull("No Namenode in cluster",mc.getNameNode());
    createFiles();
    Assert.assertEquals(TOTAL_BLOCKS,getBlockCount());
    runThreads();
  }
  finally {
    mc.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNNLeaseRecovery </h4><pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file with 1 block
 * and invokes lease recovery method. 
 * AlreadyBeingCreatedException is expected.
 * @throws AlreadyBeingCreatedException as the result
 */
@Test(expected=AlreadyBeingCreatedException.class) public void testInternalReleaseLease_1blocks() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(1,null,HdfsConstants.BlockUCState.COMMITTED,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file, sets status of last two
 * blocks to non-defined and UNDER_CONSTRUCTION and invokes lease recovery
 * method. IOException is expected for releasing a create lock on a 
 * closed file. 
 * @throws IOException as the result
 */
@Test(expected=IOException.class) public void testInternalReleaseLease_UNKNOWN_COMM() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,null,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file, sets status of last two
 * blocks to COMMITTED and COMMITTED and invokes lease recovery
 * method. AlreadyBeingCreatedException is expected.
 * @throws AlreadyBeingCreatedException as the result
 */
@Test(expected=AlreadyBeingCreatedException.class) public void testInternalReleaseLease_COMM_COMM() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.COMMITTED,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<pre class="type-5 type-12 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Releases resources used by the test cases">TestCleaner</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Releases resources used by the test cases
- Verifies assertions inside branch conditions
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Cleans the resources and closes the instance of FSNamesystem
 * @throws IOException if an error occurred
 */
@After public void tearDown() throws IOException {
  if (fsn != null) {
    try {
      fsn.close();
    }
 catch (    Exception e) {
      LOG.error("Cannot close: ",e);
    }
 finally {
      File dir=new File(NAME_DIR);
      if (dir != null)       assertTrue("Cannot delete name-node dirs",FileUtil.fullyDelete(dir));
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNameCache </h4><pre class="type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDictionary() throws Exception {
  NameCache<String> cache=new NameCache<String>(2);
  String[] matching={"part1","part10000000","fileabc","abc","filepart"};
  String[] notMatching={"spart1","apart","abcd","def"};
  for (  String s : matching) {
    cache.put(s);
    assertTrue(s == cache.put(s));
  }
  for (  String s : notMatching) {
    cache.put(s);
  }
  cache.initialized();
  for (  String s : matching) {
    verifyNameReuse(cache,s,true);
  }
  assertEquals(matching.length,cache.size());
  for (  String s : notMatching) {
    verifyNameReuse(cache,s,false);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Regression test for HDFS-1997. Test that, if an exception
 * occurs on the client side, it is properly reported as such
 */
@Test public void testClientSideException() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
  try {
    String fsName=NameNode.getHostPortString(cluster.getNameNode().getHttpAddress());
    String id="getimage=1";
    File[] localPath=new File[]{new File("/xxxxx-does-not-exist/blah")};
    TransferFsImage.getFileClient(fsName,id,localPath,false);
    fail("Didn't get an exception!");
  }
 catch (  IOException ioe) {
    assertTrue("Expected FNFE, got: " + StringUtils.stringifyException(ioe),ioe instanceof FileNotFoundException);
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.util.TestExactSizeInputStream </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMark() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertFalse(s.markSupported());
  try {
    s.mark(1);
    fail("Mark should not succeed");
  }
 catch (  UnsupportedOperationException uoe) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testReadNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertEquals(2,s.available());
  assertEquals((int)'h',s.read());
  assertEquals((int)'e',s.read());
  try {
    s.read();
    fail("Read when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testReadArrayNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  byte[] buf=new byte[10];
  assertEquals(2,s.read(buf,0,5));
  try {
    s.read(buf,2,3);
    fail("Read buf when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSkipNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertEquals(2,s.skip(3));
  try {
    s.skip(1);
    fail("Skip when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.security.TestRefreshUserMappings </h4><pre class="type-16 type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGroupMappingRefresh() throws Exception {
  DFSAdmin admin=new DFSAdmin(config);
  String[] args=new String[]{"-refreshUserToGroupsMappings"};
  Groups groups=Groups.getUserToGroupsMappingService(config);
  String user=UserGroupInformation.getCurrentUser().getUserName();
  System.out.println("first attempt:");
  List<String> g1=groups.getGroups(user);
  String[] str_groups=new String[g1.size()];
  g1.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  System.out.println("second attempt, should be same:");
  List<String> g2=groups.getGroups(user);
  g2.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g2.size(); i++) {
    assertEquals("Should be same group ",g1.get(i),g2.get(i));
  }
  admin.run(args);
  System.out.println("third attempt(after refresh command), should be different:");
  List<String> g3=groups.getGroups(user);
  g3.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g3.size(); i++) {
    assertFalse("Should be different group: " + g1.get(i) + " and "+ g3.get(i),g1.get(i).equals(g3.get(i)));
  }
  Thread.sleep(groupRefreshTimeoutSec * 1100);
  System.out.println("fourth attempt(after timeout), should be different:");
  List<String> g4=groups.getGroups(user);
  g4.toArray(str_groups);
  System.out.println(Arrays.toString(str_groups));
  for (int i=0; i < g4.size(); i++) {
    assertFalse("Should be different group ",g3.get(i).equals(g4.get(i)));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.tools.TestDelegationTokenFetcher </h4><pre class="type-10 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Verify that when the DelegationTokenFetcher runs, it talks to the Namenode,
 * pulls out the correct user's token and successfully serializes it to disk.
 */
@Test public void expectedTokenIsRetrievedFromDFS() throws Exception {
  final byte[] ident=new DelegationTokenIdentifier(new Text("owner"),new Text("renewer"),new Text("realuser")).getBytes();
  final byte[] pw=new byte[]{42};
  final Text kind=new Text("MY-KIND");
  final Text service=new Text(uri.toString());
  Token<DelegationTokenIdentifier> t=new Token<DelegationTokenIdentifier>(ident,pw,kind,service);
  when(dfs.getDelegationToken((String)null)).thenReturn(t);
  when(dfs.renewDelegationToken(eq(t))).thenReturn(1000L);
  when(dfs.getUri()).thenReturn(uri);
  FileSystem fileSys=FileSystem.getLocal(conf);
  try {
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),tokenFile});
    Path p=new Path(fileSys.getWorkingDirectory(),tokenFile);
    Credentials creds=Credentials.readTokenStorageFile(p,conf);
    Iterator<Token<?>> itr=creds.getAllTokens().iterator();
    assertTrue(itr.hasNext());
    assertEquals(t,itr.next());
    assertTrue(!itr.hasNext());
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--print",tokenFile});
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--renew",tokenFile});
    DelegationTokenFetcher.main(new String[]{"-fs",uri.toString(),"--cancel",tokenFile});
    verify(dfs).renewDelegationToken(eq(t));
    verify(dfs).cancelDelegationToken(eq(t));
  }
  finally {
    fileSys.delete(new Path(tokenFile),true);
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

<h3><span class=" glyphicon glyphicon-tag"/>&nbspUtilityVerifier</h3><kbd>Verifies (un)successful execution of the test case by reporting explicitly a failure</kbd><br><br><br><h4 style="margin:0px">Class: TestFuseDFS </h4><pre class="type-3 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test concurrent creation and access of the mount 
 */
@Test public void testMultipleThreads() throws IOException {
  ArrayList<Thread> threads=new ArrayList<Thread>();
  final AtomicReference<String> errorMessage=new AtomicReference<String>();
  for (int i=0; i < 10; i++) {
    Thread t=new Thread(){
      public void run(){
        try {
          File d=new File(mountPoint,"dir" + getId());
          execWaitRet("mkdir " + d.getAbsolutePath());
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            final String contents="thread " + getId() + " "+ j;
            createFile(f,contents);
          }
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            execWaitRet("cat " + f.getAbsolutePath());
            execWaitRet("rm " + f.getAbsolutePath());
          }
          execWaitRet("rmdir " + d.getAbsolutePath());
        }
 catch (        IOException ie) {
          errorMessage.set(String.format("Exception %s",StringUtils.stringifyException(ie)));
        }
      }
    }
;
    t.start();
    threads.add(t);
  }
  for (  Thread t : threads) {
    try {
      t.join();
    }
 catch (    InterruptedException ie) {
      fail("Thread interrupted: " + ie.getMessage());
    }
  }
  assertNull(errorMessage.get(),errorMessage.get());
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test random access to a file 
 */
@Test public void testRandomAccess() throws IOException {
  final String contents="hello world";
  File f=new File(mountPoint,"file1");
  createFile(f,contents);
  RandomAccessFile raf=new RandomAccessFile(f,"rw");
  raf.seek(f.length());
  try {
    raf.write('b');
  }
 catch (  IOException e) {
    assertEquals("Operation not supported",e.getMessage());
  }
 finally {
    raf.close();
  }
  raf=new RandomAccessFile(f,"rw");
  raf.seek(0);
  try {
    raf.write('b');
    fail("Over-wrote existing bytes");
  }
 catch (  IOException e) {
    assertEquals("Invalid argument",e.getMessage());
  }
 finally {
    raf.close();
  }
  execAssertSucceeds("rm " + f.getAbsolutePath());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFcHdfsSymlink </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testAccessLinkFromAbstractFileSystem() throws IOException {
  Path file=new Path(testBaseDir1(),"file");
  Path link=new Path(testBaseDir1(),"linkToFile");
  createAndWriteFile(file);
  fc.createSymlink(file,link,false);
  try {
    AbstractFileSystem afs=fc.getDefaultFileSystem();
    afs.open(link);
    fail("Opened a link using AFS");
  }
 catch (  UnresolvedLinkException x) {
  }
}

</code></pre>

<br>
<pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testCreateWithPartQualPathFails() throws IOException {
  Path fileWoAuth=new Path("hdfs:///test/file");
  Path linkWoAuth=new Path("hdfs:///test/link");
  try {
    createAndWriteFile(fileWoAuth);
    fail("HDFS requires URIs with schemes have an authority");
  }
 catch (  RuntimeException e) {
  }
  try {
    fc.createSymlink(new Path("foo"),linkWoAuth,false);
    fail("HDFS requires URIs with schemes have an authority");
  }
 catch (  RuntimeException e) {
  }
}

</code></pre>

<br>
<pre class="type-10 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testCreateLinkMaxPathLink() throws IOException {
  Path dir=new Path(testBaseDir1());
  Path file=new Path(testBaseDir1(),"file");
  final int maxPathLen=FSConstants.MAX_PATH_LENGTH;
  final int dirLen=dir.toString().length() + 1;
  int len=maxPathLen - dirLen;
  StringBuilder sb=new StringBuilder("");
  for (int i=0; i < (len / 10); i++) {
    sb.append("0123456789");
  }
  for (int i=0; i < (len % 10); i++) {
    sb.append("x");
  }
  Path link=new Path(sb.toString());
  assertEquals(maxPathLen,dirLen + link.toString().length());
  createAndWriteFile(file);
  fc.setWorkingDirectory(dir);
  fc.createSymlink(file,link,false);
  readFile(link);
  link=new Path(sb.toString() + "x");
  try {
    fc.createSymlink(file,link,false);
    fail("Path name should be too long");
  }
 catch (  IOException x) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestFiListPath </h4><pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Remove the target directory after the getListing RPC 
 */
@Test public void testTargetDeletionForListStatus() throws Exception {
  LOG.info("Test Target Delete For listStatus");
  try {
    fs.listStatus(TEST_PATH);
    fail("Test should fail with FileNotFoundException");
  }
 catch (  FileNotFoundException e) {
    assertEquals("File " + TEST_PATH + " does not exist.",e.getMessage());
    LOG.info(StringUtils.stringifyException(e));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.fs.TestResolveHdfsSymlink </h4><pre class="type-12 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests resolution of an hdfs symlink to the local file system.
 * @throws IOException
 * @throws InterruptedException
 */
@Test public void testFcResolveAfs() throws IOException, InterruptedException {
  Configuration conf=new Configuration();
  FileContext fcLocal=FileContext.getLocalFSFileContext();
  FileContext fcHdfs=FileContext.getFileContext(cluster.getFileSystem().getUri());
  Path alphaLocalPath=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp/alpha");
  DFSTestUtil.createFile(FileSystem.getLocal(conf),alphaLocalPath,16,(short)1,2);
  Path linkTarget=new Path(fcLocal.getDefaultFileSystem().getUri().toString(),"/tmp");
  Path hdfsLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString(),"/tmp/link");
  fcHdfs.createSymlink(linkTarget,hdfsLink,true);
  Path alphaHdfsPathViaLink=new Path(fcHdfs.getDefaultFileSystem().getUri().toString() + "/tmp/link/alpha");
  Set<AbstractFileSystem> afsList=fcHdfs.resolveAbstractFileSystems(alphaHdfsPathViaLink);
  Assert.assertEquals(2,afsList.size());
  for (  AbstractFileSystem afs : afsList) {
    if ((!afs.equals(fcHdfs.getDefaultFileSystem())) && (!afs.equals(fcLocal.getDefaultFileSystem()))) {
      Assert.fail("Failed to resolve AFS correctly");
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestAbandonBlock </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testQuotaUpdatedWhenBlockAbandoned() throws IOException {
  DistributedFileSystem dfs=(DistributedFileSystem)fs;
  dfs.setQuota(new Path("/"),FSConstants.QUOTA_DONT_SET,3 * 1024 * 1024);
  String src=FILE_NAME_PREFIX + "test_quota1";
  FSDataOutputStream fout=fs.create(new Path(src),true,4096,(short)2,1024 * 1024);
  for (int i=0; i < 1024; i++) {
    fout.writeByte(123);
  }
  cluster.getDataNodes().get(0).shutdown();
  try {
    fout.close();
  }
 catch (  QuotaExceededException e) {
    fail("Unexpected quota exception when closing fout");
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testGetNewStamp() throws IOException {
  int numDataNodes=1;
  Configuration conf=new HdfsConfiguration();
  conf.setBoolean("dfs.support.append",true);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
  try {
    cluster.waitActive();
    FileSystem fileSys=cluster.getFileSystem();
    NameNode namenode=cluster.getNameNode();
    Path file=new Path("dataprotocol.dat");
    DFSTestUtil.createFile(fileSys,file,1L,(short)numDataNodes,0L);
    ExtendedBlock firstBlock=DFSTestUtil.getFirstBlock(fileSys,file);
    try {
      namenode.updateBlockForPipeline(firstBlock,"");
      Assert.fail("Can not get a new GS from a finalized block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("is not under Construction"));
    }
    try {
      long newBlockId=firstBlock.getBlockId() + 1;
      ExtendedBlock newBlock=new ExtendedBlock(firstBlock.getBlockPoolId(),newBlockId,0,firstBlock.getGenerationStamp());
      namenode.updateBlockForPipeline(newBlock,"");
      Assert.fail("Cannot get a new GS from a non-existent block");
    }
 catch (    IOException e) {
      Assert.assertTrue(e.getMessage().contains("does not exist"));
    }
    DFSOutputStream out=null;
    try {
      out=(DFSOutputStream)(fileSys.append(file).getWrappedStream());
      out.write(1);
      out.hflush();
      FSDataInputStream in=null;
      try {
        in=fileSys.open(file);
        firstBlock=DFSTestUtil.getAllBlocks(in).get(0).getBlock();
      }
  finally {
        IOUtils.closeStream(in);
      }
      DFSClient dfs=((DistributedFileSystem)fileSys).dfs;
      try {
        namenode.updateBlockForPipeline(firstBlock,"test" + dfs.clientName);
        Assert.fail("Cannot get a new GS for a non lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      try {
        namenode.updateBlockForPipeline(firstBlock,null);
        Assert.fail("Cannot get a new GS for a null lease holder");
      }
 catch (      LeaseExpiredException e) {
        Assert.assertTrue(e.getMessage().startsWith("Lease mismatch"));
      }
      namenode.updateBlockForPipeline(firstBlock,dfs.clientName);
    }
  finally {
      IOUtils.closeStream(out);
    }
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSClientExcludedNodes </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testExcludedNodes() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  FileSystem fs=cluster.getFileSystem();
  Path filePath=new Path("/testExcludedNodes");
  cluster.stopDataNode(AppendTestUtil.nextInt(3));
  OutputStream out=fs.create(filePath,true,4096);
  out.write(20);
  try {
    out.close();
  }
 catch (  Exception e) {
    fail("DataNode failure should not result in a block abort: \n" + e.getMessage());
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUpgrade </h4><pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test(expected=IOException.class) public void testUpgradeFromPreUpgradeLVFails() throws IOException {
  Storage.checkVersionUpgradable(Storage.LAST_PRE_UPGRADE_LAYOUT_VERSION + 1);
  fail("Expected IOException is not thrown");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUtil </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * Tests for empty configuration, an exception is thrown from{@link DFSUtil#getNNServiceRpcAddresses(Configuration)}{@link DFSUtil#getBackupNodeAddresses(Configuration)}{@link DFSUtil#getSecondaryNameNodeAddresses(Configuration)}
 */
@Test public void testEmptyConf(){
  HdfsConfiguration conf=new HdfsConfiguration(false);
  try {
    DFSUtil.getNNServiceRpcAddresses(conf);
    fail("Expected IOException is not thrown");
  }
 catch (  IOException expected) {
  }
  try {
    DFSUtil.getBackupNodeAddresses(conf);
    fail("Expected IOException is not thrown");
  }
 catch (  IOException expected) {
  }
  try {
    DFSUtil.getSecondaryNameNodeAddresses(conf);
    fail("Expected IOException is not thrown");
  }
 catch (  IOException expected) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDistributedFileSystem </h4><pre class="type-16 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testFileChecksum() throws Exception {
  ((Log4JLogger)HftpFileSystem.LOG).getLogger().setLevel(Level.ALL);
  final long seed=RAN.nextLong();
  System.out.println("seed=" + seed);
  RAN.setSeed(seed);
  final Configuration conf=getTestConfiguration();
  conf.set(DFSConfigKeys.DFS_DATANODE_HOST_NAME_KEY,"localhost");
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem hdfs=cluster.getFileSystem();
  final String hftpuri="hftp://" + conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY);
  System.out.println("hftpuri=" + hftpuri);
  final FileSystem hftp=new Path(hftpuri).getFileSystem(conf);
  final String dir="/filechecksum";
  final int block_size=1024;
  final int buffer_size=conf.getInt("io.file.buffer.size",4096);
  conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,512);
  for (int n=0; n < 5; n++) {
    final byte[] data=new byte[RAN.nextInt(block_size / 2 - 1) + n * block_size + 1];
    RAN.nextBytes(data);
    System.out.println("data.length=" + data.length);
    final Path foo=new Path(dir,"foo" + n);
{
      final FSDataOutputStream out=hdfs.create(foo,false,buffer_size,(short)2,block_size);
      out.write(data);
      out.close();
    }
    final FileChecksum hdfsfoocs=hdfs.getFileChecksum(foo);
    System.out.println("hdfsfoocs=" + hdfsfoocs);
    final FileChecksum hftpfoocs=hftp.getFileChecksum(foo);
    System.out.println("hftpfoocs=" + hftpfoocs);
    final Path qualified=new Path(hftpuri + dir,"foo" + n);
    final FileChecksum qfoocs=hftp.getFileChecksum(qualified);
    System.out.println("qfoocs=" + qfoocs);
    final Path bar=new Path(dir,"bar" + n);
{
      final FSDataOutputStream out=hdfs.create(bar,false,buffer_size,(short)2,block_size);
      out.write(data);
      out.close();
    }
{
      final FileChecksum barcs=hdfs.getFileChecksum(bar);
      final int barhashcode=barcs.hashCode();
      assertEquals(hdfsfoocs.hashCode(),barhashcode);
      assertEquals(hdfsfoocs,barcs);
      assertEquals(hftpfoocs.hashCode(),barhashcode);
      assertEquals(hftpfoocs,barcs);
      assertEquals(qfoocs.hashCode(),barhashcode);
      assertEquals(qfoocs,barcs);
    }
{
      hdfs.setPermission(new Path(dir),new FsPermission((short)0));
      try {
        final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
        final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,conf,0,"somegroup");
        hftp2.getFileChecksum(qualified);
        fail();
      }
 catch (      IOException ioe) {
        FileSystem.LOG.info("GOOD: getting an exception",ioe);
      }
    }
  }
  cluster.shutdown();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileStatus </h4><pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test FileStatus objects obtained from a directory 
 */
@Test public void testGetFileStatusOnDir() throws Exception {
  Path dir=new Path("/test/mkdirs");
  assertTrue("mkdir failed",fs.mkdirs(dir));
  assertTrue("mkdir failed",fs.exists(dir));
  FileStatus status=fs.getFileStatus(dir);
  assertTrue(dir + " should be a directory",status.isDirectory());
  assertTrue(dir + " should be zero size ",status.getLen() == 0);
  assertEquals(dir.makeQualified(fs.getUri(),fs.getWorkingDirectory()).toString(),status.getPath().toString());
  FileStatus[] stats=fs.listStatus(dir);
  assertEquals(dir + " should be empty",0,stats.length);
  assertEquals(dir + " should be zero size ",0,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " should be zero size using hftp",0,hftpfs.getContentSummary(dir).getLength());
  RemoteIterator<FileStatus> itor=fc.listStatus(dir);
  assertFalse(dir + " should be empty",itor.hasNext());
  Path file2=new Path(dir,"filestatus2.dat");
  writeFile(fs,file2,1,blockSize / 4,blockSize);
  checkFile(fs,file2,1);
  status=fs.getFileStatus(file2);
  assertEquals(blockSize,status.getBlockSize());
  assertEquals(1,status.getReplication());
  file2=fs.makeQualified(file2);
  assertEquals(file2.toString(),status.getPath().toString());
  Path file3=new Path(dir,"filestatus3.dat");
  writeFile(fs,file3,1,blockSize / 4,blockSize);
  checkFile(fs,file3,1);
  file3=fs.makeQualified(file3);
  final int expected=blockSize / 2;
  assertEquals(dir + " size should be " + expected,expected,fs.getContentSummary(dir).getLength());
  assertEquals(dir + " size should be " + expected+ " using hftp",expected,hftpfs.getContentSummary(dir).getLength());
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have two entries",2,stats.length);
  assertEquals(file2.toString(),stats[0].getPath().toString());
  assertEquals(file3.toString(),stats[1].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir3=fs.makeQualified(new Path(dir,"dir3"));
  fs.mkdirs(dir3);
  dir3=fs.makeQualified(dir3);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have three entries",3,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(file2.toString(),stats[1].getPath().toString());
  assertEquals(file3.toString(),stats[2].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse("Unexpected addtional file",itor.hasNext());
  Path dir4=fs.makeQualified(new Path(dir,"dir4"));
  fs.mkdirs(dir4);
  dir4=fs.makeQualified(dir4);
  Path dir5=fs.makeQualified(new Path(dir,"dir5"));
  fs.mkdirs(dir5);
  dir5=fs.makeQualified(dir5);
  stats=fs.listStatus(dir);
  assertEquals(dir + " should have five entries",5,stats.length);
  assertEquals(dir3.toString(),stats[0].getPath().toString());
  assertEquals(dir4.toString(),stats[1].getPath().toString());
  assertEquals(dir5.toString(),stats[2].getPath().toString());
  assertEquals(file2.toString(),stats[3].getPath().toString());
  assertEquals(file3.toString(),stats[4].getPath().toString());
  itor=fc.listStatus(dir);
  assertEquals(dir3.toString(),itor.next().getPath().toString());
  assertEquals(dir4.toString(),itor.next().getPath().toString());
  assertEquals(dir5.toString(),itor.next().getPath().toString());
  assertEquals(file2.toString(),itor.next().getPath().toString());
  assertEquals(file3.toString(),itor.next().getPath().toString());
  assertFalse(itor.hasNext());
{
    fs.setPermission(dir,new FsPermission((short)0));
    try {
      final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
      final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,conf,0,"somegroup");
      hftp2.getContentSummary(dir);
      fail();
    }
 catch (    IOException ioe) {
      FileSystem.LOG.info("GOOD: getting an exception",ioe);
    }
  }
}

</code></pre>

<br>
<pre class="type-3 type-8 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test getting a FileStatus object using a non-existant path 
 */
@Test public void testGetFileStatusOnNonExistantFileDir() throws IOException {
  Path dir=new Path("/test/mkdirs");
  try {
    fs.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fc.listStatus(dir);
    fail("listStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertEquals("File " + dir + " does not exist.",fe.getMessage());
  }
  try {
    fs.getFileStatus(dir);
    fail("getFileStatus of non-existent path should fail");
  }
 catch (  FileNotFoundException fe) {
    assertTrue("Exception doesn't indicate non-existant path",fe.getMessage().startsWith("File does not exist"));
  }
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test calling getFileInfo directly on the client 
 */
@Test public void testGetFileInfo() throws IOException {
  Path path=new Path("/");
  assertTrue("/ should be a directory",fs.getFileStatus(path).isDirectory());
  HdfsFileStatus fileInfo=dfsClient.getFileInfo("/noSuchFile");
  assertEquals("Non-existant file should result in null",null,fileInfo);
  try {
    dfsClient.getFileInfo("non-absolute");
    fail("getFileInfo for a non-absolute path did not throw IOException");
  }
 catch (  RemoteException re) {
    assertTrue("Wrong exception for invalid file name",re.toString().contains("Invalid file name"));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRecovery2 </h4><pre class="type-16 type-10 type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the soft lease expiration period to be short 1s. Thus triggering
 * soft lease expiration to happen immediately by having another client
 * trying to create the same file.
 * The test makes sure that the lease recovery completes.
 * @throws Exception
 */
@Test public void testSoftLeaseRecovery() throws Exception {
  Map<String,String[]> u2g_map=new HashMap<String,String[]>(1);
  u2g_map.put(fakeUsername,new String[]{fakeGroup});
  DFSTestUtil.updateConfWithFakeGroupMapping(conf,u2g_map);
  String filestr="/foo" + AppendTestUtil.nextInt();
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
{
    UserGroupInformation ugi=UserGroupInformation.createUserForTesting(fakeUsername,new String[]{fakeGroup});
    FileSystem dfs2=DFSTestUtil.getFileSystemAs(ugi,conf);
    boolean done=false;
    for (int i=0; i < 10 && !done; i++) {
      AppendTestUtil.LOG.info("i=" + i);
      try {
        dfs2.create(filepath,false,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
        fail("Creation of an existing file should never succeed.");
      }
 catch (      FileAlreadyExistsException ex) {
        done=true;
      }
catch (      AlreadyBeingCreatedException ex) {
        AppendTestUtil.LOG.info("GOOD! got " + ex.getMessage());
      }
catch (      IOException ioe) {
        AppendTestUtil.LOG.warn("UNEXPECTED IOException",ioe);
      }
      if (!done) {
        AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
        try {
          Thread.sleep(5000);
        }
 catch (        InterruptedException e) {
        }
      }
    }
    assertTrue(done);
  }
  AppendTestUtil.LOG.info("Lease for file " + filepath + " is recovered. "+ "Validating its contents now...");
  long fileSize=dfs.getFileStatus(filepath).getLen();
  assertTrue("File should be " + size + " bytes, but is actually "+ " found to be "+ fileSize+ " bytes",fileSize == size);
  AppendTestUtil.LOG.info("File size is good. " + "Now validating data and sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * This test makes the client does not renew its lease and also
 * set the hard lease expiration period to be short 1s. Thus triggering
 * lease expiration to happen while the client is still alive.
 * The test makes sure that the lease recovery completes and the client
 * fails if it continues to write to the file.
 * @throws Exception
 */
@Test public void testHardLeaseRecovery() throws Exception {
  String filestr="/hardLeaseRecovery";
  AppendTestUtil.LOG.info("filestr=" + filestr);
  Path filepath=new Path(filestr);
  FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
  assertTrue(dfs.dfs.exists(filestr));
  int size=AppendTestUtil.nextInt(FILE_SIZE);
  AppendTestUtil.LOG.info("size=" + size);
  stm.write(buffer,0,size);
  AppendTestUtil.LOG.info("hflush");
  stm.hflush();
  AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
  dfs.dfs.leaserenewer.interruptAndJoin();
  cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
  LocatedBlocks locatedBlocks;
  do {
    Thread.sleep(SHORT_LEASE_PERIOD);
    locatedBlocks=DFSClient.callGetBlockLocations(dfs.dfs.namenode,filestr,0L,size);
  }
 while (locatedBlocks.isUnderConstruction());
  assertEquals(size,locatedBlocks.getFileLength());
  try {
    stm.write('b');
    stm.close();
    fail("Writer thread should have been killed");
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
  AppendTestUtil.LOG.info("File size is good. Now validating sizes from datanodes...");
  AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestLeaseRenewer </h4><pre class="type-12 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testRenewal() throws Exception {
  final AtomicInteger leaseRenewalCount=new AtomicInteger();
  Mockito.doAnswer(new Answer<Void>(){
    @Override public Void answer(    InvocationOnMock invocation) throws Throwable {
      leaseRenewalCount.incrementAndGet();
      return null;
    }
  }
).when(MOCK_DFSCLIENT).renewLease();
  DFSOutputStream mockStream=Mockito.mock(DFSOutputStream.class);
  String filePath="/foo";
  renewer.put(filePath,mockStream,MOCK_DFSCLIENT);
  long failTime=System.currentTimeMillis() + 5000;
  while (System.currentTimeMillis() < failTime && leaseRenewalCount.get() == 0) {
    Thread.sleep(50);
  }
  if (leaseRenewalCount.get() == 0) {
    Assert.fail("Did not renew lease at all!");
  }
  renewer.closeFile(filePath,MOCK_DFSCLIENT);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestListPathServlet </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testListStatus() throws Exception {
  checkStatus("/");
  createFile("/a",1);
  createFile("/b",1);
  mkdirs("/dir");
  checkFile(new Path("/a"));
  checkFile(new Path("/b"));
  checkStatus("/");
  createFile("/dir/.a.crc",1);
  createFile("/dir/b",1);
  mkdirs("/dir/dir1");
  checkFile(new Path("/dir/.a.crc"));
  checkFile(new Path("/dir/b"));
  checkStatus("/dir");
  checkStatus("/nonexistent");
  checkStatus("/nonexistent/a");
  final String username=UserGroupInformation.getCurrentUser().getShortUserName() + "1";
  final HftpFileSystem hftp2=cluster.getHftpFileSystemAs(username,CONF,0,"somegroup");
{
    final Path nonexistent=new Path("/nonexistent");
    try {
      hftp2.getFileStatus(nonexistent);
      Assert.fail();
    }
 catch (    IOException ioe) {
      FileSystem.LOG.info("GOOD: getting an exception",ioe);
    }
  }
{
    final Path dir=new Path("/dir");
    fs.setPermission(dir,new FsPermission((short)0));
    try {
      hftp2.getFileStatus(new Path(dir,"a"));
      Assert.fail();
    }
 catch (    IOException ioe) {
      FileSystem.LOG.info("GOOD: getting an exception",ioe);
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestParallelRead </h4><pre class="type-12 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * Do parallel read several times with different number of files and threads.
 * Note that while this is the only "test" in a junit sense, we're actually
 * dispatching a lot more. Failures in the other methods (and other threads)
 * need to be manually collected, which is inconvenient.
 */
@Test public void testParallelRead() throws IOException {
  if (!runParallelRead(1,4)) {
    fail("Check log for errors");
  }
  if (!runParallelRead(1,16)) {
    fail("Check log for errors");
  }
  if (!runParallelRead(2,4)) {
    fail("Check log for errors");
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestSafeMode </h4><pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Run various fs operations while the NN is in safe mode,
 * assert that they are either allowed or fail as expected.
 */
@Test public void testOperationsWhileInSafeMode() throws IOException {
  final Path file1=new Path("/file1");
  assertFalse(dfs.setSafeMode(SafeModeAction.SAFEMODE_GET));
  DFSTestUtil.createFile(fs,file1,1024,(short)1,0);
  assertTrue("Could not enter SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER));
  runFsFun("Set quota while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      ((DistributedFileSystem)fs).setQuota(file1,1,1);
    }
  }
);
  runFsFun("Set perm while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setPermission(file1,FsPermission.getDefault());
    }
  }
);
  runFsFun("Set owner while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setOwner(file1,"user","group");
    }
  }
);
  runFsFun("Set repl while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.setReplication(file1,(short)1);
    }
  }
);
  runFsFun("Append file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      DFSTestUtil.appendFile(fs,file1,"new bytes");
    }
  }
);
  runFsFun("Delete file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.delete(file1,false);
    }
  }
);
  runFsFun("Rename file while in SM",new FSRun(){
    public void run(    FileSystem fs) throws IOException {
      fs.rename(file1,new Path("file2"));
    }
  }
);
  try {
    fs.setTimes(file1,0,0);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  try {
    DFSTestUtil.readFile(fs,file1);
  }
 catch (  IOException ioe) {
    fail("Set times failed while in SM");
  }
  assertFalse("Could not leave SM",dfs.setSafeMode(SafeModeAction.SAFEMODE_LEAVE));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.TestDelegationToken </h4><pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testCancelDelegationToken() throws Exception {
  DelegationTokenSecretManager dtSecretManager=cluster.getNamesystem().getDelegationTokenSecretManager();
  Token<DelegationTokenIdentifier> token=generateDelegationToken("SomeUser","JobTracker");
  try {
    dtSecretManager.cancelToken(token,"FakeCanceller");
    Assert.fail("should have failed");
  }
 catch (  AccessControlException ace) {
  }
  dtSecretManager.cancelToken(token,"JobTracker");
  try {
    dtSecretManager.renewToken(token,"JobTracker");
    Assert.fail("should have failed");
  }
 catch (  InvalidToken it) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testDelegationTokenWithDoAs() throws Exception {
  final DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
  final Token<DelegationTokenIdentifier> token=dfs.getDelegationToken("JobTracker");
  final UserGroupInformation longUgi=UserGroupInformation.createRemoteUser("JobTracker/foo.com@FOO.COM");
  final UserGroupInformation shortUgi=UserGroupInformation.createRemoteUser("JobTracker");
  longUgi.doAs(new PrivilegedExceptionAction(){
    public Object run() throws IOException {
      final DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      try {
        dfs.renewDelegationToken(token);
      }
 catch (      IOException e) {
        Assert.fail("Could not renew delegation token for user " + longUgi);
      }
      return null;
    }
  }
);
  shortUgi.doAs(new PrivilegedExceptionAction(){
    public Object run() throws IOException {
      final DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      dfs.renewDelegationToken(token);
      return null;
    }
  }
);
  longUgi.doAs(new PrivilegedExceptionAction(){
    public Object run() throws IOException {
      final DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
      try {
        dfs.cancelDelegationToken(token);
      }
 catch (      IOException e) {
        Assert.fail("Could not cancel delegation token for user " + longUgi);
      }
      return null;
    }
  }
);
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDelegationTokenSecretManager() throws Exception {
  DelegationTokenSecretManager dtSecretManager=cluster.getNamesystem().getDelegationTokenSecretManager();
  Token<DelegationTokenIdentifier> token=generateDelegationToken("SomeUser","JobTracker");
  try {
    dtSecretManager.renewToken(token,"FakeRenewer");
    Assert.fail("should have failed");
  }
 catch (  AccessControlException ace) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  DelegationTokenIdentifier identifier=new DelegationTokenIdentifier();
  byte[] tokenId=token.getIdentifier();
  identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
  Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
  LOG.info("Sleep to expire the token");
  Thread.sleep(6000);
  try {
    dtSecretManager.retrievePassword(identifier);
    Assert.fail("Token should have expired");
  }
 catch (  InvalidToken e) {
  }
  dtSecretManager.renewToken(token,"JobTracker");
  LOG.info("Sleep beyond the max lifetime");
  Thread.sleep(5000);
  try {
    dtSecretManager.renewToken(token,"JobTracker");
    Assert.fail("should have been expired");
  }
 catch (  InvalidToken it) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.security.token.block.TestBlockToken </h4><pre class="type-16 type-10 type-12 type-3 type-9 type-18 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions inside branch conditions">BranchVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Sets implicit assumptions ">AssumptionSetter</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies assertions inside branch conditions
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Sets implicit assumptions 
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that fast repeated invocations of createClientDatanodeProtocolProxy
 * will not end up using up thousands of sockets. This is a regression test for
 * HDFS-1965.
 */
@Test public void testBlockTokenRpcLeak() throws Exception {
  Assume.assumeTrue(FD_DIR.exists());
  BlockTokenSecretManager sm=new BlockTokenSecretManager(true,blockKeyUpdateInterval,blockTokenLifetime);
  Token<BlockTokenIdentifier> token=sm.generateToken(block3,EnumSet.allOf(BlockTokenSecretManager.AccessMode.class));
  final Server server=createMockDatanode(sm,token);
  server.start();
  final InetSocketAddress addr=NetUtils.getConnectAddress(server);
  DatanodeID fakeDnId=new DatanodeID("localhost:" + addr.getPort(),"fake-storage",0,addr.getPort());
  ExtendedBlock b=new ExtendedBlock("fake-pool",new Block(12345L));
  LocatedBlock fakeBlock=new LocatedBlock(b,new DatanodeInfo[0]);
  fakeBlock.setBlockToken(token);
  ClientDatanodeProtocol proxyToNoWhere=RPC.getProxy(ClientDatanodeProtocol.class,ClientDatanodeProtocol.versionID,new InetSocketAddress("1.1.1.1",1),UserGroupInformation.createRemoteUser("junk"),conf,NetUtils.getDefaultSocketFactory(conf));
  ClientDatanodeProtocol proxy=null;
  int fdsAtStart=countOpenFileDescriptors();
  try {
    long endTime=System.currentTimeMillis() + 3000;
    while (System.currentTimeMillis() < endTime) {
      proxy=DFSTestUtil.createClientDatanodeProtocolProxy(fakeDnId,conf,1000,fakeBlock);
      assertEquals(block3.getBlockId(),proxy.getReplicaVisibleLength(block3));
      if (proxy != null) {
        RPC.stopProxy(proxy);
      }
      LOG.info("Num open fds:" + countOpenFileDescriptors());
    }
    int fdsAtEnd=countOpenFileDescriptors();
    if (fdsAtEnd - fdsAtStart > 50) {
      fail("Leaked " + (fdsAtEnd - fdsAtStart) + " fds!");
    }
  }
  finally {
    server.stop();
  }
  RPC.stopProxy(proxyToNoWhere);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * BlockRecovery_02.8.
 * Two replicas are in Finalized state
 * @throws IOException in case of an error
 */
@Test public void testFinalizedReplicas() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  ReplicaRecoveryInfo replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  ReplicaRecoveryInfo replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 2,ReplicaState.FINALIZED);
  InterDatanodeProtocol dn1=mock(InterDatanodeProtocol.class);
  InterDatanodeProtocol dn2=mock(InterDatanodeProtocol.class);
  testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
  verify(dn1).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  verify(dn2).updateReplicaUnderRecovery(block,RECOVERY_ID,REPLICA_LEN1);
  replica1=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN1,GEN_STAMP - 1,ReplicaState.FINALIZED);
  replica2=new ReplicaRecoveryInfo(BLOCK_ID,REPLICA_LEN2,GEN_STAMP - 2,ReplicaState.FINALIZED);
  try {
    testSyncReplicas(replica1,replica2,dn1,dn2,REPLICA_LEN1);
    Assert.fail("Two finalized replicas should not have different lengthes!");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("Inconsistent size of finalized replicas. "));
  }
}

</code></pre>

<br>
<pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * BlockRecoveryFI_10. DN has no ReplicaUnderRecovery.
 * @throws IOException in case of an error
 */
@Test public void testNoReplicaUnderRecovery() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  dn.data.createRbw(block);
  try {
    dn.syncBlock(rBlock,initBlockRecords(dn));
    fail("Sync should fail");
  }
 catch (  IOException e) {
    e.getMessage().startsWith("Cannot recover ");
  }
  DatanodeProtocol namenode=dn.getBPNamenode(POOL_ID);
  verify(namenode,never()).commitBlockSynchronization(any(ExtendedBlock.class),anyLong(),anyLong(),anyBoolean(),anyBoolean(),any(DatanodeID[].class));
}

</code></pre>

<br>
<pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * BlockRecoveryFI_11. a replica's recovery id does not match new GS.
 * @throws IOException in case of an error
 */
@Test public void testNotMatchedReplicaID() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  ReplicaInPipelineInterface replicaInfo=dn.data.createRbw(block);
  BlockWriteStreams streams=null;
  try {
    streams=replicaInfo.createStreams(true,0,0);
    streams.checksumOut.write('a');
    dn.data.initReplicaRecovery(new RecoveringBlock(block,null,RECOVERY_ID + 1));
    try {
      dn.syncBlock(rBlock,initBlockRecords(dn));
      fail("Sync should fail");
    }
 catch (    IOException e) {
      e.getMessage().startsWith("Cannot recover ");
    }
    DatanodeProtocol namenode=dn.getBPNamenode(POOL_ID);
    verify(namenode,never()).commitBlockSynchronization(any(ExtendedBlock.class),anyLong(),anyLong(),anyBoolean(),anyBoolean(),any(DatanodeID[].class));
  }
  finally {
    streams.close();
  }
}

</code></pre>

<br>
<pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
/** 
 * BlockRecoveryFI_09. some/all DNs failed to update replicas.
 * @throws IOException in case of an error
 */
@Test public void testFailedReplicaUpdate() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  DataNode spyDN=spy(dn);
  doThrow(new IOException()).when(spyDN).updateReplicaUnderRecovery(block,RECOVERY_ID,block.getNumBytes());
  try {
    spyDN.syncBlock(rBlock,initBlockRecords(spyDN));
    fail("Sync should fail");
  }
 catch (  IOException e) {
    e.getMessage().startsWith("Cannot recover ");
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations </h4><pre class="type-3 type-8 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMiniDFSClusterWithMultipleNN() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(1)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(1)Should be 3 namenodes",3,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).federation(true).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(2)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  try {
    cluster.addNameNode(conf,9929);
    Assert.fail("shouldn't be able to add another NN to non federated cluster");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("cannot add namenode"));
    Assert.assertEquals("(3)Should be 1 namenodes",1,cluster.getNumNameNodes());
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool </h4><pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDeleteBlockPool() throws Exception {
  Configuration conf=new Configuration();
  MiniDFSCluster cluster=null;
  try {
    conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId1,namesServerId2");
    cluster=new MiniDFSCluster.Builder(conf).federation(true).numNameNodes(2).numDataNodes(2).build();
    cluster.waitActive();
    FileSystem fs1=cluster.getFileSystem(0);
    FileSystem fs2=cluster.getFileSystem(1);
    DFSTestUtil.createFile(fs1,new Path("/alpha"),1024,(short)2,54);
    DFSTestUtil.createFile(fs2,new Path("/beta"),1024,(short)2,54);
    DataNode dn1=cluster.getDataNodes().get(0);
    DataNode dn2=cluster.getDataNodes().get(1);
    String bpid1=cluster.getNamesystem(0).getBlockPoolId();
    String bpid2=cluster.getNamesystem(1).getBlockPoolId();
    File dn1StorageDir1=MiniDFSCluster.getStorageDir(0,0);
    File dn1StorageDir2=MiniDFSCluster.getStorageDir(0,1);
    File dn2StorageDir1=MiniDFSCluster.getStorageDir(1,0);
    File dn2StorageDir2=MiniDFSCluster.getStorageDir(1,1);
    try {
      dn1.deleteBlockPool(bpid1,true);
      Assert.fail("Must not delete a running block pool");
    }
 catch (    IOException expected) {
    }
    Configuration nn1Conf=cluster.getConfiguration(1);
    nn1Conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"namesServerId2");
    dn1.refreshNamenodes(nn1Conf);
    assertEquals(1,dn1.getAllBpOs().length);
    try {
      dn1.deleteBlockPool(bpid1,false);
      Assert.fail("Must not delete if any block files exist unless " + "force is true");
    }
 catch (    IOException expected) {
    }
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid1);
    dn1.deleteBlockPool(bpid1,true);
    verifyBlockPoolDirectories(false,dn1StorageDir1,bpid1);
    verifyBlockPoolDirectories(false,dn1StorageDir2,bpid1);
    fs1.delete(new Path("/alpha"),true);
    while ((MiniDFSCluster.getFinalizedDir(dn2StorageDir1,bpid1).list().length != 0) || (MiniDFSCluster.getFinalizedDir(dn2StorageDir2,bpid1).list().length != 0)) {
      try {
        Thread.sleep(3000);
      }
 catch (      Exception ignored) {
      }
    }
    cluster.shutdownNameNode(0);
    try {
      dn2.deleteBlockPool(bpid1,true);
      Assert.fail("Must not delete a running block pool");
    }
 catch (    IOException expected) {
    }
    dn2.refreshNamenodes(nn1Conf);
    assertEquals(1,dn2.getAllBpOs().length);
    verifyBlockPoolDirectories(true,dn2StorageDir1,bpid1);
    verifyBlockPoolDirectories(true,dn2StorageDir2,bpid1);
    dn2.deleteBlockPool(bpid1,false);
    verifyBlockPoolDirectories(false,dn2StorageDir1,bpid1);
    verifyBlockPoolDirectories(false,dn2StorageDir2,bpid1);
    verifyBlockPoolDirectories(true,dn1StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn1StorageDir2,bpid2);
    verifyBlockPoolDirectories(true,dn2StorageDir1,bpid2);
    verifyBlockPoolDirectories(true,dn2StorageDir2,bpid2);
    Path gammaFile=new Path("/gamma");
    DFSTestUtil.createFile(fs2,gammaFile,1024,(short)1,55);
    fs2.setReplication(gammaFile,(short)2);
    DFSTestUtil.waitReplication(fs2,gammaFile,(short)2);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestInterDatanodeProtocol </h4><pre class="type-10 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test {@link FSDataset#initReplicaRecovery(String,ReplicasMap,Block,long)}
 */
@Test public void testInitReplicaRecovery() throws IOException {
  final long firstblockid=10000L;
  final long gs=7777L;
  final long length=22L;
  final ReplicasMap map=new ReplicasMap(this);
  String bpid="BP-TEST";
  final Block[] blocks=new Block[5];
  for (int i=0; i < blocks.length; i++) {
    blocks[i]=new Block(firstblockid + i,length,gs);
    map.add(bpid,createReplicaInfo(blocks[i]));
  }
{
    final Block b=blocks[0];
    final ReplicaInfo originalInfo=map.get(bpid,b);
    final long recoveryid=gs + 1;
    final ReplicaRecoveryInfo recoveryInfo=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid);
    assertEquals(originalInfo,recoveryInfo);
    final ReplicaUnderRecovery updatedInfo=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo.getBlockId());
    Assert.assertEquals(recoveryid,updatedInfo.getRecoveryID());
    final long recoveryid2=gs + 2;
    final ReplicaRecoveryInfo recoveryInfo2=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid2);
    assertEquals(originalInfo,recoveryInfo2);
    final ReplicaUnderRecovery updatedInfo2=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo2.getBlockId());
    Assert.assertEquals(recoveryid2,updatedInfo2.getRecoveryID());
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    RecoveryInProgressException ripe) {
      System.out.println("GOOD: getting " + ripe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid - 1,length,gs);
    ReplicaRecoveryInfo r=FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
    Assert.assertNull("Data-node should not have this replica.",r);
  }
{
    final long recoveryid=gs - 1;
    final Block b=new Block(firstblockid + 1,length,gs);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    IOException ioe) {
      System.out.println("GOOD: getting " + ioe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid,length,gs + 1);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      fail("InitReplicaRecovery should fail because replica's " + "gs is less than the block's gs");
    }
 catch (    IOException e) {
      e.getMessage().startsWith("replica.getGenerationStamp() < block.getGenerationStamp(), block=");
    }
  }
}

</code></pre>

<br>
<pre class="type-10 type-3 type-8 type-9 type-6 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test  for{@link FSDataset#updateReplicaUnderRecovery(ExtendedBlock,long,long)} 
 */
@Test public void testUpdateReplicaUnderRecovery() throws IOException {
  final Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    String bpid=cluster.getNamesystem().getBlockPoolId();
    DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
    String filestr="/foo";
    Path filepath=new Path(filestr);
    DFSTestUtil.createFile(dfs,filepath,1024L,(short)3,0L);
    final LocatedBlock locatedblock=getLastLocatedBlock(dfs.getClient().getNamenode(),filestr);
    final DatanodeInfo[] datanodeinfo=locatedblock.getLocations();
    Assert.assertTrue(datanodeinfo.length > 0);
    final DataNode datanode=cluster.getDataNode(datanodeinfo[0].getIpcPort());
    Assert.assertTrue(datanode != null);
    Assert.assertTrue(datanode.data instanceof FSDataset);
    final FSDataset fsdataset=(FSDataset)datanode.data;
    final ExtendedBlock b=locatedblock.getBlock();
    final long recoveryid=b.getGenerationStamp() + 1;
    final long newlength=b.getNumBytes() - 1;
    final ReplicaRecoveryInfo rri=fsdataset.initReplicaRecovery(new RecoveringBlock(b,null,recoveryid));
    final ReplicaInfo replica=fsdataset.fetchReplicaInfo(bpid,b.getBlockId());
    Assert.assertEquals(ReplicaState.RUR,replica.getState());
    FSDataset.checkReplicaFiles(replica);
{
      final ExtendedBlock tmp=new ExtendedBlock(b.getBlockPoolId(),rri.getBlockId(),rri.getNumBytes() - 1,rri.getGenerationStamp());
      try {
        fsdataset.updateReplicaUnderRecovery(tmp,recoveryid,newlength);
        Assert.fail();
      }
 catch (      IOException ioe) {
        System.out.println("GOOD: getting " + ioe);
      }
    }
    final ReplicaInfo finalized=fsdataset.updateReplicaUnderRecovery(new ExtendedBlock(b.getBlockPoolId(),rri),recoveryid,newlength);
    FSDataset.checkReplicaFiles(finalized);
    Assert.assertEquals(b.getBlockId(),finalized.getBlockId());
    Assert.assertEquals(recoveryid,finalized.getGenerationStamp());
    Assert.assertEquals(newlength,finalized.getNumBytes());
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestReplicasMap </h4><pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test for ReplicasMap.get(Block) and ReplicasMap.get(long) tests
 */
@Test public void testGet(){
  try {
    map.get(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  assertNotNull(map.get(bpid,block));
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.get(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.get(bpid,b));
  assertNotNull(map.get(bpid,block.getBlockId()));
  assertNull(map.get(bpid,0));
}

</code></pre>

<br>
<pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRemove(){
  try {
    map.remove(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.remove(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.remove(bpid,b));
  assertNotNull(map.remove(bpid,block));
  assertNull(map.remove(bpid,0));
  map.add(bpid,new FinalizedReplica(block,null,null));
  assertNotNull(map.remove(bpid,block.getBlockId()));
}

</code></pre>

<br>
<pre class="type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testAdd(){
  try {
    map.add(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestRoundRobinVolumesPolicy </h4><pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRR() throws Exception {
  final List<FSVolume> volumes=new ArrayList<FSVolume>();
  volumes.add(Mockito.mock(FSVolume.class));
  Mockito.when(volumes.get(0).getAvailable()).thenReturn(100L);
  volumes.add(Mockito.mock(FSVolume.class));
  Mockito.when(volumes.get(1).getAvailable()).thenReturn(200L);
  RoundRobinVolumesPolicy policy=ReflectionUtils.newInstance(RoundRobinVolumesPolicy.class,null);
  Assert.assertEquals(volumes.get(0),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(0),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,0));
  Assert.assertEquals(volumes.get(1),policy.chooseVolume(volumes,150));
  try {
    policy.chooseVolume(volumes,Long.MAX_VALUE);
    Assert.fail();
  }
 catch (  IOException e) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestAllowFormat </h4><pre class="type-3 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start MiniDFScluster, try formatting with different settings
 * @throws IOException
 * @throws InterruptedException 
 */
@Test public void testAllowFormat() throws IOException {
  LOG.info("--starting mini cluster");
  NameNode nn;
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  cluster=new MiniDFSCluster.Builder(config).manageDataDfsDirs(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  assertNotNull(cluster);
  nn=cluster.getNameNode();
  assertNotNull(nn);
  LOG.info("Mini cluster created OK");
  LOG.info("Verifying format will fail with allowformat false");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,false);
  try {
    cluster.shutdown();
    NameNode.format(config);
    fail("Format succeeded, when it should have failed");
  }
 catch (  IOException e) {
    assertTrue("Exception was not about formatting Namenode",e.getMessage().startsWith("The option " + DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY));
    LOG.info("Expected failure: " + StringUtils.stringifyException(e));
    LOG.info("Done verifying format will fail with allowformat false");
  }
  LOG.info("Verifying format will succeed with allowformat true");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  NameNode.format(config);
  LOG.info("Done verifying format will succeed with allowformat true");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens </h4><pre class="type-10 type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Tests save namepsace.
 */
@Test public void testSaveNamespace() throws IOException {
  DistributedFileSystem fs=null;
  try {
    Configuration conf=new HdfsConfiguration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    cluster.waitActive();
    fs=(DistributedFileSystem)(cluster.getFileSystem());
    FSNamesystem namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    String renewer=UserGroupInformation.getLoginUser().getUserName();
    Token<DelegationTokenIdentifier> token1=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token2=namesystem.getDelegationToken(new Text(renewer));
    DFSAdmin admin=new DFSAdmin(conf);
    String[] args=new String[]{"-saveNamespace"};
    Collection<URI> editsDirs=cluster.getNameEditsDirs(0);
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() > Integer.SIZE / Byte.SIZE);
    }
    fs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    try {
      admin.run(args);
    }
 catch (    Exception e) {
      throw new IOException(e.getMessage());
    }
    for (    URI uri : editsDirs) {
      File ed=new File(uri.getPath());
      Assert.assertTrue(new File(ed,"current/edits").length() == Integer.SIZE / Byte.SIZE);
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    try {
      renewToken(token1);
      renewToken(token2);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token3=namesystem.getDelegationToken(new Text(renewer));
    Token<DelegationTokenIdentifier> token4=namesystem.getDelegationToken(new Text(renewer));
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    Token<DelegationTokenIdentifier> token5=namesystem.getDelegationToken(new Text(renewer));
    try {
      renewToken(token1);
      renewToken(token2);
      renewToken(token3);
      renewToken(token4);
      renewToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
    cluster.shutdown();
    cluster=null;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).format(false).build();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    namesystem.getDelegationTokenSecretManager().startThreads();
    try {
      renewToken(token1);
      cancelToken(token1);
      renewToken(token2);
      cancelToken(token2);
      renewToken(token3);
      cancelToken(token3);
      renewToken(token4);
      cancelToken(token4);
      renewToken(token5);
      cancelToken(token5);
    }
 catch (    IOException e) {
      Assert.fail("Could not renew or cancel the token");
    }
  }
  finally {
    if (fs != null)     fs.close();
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestDeadDatanode </h4><pre class="type-10 type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test to ensure namenode rejects request from dead datanode
 * - Start a cluster
 * - Shutdown the datanode and wait for it to be marked dead at the namenode
 * - Send datanode requests to Namenode and make sure it is rejected 
 * appropriately.
 */
@Test public void testDeadDatanode() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,500);
  conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1L);
  cluster=new MiniDFSCluster.Builder(conf).build();
  cluster.waitActive();
  String poolId=cluster.getNamesystem().getBlockPoolId();
  DataNode dn=cluster.getDataNodes().get(0);
  DatanodeRegistration reg=DataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().get(0),poolId);
  waitForDatanodeState(reg.getStorageID(),true,20000);
  dn.shutdown();
  waitForDatanodeState(reg.getStorageID(),false,20000);
  DatanodeProtocol dnp=cluster.getNameNode();
  Block[] blocks=new Block[]{new Block(0)};
  String[] delHints=new String[]{""};
  try {
    dnp.blockReceived(reg,poolId,blocks,delHints);
    Assert.fail("Expected IOException is not thrown");
  }
 catch (  IOException ex) {
  }
  long[] blockReport=new long[]{0L,0L,0L};
  try {
    dnp.blockReport(reg,poolId,blockReport);
    Assert.fail("Expected IOException is not thrown");
  }
 catch (  IOException ex) {
  }
  DatanodeCommand[] cmd=dnp.sendHeartbeat(reg,0,0,0,0,0,0,0);
  Assert.assertEquals(1,cmd.length);
  Assert.assertEquals(cmd[0].getAction(),DatanodeCommand.REGISTER.getAction());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testDisplayRecentEditLogOpCodes() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  FileSystem fileSys=null;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  final FSEditLog editLog=fsimage.getEditLog();
  for (int i=0; i < 20; i++) {
    fileSys.mkdirs(new Path("/tmp/tmp" + i));
  }
  File editFile=editLog.getFsEditName();
  editLog.close();
  cluster.shutdown();
  long fileLen=editFile.length();
  RandomAccessFile rwf=new RandomAccessFile(editFile,"rw");
  rwf.seek(fileLen - 40);
  for (int i=0; i < 20; i++) {
    rwf.write(FSEditLogOpCodes.OP_DELETE.getOpCode());
  }
  rwf.close();
  String expectedErrorMessage="^Error replaying edit log at offset \\d+\n";
  expectedErrorMessage+="Recent opcode offsets: (\\d+\\s*){4}$";
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).build();
    fail("should not be able to start");
  }
 catch (  IOException e) {
    assertTrue("error message contains opcodes message",e.getMessage().matches(expectedErrorMessage));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat </h4><pre class="type-3 type-8 type-9 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * test illegal args cases
 */
@Test public void testIllegalArg() throws IOException {
  long fileLen=blockSize * 3;
  Path parentDir=new Path("/parentTrg");
  assertTrue(dfs.mkdirs(parentDir));
  Path trg=new Path(parentDir,"trg");
  DFSTestUtil.createFile(dfs,trg,fileLen,REPL_FACTOR,1);
{
    Path dir1=new Path("/dir1");
    assertTrue(dfs.mkdirs(dir1));
    Path src=new Path(dir1,"src");
    DFSTestUtil.createFile(dfs,src,fileLen,REPL_FACTOR,1);
    try {
      dfs.concat(trg,new Path[]{src});
      fail("didn't fail for src and trg in different directories");
    }
 catch (    Exception e) {
    }
  }
  try {
    dfs.concat(trg,new Path[]{new Path("test1/a")});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
  try {
    dfs.concat(trg,new Path[]{});
    fail("didn't fail with invalid arguments");
  }
 catch (  Exception e) {
  }
}

</code></pre>

<br>
<pre class="type-16 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Concatenates 10 files into one
 * Verifies the final size, deletion of the file, number of blocks
 * @throws IOException
 */
@Test public void testConcat() throws IOException, InterruptedException {
  final int numFiles=10;
  long fileLen=blockSize * 3;
  HdfsFileStatus fStatus;
  FSDataInputStream stm;
  String trg=new String("/trg");
  Path trgPath=new Path(trg);
  DFSTestUtil.createFile(dfs,trgPath,fileLen,REPL_FACTOR,1);
  fStatus=nn.getFileInfo(trg);
  long trgLen=fStatus.getLen();
  long trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  Path[] files=new Path[numFiles];
  byte[][] bytes=new byte[numFiles][(int)fileLen];
  LocatedBlocks[] lblocks=new LocatedBlocks[numFiles];
  long[] lens=new long[numFiles];
  int i=0;
  for (i=0; i < files.length; i++) {
    files[i]=new Path("/file" + i);
    Path path=files[i];
    System.out.println("Creating file " + path);
    DFSTestUtil.createFile(dfs,path,fileLen,REPL_FACTOR,1);
    fStatus=nn.getFileInfo(path.toUri().getPath());
    lens[i]=fStatus.getLen();
    assertEquals(trgLen,lens[i]);
    lblocks[i]=nn.getBlockLocations(path.toUri().getPath(),0,lens[i]);
    stm=dfs.open(path);
    stm.readFully(0,bytes[i]);
    stm.close();
  }
  final UserGroupInformation user1=UserGroupInformation.createUserForTesting("theDoctor",new String[]{"tardis"});
  DistributedFileSystem hdfs=(DistributedFileSystem)DFSTestUtil.getFileSystemAs(user1,conf);
  try {
    hdfs.concat(trgPath,files);
    fail("Permission exception expected");
  }
 catch (  IOException ie) {
    System.out.println("Got expected exception for permissions:" + ie.getLocalizedMessage());
  }
  ContentSummary cBefore=dfs.getContentSummary(trgPath.getParent());
  dfs.concat(trgPath,files);
  ContentSummary cAfter=dfs.getContentSummary(trgPath.getParent());
  assertEquals(cBefore.getFileCount(),cAfter.getFileCount() + files.length);
  long totalLen=trgLen;
  long totalBlocks=trgBlocks;
  for (i=0; i < files.length; i++) {
    totalLen+=lens[i];
    totalBlocks+=lblocks[i].locatedBlockCount();
  }
  System.out.println("total len=" + totalLen + "; totalBlocks="+ totalBlocks);
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  stm=dfs.open(trgPath);
  byte[] byteFileConcat=new byte[(int)trgLen];
  stm.readFully(0,byteFileConcat);
  stm.close();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks);
  assertEquals(trgLen,totalLen);
  for (  Path p : files) {
    fStatus=nn.getFileInfo(p.toUri().getPath());
    assertNull("File " + p + " still exists",fStatus);
    DFSTestUtil.createFile(dfs,p,fileLen,REPL_FACTOR,1);
  }
  checkFileContent(byteFileConcat,bytes);
  Path smallFile=new Path("/sfile");
  int sFileLen=10;
  DFSTestUtil.createFile(dfs,smallFile,sFileLen,REPL_FACTOR,1);
  dfs.concat(trgPath,new Path[]{smallFile});
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks + 1);
  assertEquals(trgLen,totalLen + sFileLen);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestNNLeaseRecovery </h4><pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file with 1 block
 * and invokes lease recovery method. 
 * AlreadyBeingCreatedException is expected.
 * @throws AlreadyBeingCreatedException as the result
 */
@Test(expected=AlreadyBeingCreatedException.class) public void testInternalReleaseLease_1blocks() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(1,null,HdfsConstants.BlockUCState.COMMITTED,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file, sets status of last two
 * blocks to non-defined and UNDER_CONSTRUCTION and invokes lease recovery
 * method. IOException is expected for releasing a create lock on a 
 * closed file. 
 * @throws IOException as the result
 */
@Test(expected=IOException.class) public void testInternalReleaseLease_UNKNOWN_COMM() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,null,HdfsConstants.BlockUCState.UNDER_CONSTRUCTION,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<pre class="type-3 type-15 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies that exceptions are thrown during the test case execution">ExceptionVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies that exceptions are thrown during the test case execution
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Mocks FSNamesystem instance, adds an empty file, sets status of last two
 * blocks to COMMITTED and COMMITTED and invokes lease recovery
 * method. AlreadyBeingCreatedException is expected.
 * @throws AlreadyBeingCreatedException as the result
 */
@Test(expected=AlreadyBeingCreatedException.class) public void testInternalReleaseLease_COMM_COMM() throws IOException {
  if (LOG.isDebugEnabled()) {
    LOG.debug("Running " + GenericTestUtils.getMethodName());
  }
  LeaseManager.Lease lm=mock(LeaseManager.Lease.class);
  Path file=spy(new Path("/" + GenericTestUtils.getMethodName() + "_test.dat"));
  DatanodeDescriptor dnd=mock(DatanodeDescriptor.class);
  PermissionStatus ps=new PermissionStatus("test","test",new FsPermission((short)0777));
  mockFileBlocks(2,HdfsConstants.BlockUCState.COMMITTED,HdfsConstants.BlockUCState.COMMITTED,file,dnd,ps,false);
  releaseLease(fsn,lm,file);
  fail("FSNamesystem.internalReleaseLease suppose to throw " + "IOException here");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Regression test for HDFS-1997. Test that, if an exception
 * occurs on the client side, it is properly reported as such
 */
@Test public void testClientSideException() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
  try {
    String fsName=NameNode.getHostPortString(cluster.getNameNode().getHttpAddress());
    String id="getimage=1";
    File[] localPath=new File[]{new File("/xxxxx-does-not-exist/blah")};
    TransferFsImage.getFileClient(fsName,id,localPath,false);
    fail("Didn't get an exception!");
  }
 catch (  IOException ioe) {
    assertTrue("Expected FNFE, got: " + StringUtils.stringifyException(ioe),ioe instanceof FileNotFoundException);
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.util.TestExactSizeInputStream </h4><pre class="type-3 type-8 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMark() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertFalse(s.markSupported());
  try {
    s.mark(1);
    fail("Mark should not succeed");
  }
 catch (  UnsupportedOperationException uoe) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-9 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testReadNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertEquals(2,s.available());
  assertEquals((int)'h',s.read());
  assertEquals((int)'e',s.read());
  try {
    s.read();
    fail("Read when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testReadArrayNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  byte[] buf=new byte[10];
  assertEquals(2,s.read(buf,0,5));
  try {
    s.read(buf,2,3);
    fail("Read buf when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<pre class="type-3 type-6 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects/variable are equal to an expected value 
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testSkipNotEnough() throws IOException {
  ExactSizeInputStream s=new ExactSizeInputStream(byteStream("he"),5);
  assertEquals(2,s.skip(3));
  try {
    s.skip(1);
    fail("Skip when should be out of data");
  }
 catch (  EOFException e) {
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.util.TestGSet </h4><pre class="type-16 type-3 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
"></span><br>
@Test public void testExceptionCases(){
{
    final LightWeightGSet<Integer,Integer> gset=new LightWeightGSet<Integer,Integer>(16);
    try {
      gset.contains(null);
      Assert.fail();
    }
 catch (    NullPointerException e) {
      LightWeightGSet.LOG.info("GOOD: getting " + e,e);
    }
  }
{
    final LightWeightGSet<Integer,Integer> gset=new LightWeightGSet<Integer,Integer>(16);
    try {
      gset.get(null);
      Assert.fail();
    }
 catch (    NullPointerException e) {
      LightWeightGSet.LOG.info("GOOD: getting " + e,e);
    }
  }
{
    final LightWeightGSet<Integer,Integer> gset=new LightWeightGSet<Integer,Integer>(16);
    try {
      gset.put(null);
      Assert.fail();
    }
 catch (    NullPointerException e) {
      LightWeightGSet.LOG.info("GOOD: getting " + e,e);
    }
    try {
      gset.put(1);
      Assert.fail();
    }
 catch (    IllegalArgumentException e) {
      LightWeightGSet.LOG.info("GOOD: getting " + e,e);
    }
  }
{
    final IntElement[] data=new IntElement[5];
    for (int i=0; i < data.length; i++) {
      data[i]=new IntElement(i,i);
    }
    for (int v=1; v < data.length - 1; v++) {
{
        final GSet<IntElement,IntElement> gset=createGSet(data);
        for (        IntElement i : gset) {
          if (i.value == v) {
            gset.remove(data[0]);
          }
        }
        try {
          for (          IntElement i : gset) {
            if (i.value == v) {
              gset.remove(data[1]);
            }
          }
          Assert.fail();
        }
 catch (        ConcurrentModificationException e) {
          LightWeightGSet.LOG.info("GOOD: getting " + e,e);
        }
      }
{
        final GSet<IntElement,IntElement> gset=createGSet(data);
        try {
          for (          IntElement i : gset) {
            if (i.value == v) {
              gset.put(data[0]);
            }
          }
          Assert.fail();
        }
 catch (        ConcurrentModificationException e) {
          LightWeightGSet.LOG.info("GOOD: getting " + e,e);
        }
      }
{
        final GSet<IntElement,IntElement> gset=createGSet(data);
        try {
          for (          IntElement i : gset) {
            if (i.value == v) {
              gset.put(data[3]);
            }
          }
          Assert.fail();
        }
 catch (        ConcurrentModificationException e) {
          LightWeightGSet.LOG.info("GOOD: getting " + e,e);
        }
      }
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.security.TestRefreshUserMappings </h4><pre class="type-3 type-9 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
"></span><br>
@Test public void testRefreshSuperUserGroupsConfiguration() throws Exception {
  final String SUPER_USER="super_user";
  final String[] GROUP_NAMES1=new String[]{"gr1","gr2"};
  final String[] GROUP_NAMES2=new String[]{"gr3","gr4"};
  String userKeyGroups=ProxyUsers.getProxySuperuserGroupConfKey(SUPER_USER);
  String userKeyHosts=ProxyUsers.getProxySuperuserIpConfKey(SUPER_USER);
  config.set(userKeyGroups,"gr3,gr4,gr5");
  config.set(userKeyHosts,"127.0.0.1");
  ProxyUsers.refreshSuperUserGroupsConfiguration(config);
  UserGroupInformation ugi1=mock(UserGroupInformation.class);
  UserGroupInformation ugi2=mock(UserGroupInformation.class);
  UserGroupInformation suUgi=mock(UserGroupInformation.class);
  when(ugi1.getRealUser()).thenReturn(suUgi);
  when(ugi2.getRealUser()).thenReturn(suUgi);
  when(suUgi.getShortUserName()).thenReturn(SUPER_USER);
  when(suUgi.getUserName()).thenReturn(SUPER_USER + "L");
  when(ugi1.getShortUserName()).thenReturn("user1");
  when(ugi2.getShortUserName()).thenReturn("user2");
  when(ugi1.getUserName()).thenReturn("userL1");
  when(ugi2.getUserName()).thenReturn("userL2");
  when(ugi1.getGroupNames()).thenReturn(GROUP_NAMES1);
  when(ugi2.getGroupNames()).thenReturn(GROUP_NAMES2);
  try {
    ProxyUsers.authorize(ugi1,"127.0.0.1",config);
    fail("first auth for " + ugi1.getShortUserName() + " should've failed ");
  }
 catch (  AuthorizationException e) {
    System.err.println("auth for " + ugi1.getUserName() + " failed");
  }
  try {
    ProxyUsers.authorize(ugi2,"127.0.0.1",config);
    System.err.println("auth for " + ugi2.getUserName() + " succeeded");
  }
 catch (  AuthorizationException e) {
    fail("first auth for " + ugi2.getShortUserName() + " should've succeeded: "+ e.getLocalizedMessage());
  }
  String rsrc="testGroupMappingRefresh_rsrc.xml";
  addNewConfigResource(rsrc,userKeyGroups,"gr2",userKeyHosts,"127.0.0.1");
  DFSAdmin admin=new DFSAdmin(config);
  String[] args=new String[]{"-refreshSuperUserGroupsConfiguration"};
  admin.run(args);
  try {
    ProxyUsers.authorize(ugi2,"127.0.0.1",config);
    fail("second auth for " + ugi2.getShortUserName() + " should've failed ");
  }
 catch (  AuthorizationException e) {
    System.err.println("auth for " + ugi2.getUserName() + " failed");
  }
  try {
    ProxyUsers.authorize(ugi1,"127.0.0.1",config);
    System.err.println("auth for " + ugi1.getUserName() + " succeeded");
  }
 catch (  AuthorizationException e) {
    fail("second auth for " + ugi1.getShortUserName() + " should've succeeded: "+ e.getLocalizedMessage());
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

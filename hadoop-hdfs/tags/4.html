<h3><span class=" glyphicon glyphicon-tag"/>&nbspNullVerifier</h3><kbd>Verifies whether objects are null</kbd><br><br><br><h4 style="margin:0px">Class: TestFuseDFS </h4><pre class="type-3 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test concurrent creation and access of the mount 
 */
@Test public void testMultipleThreads() throws IOException {
  ArrayList<Thread> threads=new ArrayList<Thread>();
  final AtomicReference<String> errorMessage=new AtomicReference<String>();
  for (int i=0; i < 10; i++) {
    Thread t=new Thread(){
      public void run(){
        try {
          File d=new File(mountPoint,"dir" + getId());
          execWaitRet("mkdir " + d.getAbsolutePath());
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            final String contents="thread " + getId() + " "+ j;
            createFile(f,contents);
          }
          for (int j=0; j < 10; j++) {
            File f=new File(d,"file" + j);
            execWaitRet("cat " + f.getAbsolutePath());
            execWaitRet("rm " + f.getAbsolutePath());
          }
          execWaitRet("rmdir " + d.getAbsolutePath());
        }
 catch (        IOException ie) {
          errorMessage.set(String.format("Exception %s",StringUtils.stringifyException(ie)));
        }
      }
    }
;
    t.start();
    threads.add(t);
  }
  for (  Thread t : threads) {
    try {
      t.join();
    }
 catch (    InterruptedException ie) {
      fail("Thread interrupted: " + ie.getMessage());
    }
  }
  assertNull(errorMessage.get(),errorMessage.get());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDFSUtil </h4><pre class="type-10 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test for{@link DFSUtil#getNameServiceIds(Configuration)}{@link DFSUtil#getNameServiceId(Configuration)}{@link DFSUtil#getNNServiceRpcAddresses(Configuration)}
 */
@Test public void testMultipleNamenodes() throws IOException {
  HdfsConfiguration conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICES,"nn1,nn2");
  Collection<String> nameserviceIds=DFSUtil.getNameServiceIds(conf);
  Iterator<String> it=nameserviceIds.iterator();
  assertEquals(2,nameserviceIds.size());
  assertEquals("nn1",it.next().toString());
  assertEquals("nn2",it.next().toString());
  conf.set(DFSConfigKeys.DFS_FEDERATION_NAMESERVICE_ID,"nn1");
  assertEquals("nn1",DFSUtil.getNameServiceId(conf));
  final String NN1_ADDRESS="localhost:9000";
  final String NN2_ADDRESS="localhost:9001";
  final String NN3_ADDRESS="localhost:9002";
  conf.set(DFSUtil.getNameServiceIdKey(DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY,"nn1"),NN1_ADDRESS);
  conf.set(DFSUtil.getNameServiceIdKey(DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY,"nn2"),NN2_ADDRESS);
  Collection<InetSocketAddress> nnAddresses=DFSUtil.getNNServiceRpcAddresses(conf);
  assertEquals(2,nnAddresses.size());
  Iterator<InetSocketAddress> iterator=nnAddresses.iterator();
  assertEquals(2,nameserviceIds.size());
  InetSocketAddress addr=iterator.next();
  assertEquals("localhost",addr.getHostName());
  assertEquals(9000,addr.getPort());
  addr=iterator.next();
  assertEquals("localhost",addr.getHostName());
  assertEquals(9001,addr.getPort());
  InetSocketAddress testAddress1=NetUtils.createSocketAddr(NN1_ADDRESS);
  String nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress1,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertEquals("nn1",nameserviceId);
  InetSocketAddress testAddress2=NetUtils.createSocketAddr(NN2_ADDRESS);
  nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress2,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertEquals("nn2",nameserviceId);
  InetSocketAddress testAddress3=NetUtils.createSocketAddr(NN3_ADDRESS);
  nameserviceId=DFSUtil.getNameServiceIdFromAddress(conf,testAddress3,DFSConfigKeys.DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY,DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY);
  assertNull(nameserviceId);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestDatanodeConfig </h4><pre class="type-10 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test that a data-node does not start if configuration specifies
 * incorrect URI scheme in data directory.
 * Test that a data-node starts if data directory is specified as
 * URI = "file:///path" or as a non URI path.
 */
@Test public void testDataDirectories() throws IOException {
  File dataDir=new File(BASE_DIR,"data").getCanonicalFile();
  Configuration conf=cluster.getConfiguration(0);
  String dnDir=makeURI("shv",null,fileAsURI(dataDir).getPath());
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir);
  DataNode dn=null;
  try {
    dn=DataNode.createDataNode(new String[]{},conf);
  }
 catch (  IOException e) {
  }
  if (dn != null)   dn.shutdown();
  assertNull("Data-node startup should have failed.",dn);
  String dnDir1=fileAsURI(dataDir).toString() + "1";
  String dnDir2=makeURI("file","localhost",fileAsURI(dataDir).getPath() + "2");
  String dnDir3=dataDir.getAbsolutePath() + "3";
  conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,dnDir1 + "," + dnDir2+ ","+ dnDir3);
  cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
  assertTrue("Data-node should startup.",cluster.isDataNodeUp());
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend4 </h4><pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, recovers a file from another writer,
 * starts writing from that writer, and then has the old lease holder
 * call completeFile
 */
@Test(timeout=60000) public void testCompleteOtherLeaseHoldersFile() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testCompleteOtherLease");
    final OutputStream stm=client.create("/testCompleteOtherLease",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Opening file for append from new fs");
    FSDataOutputStream appenderStream=fs2.append(file1);
    LOG.info("Writing some data from new appender");
    AppendTestUtil.write(appenderStream,0,4096);
    LOG.info("Telling old close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("Lease mismatch"))     throw thrownByClose;
    appenderStream.close();
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-10 type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test case that stops a writer after finalizing a block but
 * before calling completeFile, and then tries to recover
 * the lease from another thread.
 */
@Test(timeout=60000) public void testRecoverFinalizedBlock() throws Throwable {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
  try {
    cluster.waitActive();
    NameNode preSpyNN=cluster.getNameNode();
    NameNode spyNN=spy(preSpyNN);
    DelayAnswer delayer=new DelayAnswer();
    doAnswer(delayer).when(spyNN).complete(anyString(),anyString(),(ExtendedBlock)anyObject());
    DFSClient client=new DFSClient(null,spyNN,conf,null);
    file1=new Path("/testRecoverFinalized");
    final OutputStream stm=client.create("/testRecoverFinalized",true);
    AppendTestUtil.write(stm,0,4096);
    final AtomicReference<Throwable> err=new AtomicReference<Throwable>();
    Thread t=new Thread(){
      public void run(){
        try {
          stm.close();
        }
 catch (        Throwable t) {
          err.set(t);
        }
      }
    }
;
    t.start();
    LOG.info("Waiting for close to get to latch...");
    delayer.waitForCall();
    LOG.info("Killing lease checker");
    client.leaserenewer.interruptAndJoin();
    FileSystem fs1=cluster.getFileSystem();
    FileSystem fs2=AppendTestUtil.createHdfsWithDifferentUsername(fs1.getConf());
    LOG.info("Recovering file");
    recoverFile(fs2);
    LOG.info("Telling close to proceed.");
    delayer.proceed();
    LOG.info("Waiting for close to finish.");
    t.join();
    LOG.info("Close finished.");
    Throwable thrownByClose=err.get();
    assertNotNull(thrownByClose);
    assertTrue(thrownByClose instanceof IOException);
    if (!thrownByClose.getMessage().contains("No lease on /testRecoverFinalized"))     throw thrownByClose;
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestHL040 </h4><pre class="type-9 type-4 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
"></span><br>
@Test public void testConnect() throws IOException {
  LOG.info("Staring TestHL040: connecting to the HDFSCluster ");
  LOG.info("================ Getting namenode info ================");
  NNClient dfsMaster=cluster.getNNClient();
  LOG.info("Process info of namenode " + dfsMaster.getHostName() + " is: "+ dfsMaster.getProcessInfo());
  LOG.info("================ Getting datanode info ================");
  Collection<DNClient> clients=cluster.getDNClients();
  for (  DNClient dnC : clients) {
    LOG.info("Process info of datanode " + dnC.getHostName() + " is: "+ dnC.getProcessInfo());
    Assert.assertNotNull("Datanode process info isn't suppose to be null",dnC.getProcessInfo());
    LOG.info("Free space " + getFreeSpace(dnC));
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations </h4><pre class="type-9 type-13 type-6 type-4 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether two objects/variables are the same">IdentityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether two objects/variables are the same
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start multiple NNs and single DN and verifies per BP registrations and
 * handshakes.
 * @throws IOException
 */
@Test public void test2NNRegistration() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  try {
    cluster.waitActive();
    NameNode nn1=cluster.getNameNode(0);
    NameNode nn2=cluster.getNameNode(1);
    assertNotNull("cannot create nn1",nn1);
    assertNotNull("cannot create nn2",nn2);
    String bpid1=nn1.getFSImage().getBlockPoolID();
    String bpid2=nn2.getFSImage().getBlockPoolID();
    String cid1=nn1.getFSImage().getClusterID();
    String cid2=nn2.getFSImage().getClusterID();
    int lv1=nn1.getFSImage().getLayoutVersion();
    int lv2=nn2.getFSImage().getLayoutVersion();
    int ns1=nn1.getFSImage().getNamespaceID();
    int ns2=nn2.getFSImage().getNamespaceID();
    assertNotSame("namespace ids should be different",ns1,ns2);
    LOG.info("nn1: lv=" + lv1 + ";cid="+ cid1+ ";bpid="+ bpid1+ ";uri="+ nn1.getNameNodeAddress());
    LOG.info("nn2: lv=" + lv2 + ";cid="+ cid2+ ";bpid="+ bpid2+ ";uri="+ nn2.getNameNodeAddress());
    DataNode dn=cluster.getDataNodes().get(0);
    Collection<VolumeInfo> volInfos=((FSDataset)dn.data).getVolumeInfo();
    assertNotNull("No volumes in the fsdataset",volInfos);
    int i=0;
    for (    VolumeInfo vi : volInfos) {
      LOG.info("vol " + i++ + ";dir="+ vi.directory+ ";fs= "+ vi.freeSpace);
    }
    assertEquals("number of volumes is wrong",2,volInfos.size());
    for (    BPOfferService bpos : dn.getAllBpOs()) {
      LOG.info("reg: bpid=" + "; name=" + bpos.bpRegistration.name + "; sid="+ bpos.bpRegistration.storageID+ "; nna="+ bpos.nnAddr);
    }
    BPOfferService bpos1=dn.getAllBpOs()[0];
    BPOfferService bpos2=dn.getAllBpOs()[1];
    if (bpos1.nnAddr.equals(nn2.getNameNodeAddress())) {
      BPOfferService tmp=bpos1;
      bpos1=bpos2;
      bpos2=tmp;
    }
    assertEquals("wrong nn address",bpos1.nnAddr,nn1.getNameNodeAddress());
    assertEquals("wrong nn address",bpos2.nnAddr,nn2.getNameNodeAddress());
    assertEquals("wrong bpid",bpos1.getBlockPoolId(),bpid1);
    assertEquals("wrong bpid",bpos2.getBlockPoolId(),bpid2);
    assertEquals("wrong cid",dn.getClusterId(),cid1);
    assertEquals("cid should be same",cid2,cid1);
    assertEquals("namespace should be same",bpos1.bpNSInfo.namespaceID,ns1);
    assertEquals("namespace should be same",bpos2.bpNSInfo.namespaceID,ns2);
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-9 type-6 type-4 type-17 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values related to public fields.">PublicFieldVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Verifies values related to public fields.
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * starts single nn and single dn and verifies registration and handshake
 * @throws IOException
 */
@Test public void testFedSingleNN() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nameNodePort(9927).build();
  try {
    NameNode nn1=cluster.getNameNode();
    assertNotNull("cannot create nn1",nn1);
    String bpid1=nn1.getFSImage().getBlockPoolID();
    String cid1=nn1.getFSImage().getClusterID();
    int lv1=nn1.getFSImage().getLayoutVersion();
    LOG.info("nn1: lv=" + lv1 + ";cid="+ cid1+ ";bpid="+ bpid1+ ";uri="+ nn1.getNameNodeAddress());
    DataNode dn=cluster.getDataNodes().get(0);
    Collection<VolumeInfo> volInfos=((FSDataset)dn.data).getVolumeInfo();
    assertNotNull("No volumes in the fsdataset",volInfos);
    int i=0;
    for (    VolumeInfo vi : volInfos) {
      LOG.info("vol " + i++ + ";dir="+ vi.directory+ ";fs= "+ vi.freeSpace);
    }
    assertEquals("number of volumes is wrong",2,volInfos.size());
    for (    BPOfferService bpos : dn.getAllBpOs()) {
      LOG.info("reg: bpid=" + "; name=" + bpos.bpRegistration.name + "; sid="+ bpos.bpRegistration.storageID+ "; nna="+ bpos.nnAddr);
    }
    BPOfferService bpos1=dn.getAllBpOs()[0];
    bpos1.lastBlockReport=0;
    bpos1.blockReport();
    assertEquals("wrong nn address",bpos1.nnAddr,nn1.getNameNodeAddress());
    assertEquals("wrong bpid",bpos1.getBlockPoolId(),bpid1);
    assertEquals("wrong cid",dn.getClusterId(),cid1);
    cluster.shutdown();
    assertEquals(0,dn.getAllBpOs().length);
    cluster=null;
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}

</code></pre>

<br>
<pre class="type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testClusterIdMismatch() throws IOException {
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  try {
    cluster.waitActive();
    DataNode dn=cluster.getDataNodes().get(0);
    BPOfferService[] bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (should be 2):" + bposs.length);
    Assert.assertEquals("should've registered with two namenodes",bposs.length,2);
    cluster.addNameNode(conf,9938);
    bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (should be 3):" + bposs.length);
    Assert.assertEquals("should've registered with three namenodes",bposs.length,3);
    StartupOption.FORMAT.setClusterId("DifferentCID");
    cluster.addNameNode(conf,9948);
    NameNode nn4=cluster.getNameNode(3);
    assertNotNull("cannot create nn4",nn4);
    bposs=dn.getAllBpOs();
    LOG.info("dn bpos len (still should be 3):" + bposs.length);
    Assert.assertEquals("should've registered with three namenodes",3,bposs.length);
  }
  finally {
    if (cluster != null)     cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-3 type-8 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testMiniDFSClusterWithMultipleNN() throws IOException {
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numNameNodes(2).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(1)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(1)Should be 3 namenodes",3,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).federation(true).nameNodePort(9928).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  cluster.addNameNode(conf,9929);
  Assert.assertEquals("(2)Should be 2 namenodes",2,cluster.getNumNameNodes());
  cluster.shutdown();
  conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).build();
  Assert.assertNotNull(cluster);
  Assert.assertEquals("(2)Should be 1 namenodes",1,cluster.getNumNameNodes());
  try {
    cluster.addNameNode(conf,9929);
    Assert.fail("shouldn't be able to add another NN to non federated cluster");
  }
 catch (  IOException e) {
    Assert.assertTrue(e.getMessage().startsWith("cannot add namenode"));
    Assert.assertEquals("(3)Should be 1 namenodes",1,cluster.getNumNameNodes());
  }
 finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestInterDatanodeProtocol </h4><pre class="type-10 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test {@link FSDataset#initReplicaRecovery(String,ReplicasMap,Block,long)}
 */
@Test public void testInitReplicaRecovery() throws IOException {
  final long firstblockid=10000L;
  final long gs=7777L;
  final long length=22L;
  final ReplicasMap map=new ReplicasMap(this);
  String bpid="BP-TEST";
  final Block[] blocks=new Block[5];
  for (int i=0; i < blocks.length; i++) {
    blocks[i]=new Block(firstblockid + i,length,gs);
    map.add(bpid,createReplicaInfo(blocks[i]));
  }
{
    final Block b=blocks[0];
    final ReplicaInfo originalInfo=map.get(bpid,b);
    final long recoveryid=gs + 1;
    final ReplicaRecoveryInfo recoveryInfo=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid);
    assertEquals(originalInfo,recoveryInfo);
    final ReplicaUnderRecovery updatedInfo=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo.getBlockId());
    Assert.assertEquals(recoveryid,updatedInfo.getRecoveryID());
    final long recoveryid2=gs + 2;
    final ReplicaRecoveryInfo recoveryInfo2=FSDataset.initReplicaRecovery(bpid,map,blocks[0],recoveryid2);
    assertEquals(originalInfo,recoveryInfo2);
    final ReplicaUnderRecovery updatedInfo2=(ReplicaUnderRecovery)map.get(bpid,b);
    Assert.assertEquals(originalInfo.getBlockId(),updatedInfo2.getBlockId());
    Assert.assertEquals(recoveryid2,updatedInfo2.getRecoveryID());
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    RecoveryInProgressException ripe) {
      System.out.println("GOOD: getting " + ripe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid - 1,length,gs);
    ReplicaRecoveryInfo r=FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
    Assert.assertNull("Data-node should not have this replica.",r);
  }
{
    final long recoveryid=gs - 1;
    final Block b=new Block(firstblockid + 1,length,gs);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      Assert.fail();
    }
 catch (    IOException ioe) {
      System.out.println("GOOD: getting " + ioe);
    }
  }
{
    final long recoveryid=gs + 1;
    final Block b=new Block(firstblockid,length,gs + 1);
    try {
      FSDataset.initReplicaRecovery(bpid,map,b,recoveryid);
      fail("InitReplicaRecovery should fail because replica's " + "gs is less than the block's gs");
    }
 catch (    IOException e) {
      e.getMessage().startsWith("replica.getGenerationStamp() < block.getGenerationStamp(), block=");
    }
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestReplicasMap </h4><pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Test for ReplicasMap.get(Block) and ReplicasMap.get(long) tests
 */
@Test public void testGet(){
  try {
    map.get(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  assertNotNull(map.get(bpid,block));
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.get(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.get(bpid,b));
  assertNotNull(map.get(bpid,block.getBlockId()));
  assertNull(map.get(bpid,0));
}

</code></pre>

<br>
<pre class="type-3 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testRemove(){
  try {
    map.remove(bpid,null);
    fail("Expected exception not thrown");
  }
 catch (  IllegalArgumentException expected) {
  }
  Block b=new Block(block);
  b.setGenerationStamp(0);
  assertNull(map.remove(bpid,b));
  b.setGenerationStamp(block.getGenerationStamp());
  b.setBlockId(0);
  assertNull(map.remove(bpid,b));
  assertNotNull(map.remove(bpid,block));
  assertNull(map.remove(bpid,0));
  map.add(bpid,new FinalizedReplica(block,null,null));
  assertNotNull(map.remove(bpid,block.getBlockId()));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestAllowFormat </h4><pre class="type-3 type-8 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies boolean conditions
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * start MiniDFScluster, try formatting with different settings
 * @throws IOException
 * @throws InterruptedException 
 */
@Test public void testAllowFormat() throws IOException {
  LOG.info("--starting mini cluster");
  NameNode nn;
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  cluster=new MiniDFSCluster.Builder(config).manageDataDfsDirs(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  assertNotNull(cluster);
  nn=cluster.getNameNode();
  assertNotNull(nn);
  LOG.info("Mini cluster created OK");
  LOG.info("Verifying format will fail with allowformat false");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,false);
  try {
    cluster.shutdown();
    NameNode.format(config);
    fail("Format succeeded, when it should have failed");
  }
 catch (  IOException e) {
    assertTrue("Exception was not about formatting Namenode",e.getMessage().startsWith("The option " + DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY));
    LOG.info("Expected failure: " + StringUtils.stringifyException(e));
    LOG.info("Done verifying format will fail with allowformat false");
  }
  LOG.info("Verifying format will succeed with allowformat true");
  config.setBoolean(DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY,true);
  NameNode.format(config);
  LOG.info("Done verifying format will succeed with allowformat true");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestEditLogRace </h4><pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Most of the FSNamesystem methods have a synchronized section where they
 * update the name system itself and write to the edit log, and then
 * unsynchronized, they call logSync. This test verifies that, if an
 * operation has written to the edit log but not yet synced it,
 * we wait for that sync before entering safe mode.
 */
@Test public void testSaveRightBeforeSync() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=spy(fsimage.getEditLog());
    fsimage.editLog=editLog;
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterSync=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterSync.countDown();
        }
      }
    }
;
    Answer<Void> blockingSync=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("logSync called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it just before logSync...");
          waitToEnterSync.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to logSync. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("logSync complete");
        return null;
      }
    }
;
    doAnswer(blockingSync).when(editLog).logSync();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to just before logSync...");
    waitToEnterSync.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync about to be called.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since we have pending edits");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<pre class="type-8 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies boolean conditions">BooleanVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies boolean conditions
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * The logSync() method in FSEditLog is unsynchronized whiel syncing
 * so that other threads can concurrently enqueue edits while the prior
 * sync is ongoing. This test checks that the log is saved correctly
 * if the saveImage occurs while the syncing thread is in the unsynchronized middle section.
 * This replicates the following manual test proposed by Konstantin:
 * I start the name-node in debugger.
 * I do -mkdir and stop the debugger in logSync() just before it does flush.
 * Then I enter safe mode with another client
 * I start saveNamepsace and stop the debugger in
 * FSImage.saveFSImage() -> FSEditLog.createEditLogFile()
 * -> EditLogFileOutputStream.create() ->
 * after truncating the file but before writing LAYOUT_VERSION into it.
 * Then I let logSync() run.
 * Then I terminate the name-node.
 * After that the name-node wont start, since the edits file is broken.
 */
@Test public void testSaveImageWhileSyncInProgress() throws Exception {
  Configuration conf=getConf();
  NameNode.initMetrics(conf,NamenodeRole.ACTIVE);
  DFSTestUtil.formatNameNode(conf);
  final FSNamesystem namesystem=new FSNamesystem(conf);
  try {
    FSImage fsimage=namesystem.getFSImage();
    FSEditLog editLog=fsimage.getEditLog();
    ArrayList<EditLogOutputStream> streams=editLog.getEditStreams();
    EditLogOutputStream spyElos=spy(streams.get(0));
    streams.set(0,spyElos);
    final AtomicReference<Throwable> deferredException=new AtomicReference<Throwable>();
    final CountDownLatch waitToEnterFlush=new CountDownLatch(1);
    final Thread doAnEditThread=new Thread(){
      public void run(){
        try {
          LOG.info("Starting mkdirs");
          namesystem.mkdirs("/test",new PermissionStatus("test","test",new FsPermission((short)00755)),true);
          LOG.info("mkdirs complete");
        }
 catch (        Throwable ioe) {
          deferredException.set(ioe);
          waitToEnterFlush.countDown();
        }
      }
    }
;
    Answer<Void> blockingFlush=new Answer<Void>(){
      @Override public Void answer(      InvocationOnMock invocation) throws Throwable {
        LOG.info("Flush called");
        if (Thread.currentThread() == doAnEditThread) {
          LOG.info("edit thread: Telling main thread we made it to flush section...");
          waitToEnterFlush.countDown();
          LOG.info("edit thread: sleeping for " + BLOCK_TIME + "secs");
          Thread.sleep(BLOCK_TIME * 1000);
          LOG.info("Going through to flush. This will allow the main thread to continue.");
        }
        invocation.callRealMethod();
        LOG.info("Flush complete");
        return null;
      }
    }
;
    doAnswer(blockingFlush).when(spyElos).flush();
    doAnEditThread.start();
    LOG.info("Main thread: waiting to enter flush...");
    waitToEnterFlush.await();
    assertNull(deferredException.get());
    LOG.info("Main thread: detected that logSync is in unsynchronized section.");
    LOG.info("Trying to enter safe mode.");
    LOG.info("This should block for " + BLOCK_TIME + "sec, since flush will sleep that long");
    long st=System.currentTimeMillis();
    namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    long et=System.currentTimeMillis();
    LOG.info("Entered safe mode");
    assertTrue(et - st > (BLOCK_TIME - 1) * 1000);
    namesystem.saveNamespace();
    LOG.info("Joining on edit thread...");
    doAnEditThread.join();
    assertNull(deferredException.get());
    verifyEditLogs(namesystem,fsimage);
  }
  finally {
    LOG.info("Closing namesystem");
    if (namesystem != null)     namesystem.close();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat </h4><pre class="type-7 type-9 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Allocates resources before the execution of the test cases">TestInitializer</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Allocates resources before the execution of the test cases
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Before public void startUpCluster() throws IOException {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPL_FACTOR).build();
  assertNotNull("Failed Cluster Creation",cluster);
  cluster.waitClusterUp();
  dfs=(DistributedFileSystem)cluster.getFileSystem();
  assertNotNull("Failed to get FileSystem",dfs);
  nn=cluster.getNameNode();
  assertNotNull("Failed to get NameNode",nn);
}

</code></pre>

<br>
<pre class="type-10 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to API calls (Java or TPL) ">APIUtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to API calls (Java or TPL) 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void testConcatNotCompleteBlock() throws IOException {
  long trgFileLen=blockSize * 3;
  long srcFileLen=blockSize * 3 + 20;
  String name1="/trg", name2="/src";
  Path filePath1=new Path(name1);
  DFSTestUtil.createFile(dfs,filePath1,trgFileLen,REPL_FACTOR,1);
  HdfsFileStatus fStatus=cluster.getNameNode().getFileInfo(name1);
  long fileLen=fStatus.getLen();
  assertEquals(fileLen,trgFileLen);
  FSDataInputStream stm=dfs.open(filePath1);
  byte[] byteFile1=new byte[(int)trgFileLen];
  stm.readFully(0,byteFile1);
  stm.close();
  LocatedBlocks lb1=cluster.getNameNode().getBlockLocations(name1,0,trgFileLen);
  Path filePath2=new Path(name2);
  DFSTestUtil.createFile(dfs,filePath2,srcFileLen,REPL_FACTOR,1);
  fStatus=cluster.getNameNode().getFileInfo(name2);
  fileLen=fStatus.getLen();
  assertEquals(srcFileLen,fileLen);
  stm=dfs.open(filePath2);
  byte[] byteFile2=new byte[(int)srcFileLen];
  stm.readFully(0,byteFile2);
  stm.close();
  LocatedBlocks lb2=cluster.getNameNode().getBlockLocations(name2,0,srcFileLen);
  System.out.println("trg len=" + trgFileLen + "; src len="+ srcFileLen);
  dfs.concat(filePath1,new Path[]{filePath2});
  long totalLen=trgFileLen + srcFileLen;
  fStatus=cluster.getNameNode().getFileInfo(name1);
  fileLen=fStatus.getLen();
  stm=dfs.open(filePath1);
  byte[] byteFileConcat=new byte[(int)fileLen];
  stm.readFully(0,byteFileConcat);
  stm.close();
  LocatedBlocks lbConcat=cluster.getNameNode().getBlockLocations(name1,0,fileLen);
  assertEquals(lbConcat.locatedBlockCount(),lb1.locatedBlockCount() + lb2.locatedBlockCount());
  System.out.println("file1 len=" + fileLen + "; total len="+ totalLen);
  assertEquals(fileLen,totalLen);
  fStatus=cluster.getNameNode().getFileInfo(name2);
  assertNull("File " + name2 + "still exists",fStatus);
  checkFileContent(byteFileConcat,new byte[][]{byteFile1,byteFile2});
}

</code></pre>

<br>
<pre class="type-16 type-3 type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies assertions in iterations">IterativeVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies (un)successful execution of the test case by reporting explicitly a failure">UtilityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies assertions in iterations
- Verifies (un)successful execution of the test case by reporting explicitly a failure
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
/** 
 * Concatenates 10 files into one
 * Verifies the final size, deletion of the file, number of blocks
 * @throws IOException
 */
@Test public void testConcat() throws IOException, InterruptedException {
  final int numFiles=10;
  long fileLen=blockSize * 3;
  HdfsFileStatus fStatus;
  FSDataInputStream stm;
  String trg=new String("/trg");
  Path trgPath=new Path(trg);
  DFSTestUtil.createFile(dfs,trgPath,fileLen,REPL_FACTOR,1);
  fStatus=nn.getFileInfo(trg);
  long trgLen=fStatus.getLen();
  long trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  Path[] files=new Path[numFiles];
  byte[][] bytes=new byte[numFiles][(int)fileLen];
  LocatedBlocks[] lblocks=new LocatedBlocks[numFiles];
  long[] lens=new long[numFiles];
  int i=0;
  for (i=0; i < files.length; i++) {
    files[i]=new Path("/file" + i);
    Path path=files[i];
    System.out.println("Creating file " + path);
    DFSTestUtil.createFile(dfs,path,fileLen,REPL_FACTOR,1);
    fStatus=nn.getFileInfo(path.toUri().getPath());
    lens[i]=fStatus.getLen();
    assertEquals(trgLen,lens[i]);
    lblocks[i]=nn.getBlockLocations(path.toUri().getPath(),0,lens[i]);
    stm=dfs.open(path);
    stm.readFully(0,bytes[i]);
    stm.close();
  }
  final UserGroupInformation user1=UserGroupInformation.createUserForTesting("theDoctor",new String[]{"tardis"});
  DistributedFileSystem hdfs=(DistributedFileSystem)DFSTestUtil.getFileSystemAs(user1,conf);
  try {
    hdfs.concat(trgPath,files);
    fail("Permission exception expected");
  }
 catch (  IOException ie) {
    System.out.println("Got expected exception for permissions:" + ie.getLocalizedMessage());
  }
  ContentSummary cBefore=dfs.getContentSummary(trgPath.getParent());
  dfs.concat(trgPath,files);
  ContentSummary cAfter=dfs.getContentSummary(trgPath.getParent());
  assertEquals(cBefore.getFileCount(),cAfter.getFileCount() + files.length);
  long totalLen=trgLen;
  long totalBlocks=trgBlocks;
  for (i=0; i < files.length; i++) {
    totalLen+=lens[i];
    totalBlocks+=lblocks[i].locatedBlockCount();
  }
  System.out.println("total len=" + totalLen + "; totalBlocks="+ totalBlocks);
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  stm=dfs.open(trgPath);
  byte[] byteFileConcat=new byte[(int)trgLen];
  stm.readFully(0,byteFileConcat);
  stm.close();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks);
  assertEquals(trgLen,totalLen);
  for (  Path p : files) {
    fStatus=nn.getFileInfo(p.toUri().getPath());
    assertNull("File " + p + " still exists",fStatus);
    DFSTestUtil.createFile(dfs,p,fileLen,REPL_FACTOR,1);
  }
  checkFileContent(byteFileConcat,bytes);
  Path smallFile=new Path("/sfile");
  int sFileLen=10;
  DFSTestUtil.createFile(dfs,smallFile,sFileLen,REPL_FACTOR,1);
  dfs.concat(trgPath,new Path[]{smallFile});
  fStatus=nn.getFileInfo(trg);
  trgLen=fStatus.getLen();
  trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
  assertEquals(trgBlocks,totalBlocks + 1);
  assertEquals(trgLen,totalLen + sFileLen);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete </h4><pre class="type-9 type-6 type-4 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies values of objects/variables related to AUT calls">InternalCallVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects/variable are equal to an expected value ">EqualityVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Verifies whether objects are null">NullVerifier</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Contains more than 2 JUnit-based stereotypes">HybridVerifier</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Verifies values of objects/variables related to AUT calls
- Verifies whether objects/variable are equal to an expected value 
- Verifies whether objects are null
- Contains more than 2 JUnit-based stereotypes
"></span><br>
@Test public void largeDelete() throws Throwable {
  mc=new MiniDFSCluster.Builder(CONF).build();
  try {
    mc.waitActive();
    Assert.assertNotNull("No Namenode in cluster",mc.getNameNode());
    createFiles();
    Assert.assertEquals(TOTAL_BLOCKS,getBlockCount());
    runThreads();
  }
  finally {
    mc.shutdown();
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

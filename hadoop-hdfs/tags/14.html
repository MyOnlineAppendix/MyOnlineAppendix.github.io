<h3><span class=" glyphicon glyphicon-tag"/>&nbspLogger</h3><kbd>Invokes logging operations</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestCrcCorruption </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testCrcCorruption() throws Exception {
  System.out.println("TestCrcCorruption with default parameters");
  Configuration conf1=new HdfsConfiguration();
  conf1.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
  DFSTestUtil util1=new DFSTestUtil("TestCrcCorruption",40,3,8 * 1024);
  thistest(conf1,util1);
  System.out.println("TestCrcCorruption with specific parameters");
  Configuration conf2=new HdfsConfiguration();
  conf2.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,17);
  conf2.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,34);
  DFSTestUtil util2=new DFSTestUtil("TestCrcCorruption",40,3,400);
  thistest(conf2,util2);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestFileAppend </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test a simple flush on a simple HDFS file.
 * @throws IOException an exception might be thrown
 */
@Test public void testSimpleFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    conf.setBoolean(SimulatedFSDataset.CONFIG_PROPERTY_SIMULATED,true);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/simpleFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file simpleFlush.dat");
    int mid=AppendTestUtil.FILE_SIZE / 2;
    stm.write(fileContents,0,mid);
    stm.hflush();
    System.out.println("Wrote and Flushed first part of file.");
    stm.write(fileContents,mid,AppendTestUtil.FILE_SIZE - mid);
    System.out.println("Written second part of file");
    stm.hflush();
    stm.hflush();
    System.out.println("Wrote and Flushed second part of file.");
    checkFile(fs,file1,1);
    stm.close();
    System.out.println("Closed file.");
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<br>
<pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test that file data can be flushed.
 * @throws IOException an exception might be thrown
 */
@Test public void testComplexFlush() throws IOException {
  Configuration conf=new HdfsConfiguration();
  if (simulatedStorage) {
    conf.setBoolean(SimulatedFSDataset.CONFIG_PROPERTY_SIMULATED,true);
  }
  fileContents=AppendTestUtil.initBuffer(AppendTestUtil.FILE_SIZE);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  FileSystem fs=cluster.getFileSystem();
  try {
    Path file1=new Path("/complexFlush.dat");
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,file1,1);
    System.out.println("Created file complexFlush.dat");
    int start=0;
    for (start=0; (start + 29) < AppendTestUtil.FILE_SIZE; ) {
      stm.write(fileContents,start,29);
      stm.hflush();
      start+=29;
    }
    stm.write(fileContents,start,AppendTestUtil.FILE_SIZE - start);
    checkFile(fs,file1,1);
    stm.close();
    AppendTestUtil.checkFullFile(fs,file1,AppendTestUtil.FILE_SIZE,fileContents,"Read 2");
  }
 catch (  IOException e) {
    System.out.println("Exception :" + e);
    throw e;
  }
catch (  Throwable e) {
    System.out.println("Throwable :" + e);
    e.printStackTrace();
    throw new IOException("Throwable : " + e);
  }
 finally {
    fs.close();
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestHFlush </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * This creates a slow writer and check to see 
 * if pipeline heartbeats work fine
 */
@Test public void testPipelineHeartbeat() throws Exception {
  final int DATANODE_NUM=2;
  final int fileLen=6;
  Configuration conf=new HdfsConfiguration();
  final int timeout=2000;
  conf.setInt(DFSConfigKeys.DFS_CLIENT_SOCKET_TIMEOUT_KEY,timeout);
  final Path p=new Path("/pipelineHeartbeat/foo");
  System.out.println("p=" + p);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
  try {
    DistributedFileSystem fs=(DistributedFileSystem)cluster.getFileSystem();
    byte[] fileContents=AppendTestUtil.initBuffer(fileLen);
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,p,DATANODE_NUM);
    stm.write(fileContents,0,1);
    Thread.sleep(timeout);
    stm.hflush();
    System.out.println("Wrote 1 byte and hflush " + p);
    Thread.sleep(timeout);
    stm.write(fileContents,1,1);
    stm.hflush();
    stm.write(fileContents,2,1);
    Thread.sleep(timeout);
    stm.hflush();
    stm.write(fileContents,3,1);
    Thread.sleep(timeout);
    stm.write(fileContents,4,1);
    stm.hflush();
    stm.write(fileContents,5,1);
    Thread.sleep(timeout);
    stm.close();
    AppendTestUtil.checkFullFile(fs,p,fileLen,fileContents,"Failed to slowly write to a file");
  }
  finally {
    cluster.shutdown();
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.TestWriteConfigurationToDFS </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test(timeout=60000) public void testWriteConf() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,4096);
  System.out.println("Setting conf in: " + System.identityHashCode(conf));
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  FileSystem fs=cluster.getFileSystem();
  Path filePath=new Path("/testWriteConf.xml");
  OutputStream os=fs.create(filePath);
  StringBuilder longString=new StringBuilder();
  for (int i=0; i < 100000; i++) {
    longString.append("hello");
  }
  conf.set("foobar",longString.toString());
  conf.writeXml(os);
  os.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testVolumeFailure() throws IOException {
  FileSystem fs=cluster.getFileSystem();
  dataDir=new File(cluster.getDataDirectory());
  System.out.println("Data dir: is " + dataDir.getPath());
  String filename="/test.txt";
  Path filePath=new Path(filename);
  int filesize=block_size * blocks_num;
  DFSTestUtil.createFile(fs,filePath,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,filePath,repl);
  System.out.println("file " + filename + "(size "+ filesize+ ") is created and replicated");
  data_fail=new File(dataDir,"data3");
  failedDir=MiniDFSCluster.getFinalizedDir(dataDir,cluster.getNamesystem().getBlockPoolId());
  if (failedDir.exists() && !deteteBlocks(failedDir)) {
    throw new IOException("Could not delete hdfs directory '" + failedDir + "'");
  }
  data_fail.setReadOnly();
  failedDir.setReadOnly();
  System.out.println("Deleteing " + failedDir.getPath() + "; exist="+ failedDir.exists());
  triggerFailure(filename,filesize);
  DataNode dn=cluster.getDataNodes().get(1);
  String bpid=cluster.getNamesystem().getBlockPoolId();
  DatanodeRegistration dnR=dn.getDNRegistrationForBP(bpid);
  long[] bReport=dn.getFSDataset().getBlockReport(bpid).getBlockListAsLongs();
  cluster.getNameNode().blockReport(dnR,bpid,bReport);
  verify(filename,filesize);
  System.out.println("creating file test1.txt");
  Path fileName1=new Path("/test1.txt");
  DFSTestUtil.createFile(fs,fileName1,filesize,repl,1L);
  DFSTestUtil.waitReplication(fs,fileName1,repl);
  System.out.println("file " + fileName1.getName() + " is created and replicated");
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hdfs.tools.TestGetConf </h4><pre class="type-14 type-1 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * Test empty configuration
 */
@Test public void testEmptyConf() throws Exception {
  HdfsConfiguration conf=new HdfsConfiguration(false);
  getAddressListFromTool(TestType.NAMENODE,conf,false);
  System.out.println(getAddressListFromTool(TestType.BACKUP,conf,false));
  getAddressListFromTool(TestType.SECONDARY,conf,false);
  getAddressListFromTool(TestType.NNRPCADDRESSES,conf,false);
  for (  Command cmd : Command.values()) {
    CommandHandler handler=Command.getHandler(cmd.getName());
    if (handler.key != null) {
      String[] args={handler.key};
      runTool(conf,args,false);
    }
  }
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>

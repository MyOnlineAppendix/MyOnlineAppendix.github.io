<h3><span class=" glyphicon glyphicon-tag"/>&nbspLogger</h3><kbd>Invokes logging operations</kbd><br><br><br><h4 style="margin:0px">Class: org.apache.hadoop.hive.ql.exec.vector.TestVectorFilterOperator </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testBasicFilterLargeData() throws HiveException {
  VectorFilterOperator vfo=getAVectorFilterOperator();
  vfo.initialize(hconf,null);
  VectorExpression ve1=new FilterLongColGreaterLongColumn(0,1);
  VectorExpression ve2=new FilterLongColEqualDoubleScalar(2,0);
  VectorExpression ve3=new FilterExprAndExpr();
  ve3.setChildExpressions(new VectorExpression[]{ve1,ve2});
  vfo.setFilterCondition(ve3);
  FakeDataReader fdr=new FakeDataReader(16 * 1024 * 1024,3);
  long startTime=System.currentTimeMillis();
  VectorizedRowBatch vrg=fdr.getNext();
  while (vrg.size > 0) {
    vfo.process(vrg,0);
    vrg=fdr.getNext();
  }
  long endTime=System.currentTimeMillis();
  System.out.println("testBaseFilterOperator Op Time = " + (endTime - startTime));
  fdr=new FakeDataReader(16 * 1024 * 1024,3);
  long startTime1=System.currentTimeMillis();
  vrg=fdr.getNext();
  LongColumnVector l1=(LongColumnVector)vrg.cols[0];
  LongColumnVector l2=(LongColumnVector)vrg.cols[1];
  LongColumnVector l3=(LongColumnVector)vrg.cols[2];
  int rows=0;
  for (int j=0; j < 16 * 1024; j++) {
    for (int i=0; i < l1.vector.length && i < l2.vector.length && i < l3.vector.length; i++) {
      if ((l1.vector[i] > l2.vector[i]) && (l3.vector[i] == 0)) {
        rows++;
      }
    }
  }
  long endTime1=System.currentTimeMillis();
  System.out.println("testBaseFilterOperator base Op Time = " + (endTime1 - startTime1));
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hive.ql.io.orc.TestFileDump </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testBloomFilter2() throws Exception {
  ObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=ObjectInspectorFactory.getReflectionObjectInspector(MyRecord.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  conf.set(HiveConf.ConfVars.HIVE_ORC_ENCODING_STRATEGY.varname,"COMPRESSION");
  OrcFile.WriterOptions options=OrcFile.writerOptions(conf).fileSystem(fs).inspector(inspector).stripeSize(100000).compress(CompressionKind.ZLIB).bufferSize(10000).rowIndexStride(1000).bloomFilterColumns("l").bloomFilterFpp(0.01).batchSize(1000);
  Writer writer=OrcFile.createWriter(testFilePath,options);
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  for (int i=0; i < 21000; ++i) {
    writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),words[r1.nextInt(words.length)]));
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump-bloomfilter2.out";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"--rowindex=2"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}

</code></pre>

<br>
<pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testDump() throws Exception {
  ObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=ObjectInspectorFactory.getReflectionObjectInspector(MyRecord.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  conf.set(HiveConf.ConfVars.HIVE_ORC_ENCODING_STRATEGY.varname,"COMPRESSION");
  Writer writer=OrcFile.createWriter(testFilePath,OrcFile.writerOptions(conf).fileSystem(fs).inspector(inspector).batchSize(1000).compress(CompressionKind.ZLIB).stripeSize(100000).rowIndexStride(1000));
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  for (int i=0; i < 21000; ++i) {
    writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),words[r1.nextInt(words.length)]));
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump.out";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"--rowindex=1,2,3"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}

</code></pre>

<br>
<pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testBloomFilter() throws Exception {
  ObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=ObjectInspectorFactory.getReflectionObjectInspector(MyRecord.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  conf.set(HiveConf.ConfVars.HIVE_ORC_ENCODING_STRATEGY.varname,"COMPRESSION");
  OrcFile.WriterOptions options=OrcFile.writerOptions(conf).fileSystem(fs).inspector(inspector).stripeSize(100000).compress(CompressionKind.ZLIB).bufferSize(10000).rowIndexStride(1000).batchSize(1000).bloomFilterColumns("S");
  Writer writer=OrcFile.createWriter(testFilePath,options);
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  for (int i=0; i < 21000; ++i) {
    writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),words[r1.nextInt(words.length)]));
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump-bloomfilter.out";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"--rowindex=3"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}

</code></pre>

<br>
<pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testDictionaryThreshold() throws Exception {
  ObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=ObjectInspectorFactory.getReflectionObjectInspector(MyRecord.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  Configuration conf=new Configuration();
  conf.set(HiveConf.ConfVars.HIVE_ORC_ENCODING_STRATEGY.varname,"COMPRESSION");
  conf.setFloat(HiveConf.ConfVars.HIVE_ORC_DICTIONARY_KEY_SIZE_THRESHOLD.varname,0.49f);
  Writer writer=OrcFile.createWriter(testFilePath,OrcFile.writerOptions(conf).fileSystem(fs).batchSize(1000).inspector(inspector).stripeSize(100000).compress(CompressionKind.ZLIB).rowIndexStride(1000).bufferSize(10000));
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  int nextInt=0;
  for (int i=0; i < 21000; ++i) {
    if (i % 2 == 0) {
      nextInt=r1.nextInt(words.length);
      words[nextInt]+="-" + i;
    }
    writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),words[nextInt]));
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump-dictionary-threshold.out";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"--rowindex=1,2,3"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testJsonDump() throws Exception {
  ObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=ObjectInspectorFactory.getReflectionObjectInspector(MyRecord.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  conf.set(HiveConf.ConfVars.HIVE_ORC_ENCODING_STRATEGY.varname,"COMPRESSION");
  OrcFile.WriterOptions options=OrcFile.writerOptions(conf).fileSystem(fs).inspector(inspector).stripeSize(100000).compress(CompressionKind.ZLIB).bufferSize(10000).rowIndexStride(1000).bloomFilterColumns("s");
  Writer writer=OrcFile.createWriter(testFilePath,options);
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  for (int i=0; i < 21000; ++i) {
    if (i % 100 == 0) {
      writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),null));
    }
 else {
      writer.addRow(new MyRecord(r1.nextInt(),r1.nextLong(),words[r1.nextInt(words.length)]));
    }
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump.json";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"-j","-p","--rowindex=3"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hive.hcatalog.streaming.TestStreaming </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
/** 
 * make sure it works with table where bucket col is not 1st col
 * @throws Exception
 */
@Test public void testBucketingWhereBucketColIsNotFirstCol() throws Exception {
  List<String> partitionVals=new ArrayList<String>();
  partitionVals.add("2015");
  HiveEndPoint endPt=new HiveEndPoint(metaStoreURI,"testing5","store_sales",partitionVals);
  DelimitedInputWriter writer=new DelimitedInputWriter(new String[]{"ss_sold_date_sk","ss_sold_time_sk","ss_item_sk","ss_customer_sk","ss_cdemo_sk","ss_hdemo_sk","ss_addr_sk","ss_store_sk","ss_promo_sk","ss_ticket_number","ss_quantity","ss_wholesale_cost","ss_list_price","ss_sales_price","ss_ext_discount_amt","ss_ext_sales_price","ss_ext_wholesale_cost","ss_ext_list_price","ss_ext_tax","ss_coupon_amt","ss_net_paid","ss_net_paid_inc_tax","ss_net_profit"},",",endPt);
  StreamingConnection connection=endPt.newConnection(false,null);
  TransactionBatch txnBatch=connection.fetchTransactionBatch(2,writer);
  txnBatch.beginNextTransaction();
  StringBuilder row=new StringBuilder();
  for (int i=0; i < 10; i++) {
    for (int ints=0; ints < 11; ints++) {
      row.append(ints).append(',');
    }
    for (int decs=0; decs < 12; decs++) {
      row.append(i + 0.1).append(',');
    }
    row.setLength(row.length() - 1);
    txnBatch.write(row.toString().getBytes());
  }
  txnBatch.commit();
  txnBatch.close();
  connection.close();
  ArrayList<String> res=queryTable(driver,"select row__id.bucketid, * from testing5.store_sales");
  for (  String re : res) {
    System.out.println(re);
  }
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hive.jdbc.TestJdbcDriver2 </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testNullResultSet() throws Exception {
  List<String> setupQueries=new ArrayList<String>();
  String testQuery;
  Statement stmt=con.createStatement();
  try {
    stmt.executeQuery("select * from " + tableName);
    System.out.println("select: success");
  }
 catch (  SQLException e) {
    failWithExceptionMsg(e);
  }
  setupQueries.add("drop table test_t1");
  testQuery="create table test_t1 (under_col int, value string)";
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  setupQueries.add("drop table test_t1");
  testQuery="create table test_t1 as select * from " + tableName;
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  setupQueries.add("drop table test_t1");
  setupQueries.add("create table test_t1 (under_col int, value string)");
  testQuery="insert into table test_t1 select under_col, value from " + tableName;
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  stmt.close();
}

</code></pre>

<br>
<h4 style="margin:0px">Class: org.apache.hive.jdbc.cbo_rp_TestJdbcDriver2 </h4><pre class="type-19 type-2 "><code><span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Invokes logging operations">Logger</span>&nbsp;<span class="label label-info" style="display: inline-block;" data-toggle="tooltip" title="Executes methods or other tests from the same test unit">ExecutionTester</span>&nbsp;<span class=" glyphicon glyphicon-comment" aria-hidden="true" label-info" data-toggle="tooltip" title="This method/test case: 
- Invokes logging operations
- Executes methods or other tests from the same test unit
"></span><br>
@Test public void testNullResultSet() throws Exception {
  List<String> setupQueries=new ArrayList<String>();
  String testQuery;
  Statement stmt=con.createStatement();
  try {
    stmt.executeQuery("select * from " + tableName);
    System.out.println("select: success");
  }
 catch (  SQLException e) {
    failWithExceptionMsg(e);
  }
  setupQueries.add("drop table test_t1");
  testQuery="create table test_t1 (under_col int, value string)";
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  setupQueries.add("drop table test_t1");
  testQuery="create table test_t1 as select * from " + tableName;
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  setupQueries.add("drop table test_t1");
  setupQueries.add("create table test_t1 (under_col int, value string)");
  testQuery="insert into table test_t1 select under_col, value from " + tableName;
  checkResultSetExpected(stmt,setupQueries,testQuery,false);
  setupQueries.clear();
  stmt.close();
}

</code></pre>

<br>
<script>$(document).ready(function() {
  $('pre code').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});</script>
